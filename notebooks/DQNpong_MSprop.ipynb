{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning\n",
    "\n",
    "In this notebook, you will implement a deep Q-Learning reinforcement algorithm. The implementation borrows ideas from both the original DeepMind Nature paper and the more recent asynchronous version:<br/>\n",
    "[1] \"Human-Level Control through Deep Reinforcement Learning\" by Mnih et al. 2015<br/>\n",
    "[2] \"Asynchronous Methods for Deep Reinforcement Learning\" by Mnih et al. 2016.<br/>\n",
    "\n",
    "In particular:\n",
    "* We use separate target and Q-functions estimators with periodic updates to the target estimator. \n",
    "* We use several concurrent \"threads\" rather than experience replay to generate less biased gradient updates. \n",
    "* Threads are actually synchronized so we start each one at a random number of moves.\n",
    "* We use an epsilon-greedy policy that blends random moves with policy moves.\n",
    "* We taper the random search parameter (epsilon) and the learning rate to zero during training.\n",
    "\n",
    "This gives a simple and reasonably fast general-purpose RL algorithm. We use it here for the Cartpole environment from OpenAI Gym, but it can easily be adapted to others. For this notebook, you will implement 4 steps:\n",
    "\n",
    "1. The backward step for the Q-estimator\n",
    "2. The $\\epsilon$-greedy policy\n",
    "3. \"asynchronous\" initialization \n",
    "4. The Q-learning algorithm\n",
    "\n",
    "To get started, we import some prerequisites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 CUDA device found, CUDA version 8.0\n"
     ]
    }
   ],
   "source": [
    "import BIDMat.{CMat,CSMat,DMat,Dict,FMat,FND,GMat,GDMat,GIMat,GLMat,GSMat,GSDMat,GND,HMat,IDict,Image,IMat,LMat,Mat,SMat,SBMat,SDMat,TMat}\n",
    "import BIDMat.MatFunctions._\n",
    "import BIDMat.SciFunctions._\n",
    "import BIDMat.Solvers._\n",
    "import BIDMat.JPlotting._\n",
    "import BIDMach.Learner\n",
    "\n",
    "import BIDMach.models.{Click,FM,GLM,KMeans,KMeansw,LDA,LDAgibbs,Model,NMF,SFA,RandomForest,SVD}\n",
    "import BIDMach.networks.{Net}\n",
    "import BIDMach.datasources.{DataSource,MatSource,FileSource,SFileSource}\n",
    "import BIDMach.datasinks.{DataSink,MatSink}\n",
    "import BIDMach.mixins.{CosineSim,Perplexity,Top,L1Regularizer,L2Regularizer}\n",
    "import BIDMach.updaters.{ADAGrad,Batch,BatchNorm,Grad,IncMult,IncNorm,Telescoping}\n",
    "import BIDMach.causal.{IPTW}\n",
    "import BIDMach.rl.ALE\n",
    "\n",
    "Mat.checkMKL(false)\n",
    "Mat.checkCUDA\n",
    "Mat.setInline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ale = new ALE\n",
    "ale.getFloat(\"repeat_action_probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block below lists some parameters you can tune. They should be self-explanatory. They are currently set to train CartPole-V0 to a \"solved\" score (> 195) most of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nsteps = 20000001                     // Number of steps to run (game actions per environment)\n",
    "val npar = 16                            // Number of parallel environments\n",
    "val target_window = 100                  // Interval to update target estimator from q-estimator\n",
    "val discount_factor = 0.99f              // Reward discount factor\n",
    "val printsteps = 10000                   // Number of steps between printouts\n",
    "val render = false                       // Whether to render an environment while training\n",
    "\n",
    "val epsilon_start = 0.5f                 // Parameters for epsilon-greedy policy: initial epsilon\n",
    "val epsilon_end = 0.01f                  // Final epsilon\n",
    "val neps = (0.9*nsteps).toInt            // Number of steps to decay epsilon\n",
    "\n",
    "//val learning_rate = 5e-4f\n",
    "val learning_rate = 3e-6f                // Initial learning rate\n",
    "val lr_end = learning_rate               // Final learning rate\n",
    "val nlr = neps                           // Steps to decay learning rate\n",
    "val gsq_decay = 0.99f                   // Decay factor for RMSProp\n",
    "val momentum_decay = 0.9f\n",
    "val gclip = 1f\n",
    "val rmseps = 1e-5f\n",
    "val rmsevery = 10\n",
    "\n",
    "val nhidden = 200                        // Number of hidden layers for estimators\n",
    "\n",
    "val init_moves = 10000                   // Upper bound on random number of moves to take initially\n",
    "val nwindow = 2                          // Sensing window = last n images in a state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are environment-specific parameters. The function \"preprocess\" should process an observation returned by the environment into a vector for training. For CartPole we simply append a 1 to implement bias in the first layer. \n",
    "\n",
    "For visual environments you would typically crop, downsample to 80x80, set color to a single bit (foreground/background), and flatten to a vector. \n",
    "\n",
    "*nfeats* is the dimension of the vector output by *preprocess*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "val game_bin=\"/code/ALE/roms/Pong.bin\"                 // Model type and action definitions\n",
    "val VALID_ACTIONS = irow(0, 3, 4)\n",
    "val nactions= VALID_ACTIONS.length\n",
    "val nfeats = 80*80                         \n",
    "\n",
    "def preprocess(I:FND):FMat = {\n",
    "//  Preprocess Pong game frames into vectors.\n",
    "//  Input:\n",
    "//    - (3,160,210) uint8 frame representing Pong game screen.\n",
    "//  Returns:\n",
    "//    - Downsampled (DxD) matrix of 0s and 1s, \"raveled\" into a 1-D vector.\n",
    "    var i = 0;\n",
    "    val res = zeros(80*80,1)\n",
    "    while (i < 80) {\n",
    "        var j = 0;\n",
    "        while (j < 80) {\n",
    "            val x = I.data(3*(j*2 + 160 * (i*2 + 35)));\n",
    "            res.data(j + 80*i) = {if (x == 144f || x == 109f) 0f else {if (x != 0f) 1f else 0f}};\n",
    "            j += 1;\n",
    "        }\n",
    "        i += 1;\n",
    "    }\n",
    "    res\n",
    "}\n",
    "\n",
    "def preprocess(I:Array[Byte]):FMat = {\n",
    "//  Preprocess Pong game frames into vectors.\n",
    "//  Input:\n",
    "//    - (3,160,210) uint8 frame representing Pong game screen.\n",
    "//  Returns:\n",
    "//    - Downsampled (DxD) matrix of 0s and 1s, \"raveled\" into a 1-D vector.\n",
    "    var i = 0;\n",
    "    val res = zeros(80*80,1)\n",
    "    while (i < 80) {\n",
    "        var j = 0;\n",
    "        while (j < 80) {\n",
    "            val x = I(j*2 + 160 * (i*2 + 35));\n",
    "            res.data(j + 80*i) = {if (x == 34) 0f else {if (x != 0) 1f else 0f}};\n",
    "            j += 1;\n",
    "        }\n",
    "        i += 1;\n",
    "    }\n",
    "    res\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the Q-estimator class. We use two instances of this class, one for the target estimator, and one for the Q-estimator. The Q function is normally represented as a scalar $Q(x,a)$ where $x$ is the state and $a$ is an action. For ease of implementation, we actually estimate a vector-valued function $Q(x,.)$ which returns the estimated reward for every action. The model here has just a single hidden layer:\n",
    "\n",
    "<pre>\n",
    "Input Layer (nfeats) => FC Layer => RELU => FC Layer => Output (naction values)\n",
    "</pre>\n",
    "\n",
    "## 1. Implement Q-estimator gradient\n",
    "Your first task is to implement the\n",
    "<pre>Estimator.gradient(s, a, y)</pre>\n",
    "method for this class. **gradient** should compute the gradients wrt weight arrays W1 and W2 into\n",
    "<pre>self.grad['W1']\n",
    "self.grad['W2']</pre>\n",
    "respectively. Both <code>a</code> and <code>y</code> are vectors. Be sure to update only the output layer weights corresponding to the given action vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import scala.collection.mutable.HashMap;\n",
    "\n",
    "class Estimator(ninputs:Int, nhidden:Int, nactions:Int) {\n",
    "\n",
    "//        \"\"\" Create model matrices, and gradient and squared gradient buffers\"\"\"\n",
    "    val model = new HashMap[String, FMat]();\n",
    "    val grad = new HashMap[String, FMat]();\n",
    "    val velo = new HashMap[String, FMat]();\n",
    "    val oldgrad = new HashMap[String, FMat]();\n",
    "    val gradsq = new HashMap[String, FMat]();\n",
    "    model(\"W1\") = normrnd(0,1,nhidden, ninputs) / sqrt(ninputs)   // \"Xavier\" initialization\n",
    "    model(\"W2\") = normrnd(0,1,nactions, nhidden) / sqrt(nhidden)\n",
    "    for ((k,v) <- model) {\n",
    "         grad.put(k, zeros(v.nrows, v.ncols));\n",
    "         velo.put(k, zeros(v.nrows, v.ncols));\n",
    "         oldgrad.put(k, zeros(v.nrows, v.ncols));\n",
    "         gradsq.put(k, zeros(v.nrows, v.ncols));\n",
    "    } \n",
    "\n",
    "    def forward(s:FMat):(FMat, FMat) = {\n",
    "//        \"\"\" Run the model forward given a state as input.\n",
    "//    returns action predictions and the hidden state\"\"\"\n",
    "        val h = model(\"W1\") * s\n",
    "        h ~ h *@ (h>=0)    // ReLU nonlinearity\n",
    "        val rew = model(\"W2\") * h\n",
    "        (rew, h)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    def predict(s:FMat):FMat = {\n",
    "//        \"\"\" Predict the action rewards from a given input state\"\"\"\n",
    "        val (rew, h) = forward(s)\n",
    "        rew\n",
    "    }\n",
    "    \n",
    "    var selector:IMat = irow(0->npar)*nactions\n",
    "              \n",
    "    def gradient(s:FMat, a:IMat, y:FMat):Float = {\n",
    "//        \"\"\" Given a state s, action a and target y, compute the model gradients\"\"\"\n",
    "        val (rew, h) = forward(s);\n",
    "        val dout = y - rew(a + selector);     \n",
    "        val arew = zeros(rew.nrows, rew.ncols);\n",
    "        arew(a + selector) = dout\n",
    "        \n",
    "        grad(\"W2\") ~ grad(\"W2\") + (arew *^ h);\n",
    "        val dh = model(\"W2\") ^* arew\n",
    "        dh ~ dh *@ (h > 0)\n",
    "        \n",
    "        grad(\"W1\") ~ grad(\"W1\") + (dh *^ s);\n",
    "\n",
    "        sqrt((dout dotr dout)/dout.length).v\n",
    "    }\n",
    "    \n",
    "    \n",
    "    def rmsprop2(learning_rate:Float, decay_rate:Float) = {\n",
    "//        \"\"\" Perform model updates from the gradients using RMSprop\"\"\"\n",
    "        for ((k,v) <- model) {\n",
    "            val g = grad(k);\n",
    "            gradsq(k) = decay_rate * gradsq(k) + (1 - decay_rate) * (g *@ g)\n",
    "            model(k) = model(k) + learning_rate * g / (sqrt(gradsq(k)) + 1e-5f)\n",
    "            grad(k).clear\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def rmsprop1(learning_rate:Float, decay_rate:Float) = {\n",
    "//        \"\"\" Perform model updates from the gradients using RMSprop\"\"\"\n",
    "        for ((k,v) <- model) {\n",
    "            val g = grad(k);\n",
    "            gradsq(k) = decay_rate * gradsq(k) + (1 - decay_rate) * (g *@ g)\n",
    "            model(k) = model(k) + learning_rate * g / (gradsq(k) + 1e-4f)\n",
    "            grad(k).clear\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def rmsprop(learning_rate:Float, decay_rate:Float) = {\n",
    "//        \"\"\" Perform model updates from the gradients using RMSprop\"\"\"\n",
    "        for ((k,v) <- model) {\n",
    "            val g = grad(k).data;\n",
    "            val gsq = gradsq(k).data;\n",
    "            val m = model(k).data;\n",
    "            val len = grad(k).length;\n",
    "            var i = 0;\n",
    "            while (i < len) {\n",
    "                val gi = math.min(gclip, math.max(-gclip, g(i)));\n",
    "                gsq(i) = decay_rate * gsq(i) + (1-decay_rate) * gi * gi;\n",
    "                m(i) += learning_rate * gi / (gsq(i) + rmseps);\n",
    "                g(i) = 0;             \n",
    "                i += 1;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def simple_grad(learning_rate:Float, decay_rate:Float) = {\n",
    "//        \"\"\" Perform model updates from the gradients using RMSprop\"\"\"\n",
    "        for ((k,v) <- model) {\n",
    "            val g = grad(k).data;\n",
    "            val m = model(k).data;\n",
    "            val len = grad(k).length;\n",
    "            var i = 0;\n",
    "            while (i < len) {\n",
    "                val gi = math.min(gclip, math.max(-gclip, g(i)));\n",
    "                m(i) += learning_rate * gi\n",
    "                g(i) = 0;             \n",
    "                i += 1;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def adam(learning_rate:Float, gsq_decay:Float, momentum_decay:Float) = {\n",
    "//        \"\"\" Perform model updates from the gradients using RMSprop\"\"\"\n",
    "        for ((k,v) <- model) {\n",
    "            val g = grad(k).data;\n",
    "            val v = velo(k).data;\n",
    "            val gsq = gradsq(k).data;\n",
    "            val m = model(k).data;\n",
    "            val len = grad(k).length;\n",
    "            var i = 0;\n",
    "            while (i < len) {\n",
    "                val gi = math.min(gclip, math.max(-gclip, g(i)));\n",
    "                v(i) = momentum_decay * v(i) + (1-momentum_decay) * gi;\n",
    "                gsq(i) = gsq_decay * gsq(i) + (1-gsq_decay) * gi * gi;\n",
    "                m(i) += learning_rate * gi / (gsq(i) + rmseps);\n",
    "                g(i) = 0;             \n",
    "                i += 1;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement $\\epsilon$-Greedy Policy\n",
    "\n",
    "An $\\epsilon$-Greedy policy should:\n",
    "* with probability $\\epsilon$ take a uniformly-random action.\n",
    "* otherwise choose the best action according to the estimator from the given state.\n",
    "\n",
    "The function below should implement this policy. For each input state, it should return a (column) vector of size nactions which are the probabilities of taking each action. Thus, the probabilities of non-optimal actions should be $\\epsilon/{\\rm nactions}$ and the probability of the best action should be $1-\\epsilon+\\epsilon/{\\rm nactions}$.\n",
    "\n",
    "Since the function processes batches of states, the input <code>state</code> is a <code>nfeatures x nbatch</code> matrix, and the returned value should be a <code>nactions x nbatch</code> matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "val aselector = irow(0->npar)*nactions\n",
    "\n",
    "def policy(estimator:Estimator, state:FMat, epsilon:Float):FMat = {\n",
    "//    \"\"\" Take an estimator and state and predict the best action.\n",
    "//    For each input state, return a vector of action probabilities according to an epsilon-greedy policy\"\"\"\n",
    "    val A = ones(nactions, npar) * (epsilon / nactions)\n",
    "    val q_values = estimator.predict(state)\n",
    "    val (_,best_action) = maxi2(q_values)\n",
    "    A(best_action + aselector) = A(best_action + aselector) + (1f - epsilon)\n",
    "    A\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This routine copies the state of one estimator into another. Its used to update the target estimator from the Q-estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def update_estimator(to_estimator:Estimator, from_estimator:Estimator, window:Int, istep:Int) = {\n",
    "//    \"\"\" every <window> steps, Copy model state from from_estimator into to_estimator\"\"\"\n",
    "    if (istep % window == 0) {\n",
    "        for ((k,v) <- from_estimator.model) {\n",
    "            to_estimator.model(k) <-- from_estimator.model(k);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement \"Asynchronous Threads\"\n",
    "\n",
    "Don't try that in Python!! Actually all we do here is create an array of environments and advance each one a random number of steps, using random actions at each step. Later on we will make *synchronous* updates to all the environments, but the environments (and their gradient updates) should remain uncorrelated. This serves the same goal as asynchronous updates in paper [2], or experience replay in paper [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing games...90123 steps, 73 epochs in 109.9990 seconds at 1.2205 msecs/step\n"
     ]
    }
   ],
   "source": [
    "// Create estimators\n",
    "val q_estimator = new Estimator(nfeats*nwindow, nhidden, nactions)\n",
    "val target_estimator = new Estimator(nfeats*nwindow, nhidden, nactions)\n",
    "\n",
    "// The epsilon and learning rate decay schedules\n",
    "// val epsilons = np.linspace(epsilon_start, epsilon_end, neps)\n",
    "val epsilons = epsilon_start / (1f + row(0->neps)/(neps*epsilon_end/epsilon_start))\n",
    "val learning_rates = learning_rate - row(0 -> nlr) * ((lr_end - learning_rate) / nlr)\n",
    "\n",
    "// Initialize the games\n",
    "print(\"Initializing games...\")\n",
    "val envs = new Array[ALE](npar)\n",
    "val state = zeros(nfeats * nwindow, npar)\n",
    "var total_time=0f\n",
    "var total_steps=0\n",
    "var total_epochs = 0\n",
    "\n",
    "import java.util.Random\n",
    "val rn = new Random\n",
    "\n",
    "tic\n",
    "for (i <- 0 until npar) {\n",
    "    envs(i) = new ALE\n",
    "    envs(i).setInt(\"random_seed\", i)\n",
    "    envs(i).loadROM(game_bin)\n",
    "\n",
    "    val nmoves = rn.nextInt(init_moves - nwindow) + nwindow\n",
    "    for (j <- 0 until nmoves) {   \n",
    "        val action = VALID_ACTIONS(rn.nextInt(nactions))\n",
    "        val (obs, reward, done) = envs(i).step(action)\n",
    "        total_steps += 1;\n",
    "        if (nmoves - j <= nwindow) {\n",
    "            val k = nwindow - nmoves + j;\n",
    "            state((k*nfeats)->((k+1)*nfeats), i) = preprocess(obs)\n",
    "        }\n",
    "        if (done) {\n",
    "            envs(i).reset() \n",
    "            total_epochs += 1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "total_time = toc     \n",
    "println(\"%d steps, %d epochs in %5.4f seconds at %5.4f msecs/step\" format(\n",
    "    total_steps, total_epochs, total_time, 1000f*total_time/total_steps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select integer actions using the probability distribution in each column of <code>probs</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def random_choices(probs:FMat):IMat = {\n",
    "    val result = izeros(1, probs.ncols);\n",
    "    var i = 0;\n",
    "    while (i < probs.ncols) {\n",
    "        val r = rn.nextFloat();\n",
    "        var j = 0;\n",
    "        var cumprob = probs(0, i);\n",
    "        while (r > cumprob && j+1 < probs.length) {\n",
    "            j += 1;\n",
    "            cumprob += probs(j, i);\n",
    "        }\n",
    "        result(i) = j;\n",
    "        i += 1\n",
    "    }\n",
    "    result\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement Deep Q-Learning\n",
    "In this cell you actually implement the algorithm. We've given you comments to define all the steps. You should also add book-keeping steps to keep track of the loss, reward and number of epochs (where env.step() returns done = true). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, time 0.1, loss 0.00000629, epochs 0, reward/epoch 0.00000, cum reward/epoch 0.00000\n",
      "step 10000, time 196.9, loss 0.10600276, epochs 129, reward/epoch -20.28682, cum reward/epoch -20.28682\n",
      "step 20000, time 413.3, loss 0.08713018, epochs 250, reward/epoch -20.28926, cum reward/epoch -20.28800\n",
      "step 30000, time 635.6, loss 0.08261964, epochs 357, reward/epoch -20.12150, cum reward/epoch -20.23809\n",
      "step 40000, time 860.1, loss 0.08161884, epochs 458, reward/epoch -19.18812, cum reward/epoch -20.00655\n",
      "step 50000, time 1090.4, loss 0.07892536, epochs 557, reward/epoch -19.11111, cum reward/epoch -19.84740\n",
      "step 60000, time 1321.1, loss 0.08794859, epochs 648, reward/epoch -19.16483, cum reward/epoch -19.75154\n",
      "step 70000, time 1552.5, loss 0.08260289, epochs 740, reward/epoch -18.63043, cum reward/epoch -19.61216\n",
      "step 80000, time 1790.9, loss 0.07963189, epochs 823, reward/epoch -18.51807, cum reward/epoch -19.50182\n",
      "step 90000, time 2040.3, loss 0.08101470, epochs 903, reward/epoch -19.71250, cum reward/epoch -19.52049\n",
      "step 100000, time 2293.8, loss 0.08129574, epochs 986, reward/epoch -18.49398, cum reward/epoch -19.43408\n",
      "step 110000, time 2548.3, loss 0.08007074, epochs 1065, reward/epoch -19.03798, cum reward/epoch -19.40470\n",
      "step 120000, time 2803.1, loss 0.07856327, epochs 1140, reward/epoch -18.66667, cum reward/epoch -19.35614\n",
      "step 130000, time 3057.2, loss 0.08027526, epochs 1217, reward/epoch -17.67533, cum reward/epoch -19.24979\n",
      "step 140000, time 3281.4, loss 0.08053379, epochs 1290, reward/epoch -18.72603, cum reward/epoch -19.22016\n",
      "step 150000, time 3537.6, loss 0.07966112, epochs 1360, reward/epoch -18.55714, cum reward/epoch -19.18603\n",
      "step 160000, time 3797.8, loss 0.07802532, epochs 1433, reward/epoch -17.94521, cum reward/epoch -19.12282\n",
      "step 170000, time 4060.0, loss 0.07650679, epochs 1502, reward/epoch -18.52174, cum reward/epoch -19.09521\n",
      "step 180000, time 4318.2, loss 0.07849326, epochs 1572, reward/epoch -17.75714, cum reward/epoch -19.03562\n",
      "step 190000, time 4537.3, loss 0.07632902, epochs 1641, reward/epoch -17.97101, cum reward/epoch -18.99086\n",
      "step 200000, time 4756.1, loss 0.07661106, epochs 1703, reward/epoch -18.48387, cum reward/epoch -18.97240\n",
      "step 210000, time 4974.9, loss 0.07585177, epochs 1767, reward/epoch -18.70313, cum reward/epoch -18.96265\n",
      "step 220000, time 5194.3, loss 0.07451060, epochs 1837, reward/epoch -18.27143, cum reward/epoch -18.93631\n",
      "step 230000, time 5414.7, loss 0.07375654, epochs 1902, reward/epoch -17.06154, cum reward/epoch -18.87224\n",
      "step 240000, time 5635.4, loss 0.07332321, epochs 1962, reward/epoch -17.60000, cum reward/epoch -18.83333\n",
      "step 250000, time 5856.8, loss 0.07307559, epochs 2025, reward/epoch -17.11111, cum reward/epoch -18.77975\n",
      "step 260000, time 6077.6, loss 0.07485896, epochs 2084, reward/epoch -17.59322, cum reward/epoch -18.74616\n",
      "step 270000, time 6298.6, loss 0.07331425, epochs 2142, reward/epoch -18.00000, cum reward/epoch -18.72596\n",
      "step 280000, time 6520.4, loss 0.07349478, epochs 2204, reward/epoch -17.51613, cum reward/epoch -18.69192\n",
      "step 290000, time 6742.8, loss 0.07186189, epochs 2263, reward/epoch -17.45763, cum reward/epoch -18.65974\n",
      "step 300000, time 6965.2, loss 0.07295857, epochs 2324, reward/epoch -17.86885, cum reward/epoch -18.63898\n",
      "step 310000, time 7188.1, loss 0.06960708, epochs 2382, reward/epoch -18.53448, cum reward/epoch -18.63644\n",
      "step 320000, time 7411.5, loss 0.07065141, epochs 2445, reward/epoch -16.00000, cum reward/epoch -18.56851\n",
      "step 330000, time 7634.9, loss 0.06981815, epochs 2501, reward/epoch -18.42857, cum reward/epoch -18.56537\n",
      "step 340000, time 7857.8, loss 0.06992274, epochs 2565, reward/epoch -16.79688, cum reward/epoch -18.52125\n",
      "step 350000, time 8081.9, loss 0.06858852, epochs 2619, reward/epoch -18.51852, cum reward/epoch -18.52119\n",
      "step 360000, time 8306.1, loss 0.06892727, epochs 2681, reward/epoch -18.27419, cum reward/epoch -18.51548\n",
      "step 370000, time 8531.0, loss 0.06898618, epochs 2741, reward/epoch -16.16667, cum reward/epoch -18.46406\n",
      "step 380000, time 8755.5, loss 0.07048591, epochs 2797, reward/epoch -17.03572, cum reward/epoch -18.43547\n",
      "step 390000, time 8980.7, loss 0.06842633, epochs 2849, reward/epoch -18.00000, cum reward/epoch -18.42752\n",
      "step 400000, time 9205.6, loss 0.06924471, epochs 2903, reward/epoch -16.68518, cum reward/epoch -18.39511\n",
      "step 410000, time 9431.5, loss 0.06996377, epochs 2955, reward/epoch -16.05769, cum reward/epoch -18.35398\n",
      "step 420000, time 9658.2, loss 0.06864190, epochs 3007, reward/epoch -16.19231, cum reward/epoch -18.31660\n",
      "step 430000, time 9883.6, loss 0.06880444, epochs 3061, reward/epoch -16.51852, cum reward/epoch -18.28487\n",
      "step 440000, time 10109.6, loss 0.06735579, epochs 3108, reward/epoch -16.38298, cum reward/epoch -18.25611\n",
      "step 450000, time 10335.5, loss 0.06691077, epochs 3161, reward/epoch -16.41509, cum reward/epoch -18.22524\n",
      "step 460000, time 10561.7, loss 0.06694885, epochs 3213, reward/epoch -16.67308, cum reward/epoch -18.20012\n",
      "step 470000, time 10788.3, loss 0.06622603, epochs 3265, reward/epoch -17.25000, cum reward/epoch -18.18499\n",
      "step 480000, time 11015.7, loss 0.06637952, epochs 3317, reward/epoch -16.05769, cum reward/epoch -18.15164\n",
      "step 490000, time 11243.2, loss 0.06575787, epochs 3365, reward/epoch -17.14583, cum reward/epoch -18.13729\n",
      "step 500000, time 11473.5, loss 0.06487142, epochs 3417, reward/epoch -16.71154, cum reward/epoch -18.11560\n",
      "step 510000, time 11731.1, loss 0.06523324, epochs 3465, reward/epoch -16.58333, cum reward/epoch -18.09437\n",
      "step 520000, time 12000.5, loss 0.06444579, epochs 3514, reward/epoch -16.93878, cum reward/epoch -18.07826\n",
      "step 530000, time 12271.9, loss 0.06400990, epochs 3564, reward/epoch -15.70000, cum reward/epoch -18.04489\n",
      "step 540000, time 12541.2, loss 0.06413054, epochs 3609, reward/epoch -16.82222, cum reward/epoch -18.02965\n",
      "step 550000, time 12811.4, loss 0.06421204, epochs 3655, reward/epoch -16.23913, cum reward/epoch -18.00711\n",
      "step 560000, time 13081.8, loss 0.06542765, epochs 3705, reward/epoch -15.76000, cum reward/epoch -17.97679\n",
      "step 570000, time 13354.4, loss 0.06460677, epochs 3755, reward/epoch -15.86000, cum reward/epoch -17.94860\n",
      "step 580000, time 13627.7, loss 0.06517996, epochs 3805, reward/epoch -17.06000, cum reward/epoch -17.93693\n",
      "step 590000, time 13900.1, loss 0.06340646, epochs 3847, reward/epoch -16.76191, cum reward/epoch -17.92410\n",
      "step 600000, time 14172.6, loss 0.06332227, epochs 3890, reward/epoch -15.37209, cum reward/epoch -17.89589\n",
      "step 610000, time 14446.8, loss 0.06465512, epochs 3938, reward/epoch -16.06250, cum reward/epoch -17.87354\n",
      "step 620000, time 14718.4, loss 0.06236235, epochs 3981, reward/epoch -17.97674, cum reward/epoch -17.87465\n",
      "step 630000, time 14992.5, loss 0.06384163, epochs 4034, reward/epoch -16.07547, cum reward/epoch -17.85102\n",
      "step 640000, time 15265.2, loss 0.06408759, epochs 4082, reward/epoch -16.56250, cum reward/epoch -17.83587\n",
      "step 650000, time 15535.2, loss 0.06205625, epochs 4126, reward/epoch -15.95455, cum reward/epoch -17.81580\n",
      "step 660000, time 15806.7, loss 0.06358779, epochs 4174, reward/epoch -16.06250, cum reward/epoch -17.79564\n",
      "step 670000, time 16079.1, loss 0.06212028, epochs 4220, reward/epoch -17.63043, cum reward/epoch -17.79384\n",
      "step 680000, time 16351.8, loss 0.06110275, epochs 4265, reward/epoch -15.71111, cum reward/epoch -17.77186\n",
      "step 690000, time 16624.2, loss 0.06183519, epochs 4311, reward/epoch -16.50000, cum reward/epoch -17.75829\n",
      "step 700000, time 16895.7, loss 0.06264454, epochs 4357, reward/epoch -16.34783, cum reward/epoch -17.74340\n",
      "step 710000, time 17167.4, loss 0.06073610, epochs 4399, reward/epoch -16.14286, cum reward/epoch -17.72812\n",
      "step 720000, time 17440.3, loss 0.06201926, epochs 4442, reward/epoch -15.62791, cum reward/epoch -17.70779\n",
      "step 730000, time 17714.2, loss 0.06151616, epochs 4484, reward/epoch -15.57143, cum reward/epoch -17.68778\n",
      "step 740000, time 17986.7, loss 0.06090856, epochs 4524, reward/epoch -15.07500, cum reward/epoch -17.66468\n",
      "step 750000, time 18258.3, loss 0.06332278, epochs 4574, reward/epoch -16.22000, cum reward/epoch -17.64889\n",
      "step 760000, time 18532.7, loss 0.06059074, epochs 4612, reward/epoch -16.60526, cum reward/epoch -17.64029\n",
      "step 770000, time 18806.7, loss 0.06157489, epochs 4655, reward/epoch -16.18605, cum reward/epoch -17.62685\n",
      "step 780000, time 19079.5, loss 0.06095951, epochs 4695, reward/epoch -13.75000, cum reward/epoch -17.59382\n",
      "step 790000, time 19353.1, loss 0.06071630, epochs 4739, reward/epoch -15.18182, cum reward/epoch -17.57143\n",
      "step 800000, time 19625.0, loss 0.06091577, epochs 4783, reward/epoch -16.34091, cum reward/epoch -17.56011\n",
      "step 810000, time 19897.4, loss 0.06028337, epochs 4825, reward/epoch -16.83333, cum reward/epoch -17.55378\n",
      "step 820000, time 20171.1, loss 0.06005472, epochs 4868, reward/epoch -15.88372, cum reward/epoch -17.53903\n",
      "step 830000, time 20445.9, loss 0.05951725, epochs 4911, reward/epoch -14.88372, cum reward/epoch -17.51578\n",
      "step 840000, time 20720.1, loss 0.06034080, epochs 4952, reward/epoch -14.90244, cum reward/epoch -17.49414\n",
      "step 850000, time 20993.8, loss 0.05919190, epochs 4990, reward/epoch -17.28947, cum reward/epoch -17.49258\n",
      "step 860000, time 21270.2, loss 0.05976214, epochs 5033, reward/epoch -15.18605, cum reward/epoch -17.47288\n",
      "step 870000, time 21544.5, loss 0.05973937, epochs 5073, reward/epoch -17.15000, cum reward/epoch -17.47033\n",
      "step 880000, time 21818.2, loss 0.05848039, epochs 5113, reward/epoch -14.67500, cum reward/epoch -17.44847\n",
      "step 890000, time 22094.1, loss 0.05982956, epochs 5152, reward/epoch -15.56410, cum reward/epoch -17.43420\n",
      "step 900000, time 22369.0, loss 0.06034862, epochs 5194, reward/epoch -15.83333, cum reward/epoch -17.42126\n",
      "step 910000, time 22645.3, loss 0.05910847, epochs 5237, reward/epoch -15.06977, cum reward/epoch -17.40195\n",
      "step 920000, time 22921.5, loss 0.06120116, epochs 5281, reward/epoch -14.93182, cum reward/epoch -17.38137\n",
      "step 930000, time 23196.9, loss 0.06047951, epochs 5325, reward/epoch -17.40909, cum reward/epoch -17.38160\n",
      "step 940000, time 23473.9, loss 0.05829686, epochs 5366, reward/epoch -16.36585, cum reward/epoch -17.37383\n",
      "step 950000, time 23751.8, loss 0.05857525, epochs 5408, reward/epoch -14.88095, cum reward/epoch -17.35448\n",
      "step 960000, time 24028.0, loss 0.05900483, epochs 5447, reward/epoch -14.84615, cum reward/epoch -17.33652\n",
      "step 970000, time 24303.0, loss 0.05927866, epochs 5489, reward/epoch -14.69048, cum reward/epoch -17.31627\n",
      "step 980000, time 24578.9, loss 0.05847426, epochs 5526, reward/epoch -16.21622, cum reward/epoch -17.30890\n",
      "step 990000, time 24854.2, loss 0.05818640, epochs 5568, reward/epoch -14.28571, cum reward/epoch -17.28610\n",
      "step 1000000, time 25129.8, loss 0.05849950, epochs 5609, reward/epoch -15.87805, cum reward/epoch -17.27581\n",
      "step 1010000, time 25407.0, loss 0.06035537, epochs 5650, reward/epoch -15.58537, cum reward/epoch -17.26354\n",
      "step 1020000, time 25683.9, loss 0.05921601, epochs 5691, reward/epoch -15.36585, cum reward/epoch -17.24987\n",
      "step 1030000, time 25960.7, loss 0.05985269, epochs 5734, reward/epoch -15.65116, cum reward/epoch -17.23788\n",
      "step 1040000, time 26239.3, loss 0.05890598, epochs 5773, reward/epoch -15.05128, cum reward/epoch -17.22311\n",
      "step 1050000, time 26515.8, loss 0.05926384, epochs 5814, reward/epoch -15.17073, cum reward/epoch -17.20863\n",
      "step 1060000, time 26792.6, loss 0.06026237, epochs 5855, reward/epoch -14.34146, cum reward/epoch -17.18856\n",
      "step 1070000, time 27068.6, loss 0.05942855, epochs 5892, reward/epoch -13.91892, cum reward/epoch -17.16802\n",
      "step 1080000, time 27345.8, loss 0.05899197, epochs 5928, reward/epoch -15.25000, cum reward/epoch -17.15638\n",
      "step 1090000, time 27623.6, loss 0.05795319, epochs 5965, reward/epoch -15.08108, cum reward/epoch -17.14350\n",
      "step 1100000, time 27902.2, loss 0.05894927, epochs 6004, reward/epoch -14.33333, cum reward/epoch -17.12525\n",
      "step 1110000, time 28180.8, loss 0.05946103, epochs 6047, reward/epoch -13.53488, cum reward/epoch -17.09972\n",
      "step 1120000, time 28458.9, loss 0.05918239, epochs 6084, reward/epoch -15.13513, cum reward/epoch -17.08777\n",
      "step 1130000, time 28737.4, loss 0.05973041, epochs 6123, reward/epoch -13.58974, cum reward/epoch -17.06549\n",
      "step 1140000, time 29016.3, loss 0.05794341, epochs 6161, reward/epoch -13.68421, cum reward/epoch -17.04464\n",
      "step 1150000, time 29295.7, loss 0.05634484, epochs 6196, reward/epoch -16.97143, cum reward/epoch -17.04422\n",
      "step 1160000, time 29574.7, loss 0.05725534, epochs 6236, reward/epoch -14.02500, cum reward/epoch -17.02486\n",
      "step 1170000, time 29853.6, loss 0.05714355, epochs 6272, reward/epoch -15.83333, cum reward/epoch -17.01802\n",
      "step 1180000, time 30133.3, loss 0.05643087, epochs 6310, reward/epoch -15.31579, cum reward/epoch -17.00776\n",
      "step 1190000, time 30411.8, loss 0.05748234, epochs 6345, reward/epoch -14.17143, cum reward/epoch -16.99212\n",
      "step 1200000, time 30691.4, loss 0.06043625, epochs 6391, reward/epoch -15.36957, cum reward/epoch -16.98044\n",
      "step 1210000, time 30938.3, loss 0.05936879, epochs 6433, reward/epoch -13.85714, cum reward/epoch -16.96005\n",
      "step 1220000, time 31175.3, loss 0.05860220, epochs 6471, reward/epoch -13.52632, cum reward/epoch -16.93989\n",
      "step 1230000, time 31411.8, loss 0.05797068, epochs 6509, reward/epoch -15.28947, cum reward/epoch -16.93025\n",
      "step 1240000, time 31648.5, loss 0.05698593, epochs 6546, reward/epoch -12.54054, cum reward/epoch -16.90544\n",
      "step 1250000, time 31885.9, loss 0.05726579, epochs 6582, reward/epoch -13.19444, cum reward/epoch -16.88514\n",
      "step 1260000, time 32122.2, loss 0.05859860, epochs 6617, reward/epoch -14.71429, cum reward/epoch -16.87366\n",
      "step 1270000, time 32360.2, loss 0.05901172, epochs 6655, reward/epoch -12.86842, cum reward/epoch -16.85079\n",
      "step 1280000, time 32597.2, loss 0.05664793, epochs 6690, reward/epoch -13.94286, cum reward/epoch -16.83558\n",
      "step 1290000, time 32834.3, loss 0.05872320, epochs 6729, reward/epoch -14.84615, cum reward/epoch -16.82405\n",
      "step 1300000, time 33071.9, loss 0.05602916, epochs 6764, reward/epoch -13.20000, cum reward/epoch -16.80529\n",
      "step 1310000, time 33310.0, loss 0.05699221, epochs 6799, reward/epoch -15.91429, cum reward/epoch -16.80071\n",
      "step 1320000, time 33548.3, loss 0.05673993, epochs 6835, reward/epoch -12.75000, cum reward/epoch -16.77937\n",
      "step 1330000, time 33786.2, loss 0.05717928, epochs 6873, reward/epoch -13.71053, cum reward/epoch -16.76240\n",
      "step 1340000, time 34025.3, loss 0.05640000, epochs 6911, reward/epoch -13.52632, cum reward/epoch -16.74461\n",
      "step 1350000, time 34263.8, loss 0.05642982, epochs 6945, reward/epoch -13.55882, cum reward/epoch -16.72901\n",
      "step 1360000, time 34501.2, loss 0.05745385, epochs 6980, reward/epoch -13.51429, cum reward/epoch -16.71289\n",
      "step 1370000, time 34739.5, loss 0.05687329, epochs 7011, reward/epoch -12.77419, cum reward/epoch -16.69548\n",
      "step 1380000, time 34977.2, loss 0.05735907, epochs 7050, reward/epoch -13.23077, cum reward/epoch -16.67631\n",
      "step 1390000, time 35214.8, loss 0.05668154, epochs 7083, reward/epoch -12.57576, cum reward/epoch -16.65721\n",
      "step 1400000, time 35452.8, loss 0.05670765, epochs 7115, reward/epoch -13.34375, cum reward/epoch -16.64231\n",
      "step 1410000, time 35690.1, loss 0.05737503, epochs 7150, reward/epoch -11.80000, cum reward/epoch -16.61860\n",
      "step 1420000, time 35927.8, loss 0.05826195, epochs 7184, reward/epoch -14.14706, cum reward/epoch -16.60690\n",
      "step 1430000, time 36164.6, loss 0.05744193, epochs 7224, reward/epoch -12.62500, cum reward/epoch -16.58486\n",
      "step 1440000, time 36402.2, loss 0.05793164, epochs 7256, reward/epoch -15.50000, cum reward/epoch -16.58007\n",
      "step 1450000, time 36640.3, loss 0.05954166, epochs 7295, reward/epoch -13.46154, cum reward/epoch -16.56340\n",
      "step 1460000, time 36878.1, loss 0.05593873, epochs 7330, reward/epoch -13.37143, cum reward/epoch -16.54816\n",
      "step 1470000, time 37117.1, loss 0.05622805, epochs 7363, reward/epoch -13.30303, cum reward/epoch -16.53361\n",
      "step 1480000, time 37355.2, loss 0.05588691, epochs 7396, reward/epoch -11.84848, cum reward/epoch -16.51271\n",
      "step 1490000, time 37593.1, loss 0.05732537, epochs 7428, reward/epoch -15.06250, cum reward/epoch -16.50646\n",
      "step 1500000, time 37831.1, loss 0.05592898, epochs 7459, reward/epoch -12.16129, cum reward/epoch -16.48840\n",
      "step 1510000, time 38068.6, loss 0.05527528, epochs 7492, reward/epoch -12.18182, cum reward/epoch -16.46943\n",
      "step 1520000, time 38307.1, loss 0.05765097, epochs 7526, reward/epoch -12.29412, cum reward/epoch -16.45057\n",
      "step 1530000, time 38545.6, loss 0.05689963, epochs 7556, reward/epoch -12.73333, cum reward/epoch -16.43581\n",
      "step 1540000, time 38784.0, loss 0.05575268, epochs 7585, reward/epoch -9.86207, cum reward/epoch -16.41068\n",
      "step 1550000, time 39023.3, loss 0.05688694, epochs 7618, reward/epoch -11.27273, cum reward/epoch -16.38842\n",
      "step 1560000, time 39261.7, loss 0.05535771, epochs 7654, reward/epoch -11.33333, cum reward/epoch -16.36465\n",
      "step 1570000, time 39500.2, loss 0.05661060, epochs 7686, reward/epoch -13.96875, cum reward/epoch -16.35467\n",
      "step 1580000, time 39738.4, loss 0.05614262, epochs 7718, reward/epoch -11.46875, cum reward/epoch -16.33441\n",
      "step 1590000, time 39976.9, loss 0.05808684, epochs 7750, reward/epoch -11.12500, cum reward/epoch -16.31290\n",
      "step 1600000, time 40215.9, loss 0.05673317, epochs 7787, reward/epoch -11.02703, cum reward/epoch -16.28779\n",
      "step 1610000, time 40454.9, loss 0.05580037, epochs 7819, reward/epoch -13.62500, cum reward/epoch -16.27689\n",
      "step 1620000, time 40693.5, loss 0.05670621, epochs 7852, reward/epoch -10.30303, cum reward/epoch -16.25178\n",
      "step 1630000, time 40931.5, loss 0.05733167, epochs 7883, reward/epoch -12.48387, cum reward/epoch -16.23697\n",
      "step 1640000, time 41170.4, loss 0.05563084, epochs 7915, reward/epoch -11.06250, cum reward/epoch -16.21605\n",
      "step 1650000, time 41409.9, loss 0.05640936, epochs 7948, reward/epoch -11.12121, cum reward/epoch -16.19489\n",
      "step 1660000, time 41649.0, loss 0.05778094, epochs 7983, reward/epoch -11.85714, cum reward/epoch -16.17587\n",
      "step 1670000, time 41887.5, loss 0.05620459, epochs 8013, reward/epoch -11.16667, cum reward/epoch -16.15712\n",
      "step 1680000, time 42127.6, loss 0.05563097, epochs 8042, reward/epoch -11.17241, cum reward/epoch -16.13914\n",
      "step 1690000, time 42366.4, loss 0.05601602, epochs 8069, reward/epoch -10.66667, cum reward/epoch -16.12083\n",
      "step 1700000, time 42605.5, loss 0.05724050, epochs 8100, reward/epoch -10.03226, cum reward/epoch -16.09753\n",
      "step 1710000, time 42845.5, loss 0.05597380, epochs 8134, reward/epoch -9.97059, cum reward/epoch -16.07192\n",
      "step 1720000, time 43084.0, loss 0.05645388, epochs 8167, reward/epoch -11.96970, cum reward/epoch -16.05535\n",
      "step 1730000, time 43323.1, loss 0.05653548, epochs 8200, reward/epoch -12.48485, cum reward/epoch -16.04098\n",
      "step 1740000, time 43563.0, loss 0.05631655, epochs 8232, reward/epoch -12.87500, cum reward/epoch -16.02867\n",
      "step 1750000, time 43802.3, loss 0.05757442, epochs 8266, reward/epoch -11.94118, cum reward/epoch -16.01186\n",
      "step 1760000, time 44041.5, loss 0.05573925, epochs 8296, reward/epoch -9.76667, cum reward/epoch -15.98927\n",
      "step 1770000, time 44280.9, loss 0.05700560, epochs 8325, reward/epoch -10.00000, cum reward/epoch -15.96841\n",
      "step 1780000, time 44520.7, loss 0.05563240, epochs 8356, reward/epoch -10.35484, cum reward/epoch -15.94758\n",
      "step 1790000, time 44759.9, loss 0.05622274, epochs 8385, reward/epoch -11.20690, cum reward/epoch -15.93119\n",
      "step 1800000, time 44999.1, loss 0.05583071, epochs 8417, reward/epoch -12.62500, cum reward/epoch -15.91862\n",
      "step 1810000, time 45238.5, loss 0.05432492, epochs 8447, reward/epoch -10.83333, cum reward/epoch -15.90056\n",
      "step 1820000, time 45478.1, loss 0.05455966, epochs 8477, reward/epoch -9.96667, cum reward/epoch -15.87956\n",
      "step 1830000, time 45718.2, loss 0.05520910, epochs 8508, reward/epoch -12.16129, cum reward/epoch -15.86601\n",
      "step 1840000, time 45957.8, loss 0.05481364, epochs 8541, reward/epoch -11.54545, cum reward/epoch -15.84931\n",
      "step 1850000, time 46198.0, loss 0.05574761, epochs 8571, reward/epoch -12.40000, cum reward/epoch -15.83724\n",
      "step 1860000, time 46437.2, loss 0.05455866, epochs 8599, reward/epoch -10.92857, cum reward/epoch -15.82126\n",
      "step 1870000, time 46678.0, loss 0.05572059, epochs 8628, reward/epoch -9.37931, cum reward/epoch -15.79961\n",
      "step 1880000, time 46918.1, loss 0.05730461, epochs 8658, reward/epoch -11.33333, cum reward/epoch -15.78413\n",
      "step 1890000, time 47158.6, loss 0.05635450, epochs 8688, reward/epoch -10.40000, cum reward/epoch -15.76554\n",
      "step 1900000, time 47398.7, loss 0.05644375, epochs 8719, reward/epoch -9.83871, cum reward/epoch -15.74447\n",
      "step 1910000, time 47638.6, loss 0.05551402, epochs 8749, reward/epoch -11.06667, cum reward/epoch -15.72843\n",
      "step 1920000, time 47878.7, loss 0.05414741, epochs 8779, reward/epoch -12.23333, cum reward/epoch -15.71648\n",
      "step 1930000, time 48118.6, loss 0.05405239, epochs 8807, reward/epoch -11.25000, cum reward/epoch -15.70228\n",
      "step 1940000, time 48358.5, loss 0.05458425, epochs 8839, reward/epoch -10.00000, cum reward/epoch -15.68164\n",
      "step 1950000, time 48598.7, loss 0.05533643, epochs 8870, reward/epoch -10.35484, cum reward/epoch -15.66302\n",
      "step 1960000, time 48838.4, loss 0.05647221, epochs 8902, reward/epoch -10.84375, cum reward/epoch -15.64570\n",
      "step 1970000, time 49078.0, loss 0.05387247, epochs 8925, reward/epoch -10.78261, cum reward/epoch -15.63317\n",
      "step 1980000, time 49317.8, loss 0.05428112, epochs 8956, reward/epoch -8.90323, cum reward/epoch -15.60987\n",
      "step 1990000, time 49558.5, loss 0.05610551, epochs 8986, reward/epoch -12.70000, cum reward/epoch -15.60016\n",
      "step 2000000, time 49798.2, loss 0.05428749, epochs 9016, reward/epoch -9.23333, cum reward/epoch -15.57897\n",
      "step 2010000, time 50038.8, loss 0.05488467, epochs 9043, reward/epoch -7.96296, cum reward/epoch -15.55623\n",
      "step 2020000, time 50279.5, loss 0.05515727, epochs 9070, reward/epoch -8.29630, cum reward/epoch -15.53462\n",
      "step 2030000, time 50519.5, loss 0.05534493, epochs 9100, reward/epoch -9.63333, cum reward/epoch -15.51516\n",
      "step 2040000, time 50760.3, loss 0.05577314, epochs 9130, reward/epoch -10.80000, cum reward/epoch -15.49967\n",
      "step 2050000, time 51000.3, loss 0.05416603, epochs 9159, reward/epoch -8.86207, cum reward/epoch -15.47865\n",
      "step 2060000, time 51241.2, loss 0.05532897, epochs 9189, reward/epoch -9.80000, cum reward/epoch -15.46012\n",
      "step 2070000, time 51481.1, loss 0.05621114, epochs 9216, reward/epoch -8.92593, cum reward/epoch -15.44097\n",
      "step 2080000, time 51721.4, loss 0.05706171, epochs 9246, reward/epoch -7.96667, cum reward/epoch -15.41672\n",
      "step 2090000, time 51961.3, loss 0.05371925, epochs 9275, reward/epoch -9.72414, cum reward/epoch -15.39892\n",
      "step 2100000, time 52201.6, loss 0.05419509, epochs 9303, reward/epoch -8.92857, cum reward/epoch -15.37945\n",
      "step 2110000, time 52442.5, loss 0.05470039, epochs 9328, reward/epoch -7.08000, cum reward/epoch -15.35720\n",
      "step 2120000, time 52683.6, loss 0.05435972, epochs 9356, reward/epoch -7.60714, cum reward/epoch -15.33401\n",
      "step 2130000, time 52923.7, loss 0.05420873, epochs 9382, reward/epoch -7.92308, cum reward/epoch -15.31347\n",
      "step 2140000, time 53164.2, loss 0.05565799, epochs 9408, reward/epoch -6.73077, cum reward/epoch -15.28975\n",
      "step 2150000, time 53404.7, loss 0.05663242, epochs 9436, reward/epoch -7.75000, cum reward/epoch -15.26738\n",
      "step 2160000, time 53644.5, loss 0.05551774, epochs 9464, reward/epoch -9.71429, cum reward/epoch -15.25095\n",
      "step 2170000, time 53884.8, loss 0.05525121, epochs 9493, reward/epoch -6.13793, cum reward/epoch -15.22311\n",
      "step 2180000, time 54125.4, loss 0.05528934, epochs 9525, reward/epoch -8.75000, cum reward/epoch -15.20136\n",
      "step 2190000, time 54365.7, loss 0.05770661, epochs 9557, reward/epoch -11.31250, cum reward/epoch -15.18834\n",
      "step 2200000, time 54605.8, loss 0.05448602, epochs 9581, reward/epoch -6.70833, cum reward/epoch -15.16710\n",
      "step 2210000, time 54846.8, loss 0.05592060, epochs 9611, reward/epoch -7.33333, cum reward/epoch -15.14265\n",
      "step 2220000, time 55086.7, loss 0.05506550, epochs 9636, reward/epoch -5.24000, cum reward/epoch -15.11696\n",
      "step 2230000, time 55325.7, loss 0.05471030, epochs 9663, reward/epoch -7.03704, cum reward/epoch -15.09438\n",
      "step 2240000, time 55566.7, loss 0.05555672, epochs 9689, reward/epoch -6.26923, cum reward/epoch -15.07070\n",
      "step 2250000, time 55807.2, loss 0.05468107, epochs 9719, reward/epoch -6.76667, cum reward/epoch -15.04507\n",
      "step 2260000, time 56047.0, loss 0.05404379, epochs 9740, reward/epoch -7.23810, cum reward/epoch -15.02823\n",
      "step 2270000, time 56287.3, loss 0.05521195, epochs 9770, reward/epoch -4.03333, cum reward/epoch -14.99447\n",
      "step 2280000, time 56527.6, loss 0.05422537, epochs 9797, reward/epoch -5.92593, cum reward/epoch -14.96948\n",
      "step 2290000, time 56769.0, loss 0.05556879, epochs 9824, reward/epoch -11.07407, cum reward/epoch -14.95877\n",
      "step 2300000, time 57009.7, loss 0.05633433, epochs 9854, reward/epoch -6.80000, cum reward/epoch -14.93394\n",
      "step 2310000, time 57250.6, loss 0.05504748, epochs 9882, reward/epoch -7.25000, cum reward/epoch -14.91216\n",
      "step 2320000, time 57491.3, loss 0.05637691, epochs 9909, reward/epoch -8.59259, cum reward/epoch -14.89494\n",
      "step 2330000, time 57732.3, loss 0.05508359, epochs 9938, reward/epoch -8.48276, cum reward/epoch -14.87623\n",
      "step 2340000, time 57972.3, loss 0.05527020, epochs 9968, reward/epoch -6.50000, cum reward/epoch -14.85102\n",
      "step 2350000, time 58213.2, loss 0.05577460, epochs 9995, reward/epoch -7.22222, cum reward/epoch -14.83041\n",
      "step 2360000, time 58453.7, loss 0.05889628, epochs 10029, reward/epoch -11.11765, cum reward/epoch -14.81783\n",
      "step 2370000, time 58694.3, loss 0.05623892, epochs 10059, reward/epoch -10.46667, cum reward/epoch -14.80485\n",
      "step 2380000, time 58935.3, loss 0.05614781, epochs 10085, reward/epoch -12.11539, cum reward/epoch -14.79792\n",
      "step 2390000, time 59176.3, loss 0.05612062, epochs 10116, reward/epoch -10.16129, cum reward/epoch -14.78371\n",
      "step 2400000, time 59417.0, loss 0.05660741, epochs 10148, reward/epoch -10.50000, cum reward/epoch -14.77020\n",
      "step 2410000, time 59657.8, loss 0.05592519, epochs 10180, reward/epoch -10.46875, cum reward/epoch -14.75668\n",
      "step 2420000, time 59898.5, loss 0.05525566, epochs 10209, reward/epoch -9.82759, cum reward/epoch -14.74268\n",
      "step 2430000, time 60140.4, loss 0.05550267, epochs 10238, reward/epoch -7.96552, cum reward/epoch -14.72348\n",
      "step 2440000, time 60382.6, loss 0.05524497, epochs 10266, reward/epoch -7.64286, cum reward/epoch -14.70417\n",
      "step 2450000, time 60623.8, loss 0.05495381, epochs 10293, reward/epoch -7.51852, cum reward/epoch -14.68532\n",
      "step 2460000, time 60865.3, loss 0.05413124, epochs 10320, reward/epoch -5.40741, cum reward/epoch -14.66105\n",
      "step 2470000, time 61106.5, loss 0.05407758, epochs 10347, reward/epoch -8.51852, cum reward/epoch -14.64502\n",
      "step 2480000, time 61347.2, loss 0.05390499, epochs 10369, reward/epoch -9.45455, cum reward/epoch -14.63401\n",
      "step 2490000, time 61588.1, loss 0.05446590, epochs 10398, reward/epoch -7.51724, cum reward/epoch -14.61416\n",
      "step 2500000, time 61829.6, loss 0.05691034, epochs 10431, reward/epoch -10.93939, cum reward/epoch -14.60253\n",
      "step 2510000, time 62071.0, loss 0.05637272, epochs 10463, reward/epoch -4.46875, cum reward/epoch -14.57154\n",
      "step 2520000, time 62312.6, loss 0.05621047, epochs 10489, reward/epoch -7.73077, cum reward/epoch -14.55458\n",
      "step 2530000, time 62553.8, loss 0.05342686, epochs 10514, reward/epoch -5.80000, cum reward/epoch -14.53376\n",
      "step 2540000, time 62795.9, loss 0.05502856, epochs 10544, reward/epoch -6.26667, cum reward/epoch -14.51024\n",
      "step 2550000, time 63037.8, loss 0.05438454, epochs 10570, reward/epoch -6.30769, cum reward/epoch -14.49007\n",
      "step 2560000, time 63278.8, loss 0.05482148, epochs 10594, reward/epoch -5.75000, cum reward/epoch -14.47027\n",
      "step 2570000, time 63520.6, loss 0.05488034, epochs 10623, reward/epoch -5.48276, cum reward/epoch -14.44573\n",
      "step 2580000, time 63763.4, loss 0.05432330, epochs 10650, reward/epoch -7.07407, cum reward/epoch -14.42704\n",
      "step 2590000, time 64004.9, loss 0.05729485, epochs 10681, reward/epoch -8.87097, cum reward/epoch -14.41092\n",
      "step 2600000, time 64246.4, loss 0.05484870, epochs 10710, reward/epoch -9.96552, cum reward/epoch -14.39888\n",
      "step 2610000, time 64486.7, loss 0.05258878, epochs 10732, reward/epoch -6.18182, cum reward/epoch -14.38204\n",
      "step 2620000, time 64727.4, loss 0.05659568, epochs 10763, reward/epoch -10.41935, cum reward/epoch -14.37062\n",
      "step 2630000, time 64968.8, loss 0.05608467, epochs 10793, reward/epoch -9.60000, cum reward/epoch -14.35736\n",
      "step 2640000, time 65209.7, loss 0.05386652, epochs 10819, reward/epoch -6.57692, cum reward/epoch -14.33866\n",
      "step 2650000, time 65451.0, loss 0.05390747, epochs 10844, reward/epoch -4.20000, cum reward/epoch -14.31529\n",
      "step 2660000, time 65691.7, loss 0.05582407, epochs 10872, reward/epoch -8.25000, cum reward/epoch -14.29967\n",
      "step 2670000, time 65933.5, loss 0.05467983, epochs 10900, reward/epoch -7.10714, cum reward/epoch -14.28119\n",
      "step 2680000, time 66174.7, loss 0.05515960, epochs 10927, reward/epoch -8.40741, cum reward/epoch -14.26668\n",
      "step 2690000, time 66416.2, loss 0.05391214, epochs 10951, reward/epoch -6.95833, cum reward/epoch -14.25066\n",
      "step 2700000, time 66657.7, loss 0.05410535, epochs 10977, reward/epoch -4.57692, cum reward/epoch -14.22775\n",
      "step 2710000, time 66900.1, loss 0.05388372, epochs 11000, reward/epoch -5.65217, cum reward/epoch -14.20982\n",
      "step 2720000, time 67142.1, loss 0.05429929, epochs 11028, reward/epoch -6.60714, cum reward/epoch -14.19052\n",
      "step 2730000, time 67384.7, loss 0.05285197, epochs 11056, reward/epoch -7.14286, cum reward/epoch -14.17267\n",
      "step 2740000, time 67626.6, loss 0.05474779, epochs 11082, reward/epoch -7.26923, cum reward/epoch -14.15647\n",
      "step 2750000, time 67869.0, loss 0.05820550, epochs 11111, reward/epoch -11.00000, cum reward/epoch -14.14823\n",
      "step 2760000, time 68112.9, loss 0.05637249, epochs 11138, reward/epoch -5.62963, cum reward/epoch -14.12758\n",
      "step 2770000, time 68355.3, loss 0.05462863, epochs 11166, reward/epoch -5.89286, cum reward/epoch -14.10693\n",
      "step 2780000, time 68597.0, loss 0.05297348, epochs 11189, reward/epoch -4.65217, cum reward/epoch -14.08750\n",
      "step 2790000, time 68839.4, loss 0.05465833, epochs 11214, reward/epoch -6.96000, cum reward/epoch -14.07161\n",
      "step 2800000, time 69082.3, loss 0.05407899, epochs 11244, reward/epoch -5.76667, cum reward/epoch -14.04945\n",
      "step 2810000, time 69324.4, loss 0.05328925, epochs 11269, reward/epoch -6.28000, cum reward/epoch -14.03221\n",
      "step 2820000, time 69566.6, loss 0.05392326, epochs 11295, reward/epoch -6.69231, cum reward/epoch -14.01532\n",
      "step 2830000, time 69809.1, loss 0.05320048, epochs 11319, reward/epoch -4.37500, cum reward/epoch -13.99488\n",
      "step 2840000, time 70052.0, loss 0.05608854, epochs 11348, reward/epoch -10.72414, cum reward/epoch -13.98652\n",
      "step 2850000, time 70295.3, loss 0.05579840, epochs 11378, reward/epoch -8.30000, cum reward/epoch -13.97152\n",
      "step 2860000, time 70538.3, loss 0.05269758, epochs 11403, reward/epoch -6.04000, cum reward/epoch -13.95413\n",
      "step 2870000, time 70781.0, loss 0.05313862, epochs 11428, reward/epoch -5.88000, cum reward/epoch -13.93647\n",
      "step 2880000, time 71023.6, loss 0.05377333, epochs 11453, reward/epoch -5.48000, cum reward/epoch -13.91801\n",
      "step 2890000, time 71266.2, loss 0.05346278, epochs 11479, reward/epoch -6.26923, cum reward/epoch -13.90069\n",
      "step 2900000, time 71508.6, loss 0.05266706, epochs 11504, reward/epoch -4.72000, cum reward/epoch -13.88074\n",
      "step 2910000, time 71750.8, loss 0.05417342, epochs 11527, reward/epoch -6.21739, cum reward/epoch -13.86545\n",
      "step 2920000, time 71993.3, loss 0.05359481, epochs 11554, reward/epoch -5.18518, cum reward/epoch -13.84516\n",
      "step 2930000, time 72236.0, loss 0.05398604, epochs 11579, reward/epoch -6.04000, cum reward/epoch -13.82831\n",
      "step 2940000, time 72479.3, loss 0.05400219, epochs 11604, reward/epoch -4.28000, cum reward/epoch -13.80774\n",
      "step 2950000, time 72722.3, loss 0.05359429, epochs 11629, reward/epoch -4.28000, cum reward/epoch -13.78726\n",
      "step 2960000, time 72965.6, loss 0.05286587, epochs 11654, reward/epoch -5.72000, cum reward/epoch -13.76995\n",
      "step 2970000, time 73208.6, loss 0.05334226, epochs 11681, reward/epoch -4.85185, cum reward/epoch -13.74934\n",
      "step 2980000, time 73451.6, loss 0.05489266, epochs 11707, reward/epoch -6.61538, cum reward/epoch -13.73349\n",
      "step 2990000, time 73694.1, loss 0.05412273, epochs 11731, reward/epoch -4.04167, cum reward/epoch -13.71367\n",
      "step 3000000, time 73937.0, loss 0.05290017, epochs 11758, reward/epoch -5.14815, cum reward/epoch -13.69400\n",
      "step 3010000, time 74179.3, loss 0.05302303, epochs 11784, reward/epoch -6.46154, cum reward/epoch -13.67804\n",
      "step 3020000, time 74421.6, loss 0.05350515, epochs 11805, reward/epoch -6.47619, cum reward/epoch -13.66523\n",
      "step 3030000, time 74664.5, loss 0.05343835, epochs 11833, reward/epoch -7.07143, cum reward/epoch -13.64962\n",
      "step 3040000, time 74907.3, loss 0.05237458, epochs 11857, reward/epoch -5.95833, cum reward/epoch -13.63406\n",
      "step 3050000, time 75150.0, loss 0.05376395, epochs 11882, reward/epoch -6.80000, cum reward/epoch -13.61968\n",
      "step 3060000, time 75393.4, loss 0.05266253, epochs 11909, reward/epoch -3.96296, cum reward/epoch -13.59778\n",
      "step 3070000, time 75636.5, loss 0.05281425, epochs 11930, reward/epoch -4.33333, cum reward/epoch -13.58148\n",
      "step 3080000, time 75879.5, loss 0.05434142, epochs 11959, reward/epoch -3.96552, cum reward/epoch -13.55816\n",
      "step 3090000, time 76122.0, loss 0.05305191, epochs 11982, reward/epoch -5.73913, cum reward/epoch -13.54315\n",
      "step 3100000, time 76364.7, loss 0.05303602, epochs 12008, reward/epoch -6.07692, cum reward/epoch -13.52698\n",
      "step 3110000, time 76608.2, loss 0.05508629, epochs 12038, reward/epoch -8.43333, cum reward/epoch -13.51429\n",
      "step 3120000, time 76851.5, loss 0.05389084, epochs 12061, reward/epoch -5.47826, cum reward/epoch -13.49896\n",
      "step 3130000, time 77094.5, loss 0.05416294, epochs 12088, reward/epoch -4.48148, cum reward/epoch -13.47882\n",
      "step 3140000, time 77337.0, loss 0.05309289, epochs 12115, reward/epoch -3.03704, cum reward/epoch -13.45555\n",
      "step 3150000, time 77580.0, loss 0.05277798, epochs 12135, reward/epoch -5.30000, cum reward/epoch -13.44211\n",
      "step 3160000, time 77823.5, loss 0.05561378, epochs 12165, reward/epoch -7.20000, cum reward/epoch -13.42672\n",
      "step 3170000, time 78067.2, loss 0.05556893, epochs 12192, reward/epoch -7.62963, cum reward/epoch -13.41388\n",
      "step 3180000, time 78310.2, loss 0.05265215, epochs 12212, reward/epoch -2.45000, cum reward/epoch -13.39592\n",
      "step 3190000, time 78552.9, loss 0.05407311, epochs 12239, reward/epoch -4.22222, cum reward/epoch -13.37568\n",
      "step 3200000, time 78795.1, loss 0.05337261, epochs 12261, reward/epoch -3.81818, cum reward/epoch -13.35853\n",
      "step 3210000, time 79038.5, loss 0.05320248, epochs 12284, reward/epoch -4.26087, cum reward/epoch -13.34150\n",
      "step 3220000, time 79280.8, loss 0.05298503, epochs 12308, reward/epoch -4.83333, cum reward/epoch -13.32491\n",
      "step 3230000, time 79523.1, loss 0.05498680, epochs 12335, reward/epoch -7.22222, cum reward/epoch -13.31155\n",
      "step 3240000, time 79765.4, loss 0.05373202, epochs 12361, reward/epoch -7.57692, cum reward/epoch -13.29949\n",
      "step 3250000, time 80008.5, loss 0.05287557, epochs 12383, reward/epoch -3.04545, cum reward/epoch -13.28127\n",
      "step 3260000, time 80250.5, loss 0.05248822, epochs 12408, reward/epoch -4.56000, cum reward/epoch -13.26370\n",
      "step 3270000, time 80493.8, loss 0.05454772, epochs 12436, reward/epoch -7.39286, cum reward/epoch -13.25048\n",
      "step 3280000, time 80736.7, loss 0.05472523, epochs 12461, reward/epoch -8.48000, cum reward/epoch -13.24091\n",
      "step 3290000, time 80979.5, loss 0.05274126, epochs 12487, reward/epoch -2.23077, cum reward/epoch -13.21799\n",
      "step 3300000, time 81222.7, loss 0.05308271, epochs 12510, reward/epoch -6.69565, cum reward/epoch -13.20600\n",
      "step 3310000, time 81466.1, loss 0.05293976, epochs 12537, reward/epoch -6.33333, cum reward/epoch -13.19119\n",
      "step 3320000, time 81709.7, loss 0.05275111, epochs 12562, reward/epoch -4.60000, cum reward/epoch -13.17410\n",
      "step 3330000, time 81952.9, loss 0.05264572, epochs 12583, reward/epoch -4.42857, cum reward/epoch -13.15950\n",
      "step 3340000, time 82196.9, loss 0.05234530, epochs 12610, reward/epoch -3.81481, cum reward/epoch -13.13949\n",
      "step 3350000, time 82440.3, loss 0.05297619, epochs 12634, reward/epoch -3.66667, cum reward/epoch -13.12150\n",
      "step 3360000, time 82684.0, loss 0.05428088, epochs 12661, reward/epoch -5.55556, cum reward/epoch -13.10536\n",
      "step 3370000, time 82928.0, loss 0.05458204, epochs 12686, reward/epoch -3.88000, cum reward/epoch -13.08718\n",
      "step 3380000, time 83171.4, loss 0.05251325, epochs 12708, reward/epoch -1.45455, cum reward/epoch -13.06704\n",
      "step 3390000, time 83414.6, loss 0.05384630, epochs 12735, reward/epoch -3.22222, cum reward/epoch -13.04617\n",
      "step 3400000, time 83658.3, loss 0.05353003, epochs 12762, reward/epoch -4.37037, cum reward/epoch -13.02782\n",
      "step 3410000, time 83901.6, loss 0.05356152, epochs 12784, reward/epoch -4.95455, cum reward/epoch -13.01392\n",
      "step 3420000, time 84145.7, loss 0.05332731, epochs 12808, reward/epoch -3.95833, cum reward/epoch -12.99695\n",
      "step 3430000, time 84389.6, loss 0.05272228, epochs 12835, reward/epoch -0.62963, cum reward/epoch -12.97094\n",
      "step 3440000, time 84632.8, loss 0.05134508, epochs 12855, reward/epoch -1.80000, cum reward/epoch -12.95356\n",
      "step 3450000, time 84876.2, loss 0.05324589, epochs 12881, reward/epoch -1.73077, cum reward/epoch -12.93091\n",
      "step 3460000, time 85120.3, loss 0.05174506, epochs 12902, reward/epoch -3.23810, cum reward/epoch -12.91513\n",
      "step 3470000, time 85365.1, loss 0.05217209, epochs 12929, reward/epoch -3.29630, cum reward/epoch -12.89504\n",
      "step 3480000, time 85609.4, loss 0.05335203, epochs 12950, reward/epoch -1.95238, cum reward/epoch -12.87730\n",
      "step 3490000, time 85854.2, loss 0.05359504, epochs 12979, reward/epoch -2.79310, cum reward/epoch -12.85476\n",
      "step 3500000, time 86099.0, loss 0.05462427, epochs 13002, reward/epoch -2.52174, cum reward/epoch -12.83649\n",
      "step 3510000, time 86344.3, loss 0.05218869, epochs 13023, reward/epoch -2.61905, cum reward/epoch -12.82001\n",
      "step 3520000, time 86588.8, loss 0.05264977, epochs 13050, reward/epoch -2.07407, cum reward/epoch -12.79778\n",
      "step 3530000, time 86833.1, loss 0.05294235, epochs 13074, reward/epoch -2.58333, cum reward/epoch -12.77903\n",
      "step 3540000, time 87077.4, loss 0.05195273, epochs 13097, reward/epoch -2.34783, cum reward/epoch -12.76071\n",
      "step 3550000, time 87322.2, loss 0.05497310, epochs 13127, reward/epoch -7.00000, cum reward/epoch -12.74754\n",
      "step 3560000, time 87566.8, loss 0.05701576, epochs 13156, reward/epoch -9.31034, cum reward/epoch -12.73997\n",
      "step 3570000, time 87811.6, loss 0.05485504, epochs 13183, reward/epoch -4.07407, cum reward/epoch -12.72222\n",
      "step 3580000, time 88055.9, loss 0.05259398, epochs 13207, reward/epoch -1.70833, cum reward/epoch -12.70220\n",
      "step 3590000, time 88300.2, loss 0.05161882, epochs 13230, reward/epoch -2.78261, cum reward/epoch -12.68496\n",
      "step 3600000, time 88544.7, loss 0.05190958, epochs 13253, reward/epoch -1.56522, cum reward/epoch -12.66566\n",
      "step 3610000, time 88789.4, loss 0.05546205, epochs 13282, reward/epoch -8.48276, cum reward/epoch -12.65653\n",
      "step 3620000, time 89034.4, loss 0.05313601, epochs 13306, reward/epoch -3.41667, cum reward/epoch -12.63986\n",
      "step 3630000, time 89278.8, loss 0.05240563, epochs 13330, reward/epoch -2.00000, cum reward/epoch -12.62071\n",
      "step 3640000, time 89523.6, loss 0.05345394, epochs 13360, reward/epoch -4.70000, cum reward/epoch -12.60292\n",
      "step 3650000, time 89768.2, loss 0.05351778, epochs 13382, reward/epoch -3.36364, cum reward/epoch -12.58773\n",
      "step 3660000, time 90013.6, loss 0.05267464, epochs 13405, reward/epoch -3.08696, cum reward/epoch -12.57143\n",
      "step 3670000, time 90258.3, loss 0.05359250, epochs 13432, reward/epoch -4.81482, cum reward/epoch -12.55584\n",
      "step 3680000, time 90503.1, loss 0.05232795, epochs 13452, reward/epoch -2.05000, cum reward/epoch -12.54022\n",
      "step 3690000, time 90748.5, loss 0.05172164, epochs 13477, reward/epoch -3.12000, cum reward/epoch -12.52274\n",
      "step 3700000, time 90994.1, loss 0.05201383, epochs 13501, reward/epoch -3.45833, cum reward/epoch -12.50663\n",
      "step 3710000, time 91238.7, loss 0.05224637, epochs 13523, reward/epoch -5.31818, cum reward/epoch -12.49493\n",
      "step 3720000, time 91484.0, loss 0.05267693, epochs 13549, reward/epoch -3.42308, cum reward/epoch -12.47753\n",
      "step 3730000, time 91729.2, loss 0.05338660, epochs 13575, reward/epoch -5.88462, cum reward/epoch -12.46490\n",
      "step 3740000, time 91974.8, loss 0.05288570, epochs 13600, reward/epoch -3.32000, cum reward/epoch -12.44809\n",
      "step 3750000, time 92220.0, loss 0.05377642, epochs 13624, reward/epoch -6.54167, cum reward/epoch -12.43768\n",
      "step 3760000, time 92465.2, loss 0.05433757, epochs 13652, reward/epoch -4.60714, cum reward/epoch -12.42162\n",
      "step 3770000, time 92711.3, loss 0.05433119, epochs 13675, reward/epoch -3.43478, cum reward/epoch -12.40651\n",
      "step 3780000, time 92956.9, loss 0.05926298, epochs 13712, reward/epoch -10.62162, cum reward/epoch -12.40169\n",
      "step 3790000, time 93202.3, loss 0.05658790, epochs 13738, reward/epoch -6.76923, cum reward/epoch -12.39103\n",
      "step 3800000, time 93447.4, loss 0.05420762, epochs 13763, reward/epoch -4.08000, cum reward/epoch -12.37594\n",
      "step 3810000, time 93692.0, loss 0.05337554, epochs 13787, reward/epoch -4.25000, cum reward/epoch -12.36179\n",
      "step 3820000, time 93937.4, loss 0.05234306, epochs 13813, reward/epoch -1.03846, cum reward/epoch -12.34048\n",
      "step 3830000, time 94182.3, loss 0.05211039, epochs 13835, reward/epoch -1.63636, cum reward/epoch -12.32345\n",
      "step 3840000, time 94426.5, loss 0.05244648, epochs 13859, reward/epoch -0.95833, cum reward/epoch -12.30377\n",
      "step 3850000, time 94671.1, loss 0.05484056, epochs 13885, reward/epoch -4.53846, cum reward/epoch -12.28923\n",
      "step 3860000, time 94915.6, loss 0.05419207, epochs 13910, reward/epoch -6.00000, cum reward/epoch -12.27793\n",
      "step 3870000, time 95161.1, loss 0.05340627, epochs 13937, reward/epoch -5.81482, cum reward/epoch -12.26541\n",
      "step 3880000, time 95406.1, loss 0.05283073, epochs 13961, reward/epoch -2.75000, cum reward/epoch -12.24905\n",
      "step 3890000, time 95651.6, loss 0.05374558, epochs 13986, reward/epoch -2.40000, cum reward/epoch -12.23145\n",
      "step 3900000, time 95896.8, loss 0.05374082, epochs 14008, reward/epoch -4.63636, cum reward/epoch -12.21952\n",
      "step 3910000, time 96141.7, loss 0.05323054, epochs 14032, reward/epoch -1.91667, cum reward/epoch -12.20190\n",
      "step 3920000, time 96387.0, loss 0.05357204, epochs 14058, reward/epoch -3.96154, cum reward/epoch -12.18666\n",
      "step 3930000, time 96632.1, loss 0.05873489, epochs 14093, reward/epoch -10.97143, cum reward/epoch -12.18364\n",
      "step 3940000, time 96876.8, loss 0.05720336, epochs 14123, reward/epoch -7.50000, cum reward/epoch -12.17369\n",
      "step 3950000, time 97122.3, loss 0.05454684, epochs 14145, reward/epoch -2.31818, cum reward/epoch -12.15836\n",
      "step 3960000, time 97367.3, loss 0.05257297, epochs 14169, reward/epoch -0.62500, cum reward/epoch -12.13882\n",
      "step 3970000, time 97611.9, loss 0.05336254, epochs 14192, reward/epoch -2.47826, cum reward/epoch -12.12317\n",
      "step 3980000, time 97856.8, loss 0.05238698, epochs 14216, reward/epoch -0.41667, cum reward/epoch -12.10340\n",
      "step 3990000, time 98101.8, loss 0.05311977, epochs 14240, reward/epoch -4.12500, cum reward/epoch -12.08996\n",
      "step 4000000, time 98347.8, loss 0.05304604, epochs 14266, reward/epoch -1.96154, cum reward/epoch -12.07150\n",
      "step 4010000, time 98592.9, loss 0.05394668, epochs 14293, reward/epoch -7.66667, cum reward/epoch -12.06318\n",
      "step 4020000, time 98837.8, loss 0.05562533, epochs 14317, reward/epoch -5.54167, cum reward/epoch -12.05225\n",
      "step 4030000, time 99082.9, loss 0.05243067, epochs 14342, reward/epoch -3.52000, cum reward/epoch -12.03737\n",
      "step 4040000, time 99328.1, loss 0.05158233, epochs 14364, reward/epoch -1.27273, cum reward/epoch -12.02089\n",
      "step 4050000, time 99573.8, loss 0.05175706, epochs 14388, reward/epoch -0.50000, cum reward/epoch -12.00167\n",
      "step 4060000, time 99819.4, loss 0.05146677, epochs 14411, reward/epoch -1.08696, cum reward/epoch -11.98425\n",
      "step 4070000, time 100065.3, loss 0.05137350, epochs 14430, reward/epoch -3.84211, cum reward/epoch -11.97353\n",
      "step 4080000, time 100310.5, loss 0.05217467, epochs 14453, reward/epoch -0.82609, cum reward/epoch -11.95579\n",
      "step 4090000, time 100555.9, loss 0.05218064, epochs 14478, reward/epoch -2.12000, cum reward/epoch -11.93880\n",
      "step 4100000, time 100801.4, loss 0.05205060, epochs 14501, reward/epoch -0.08696, cum reward/epoch -11.92001\n",
      "step 4110000, time 101047.1, loss 0.05190210, epochs 14523, reward/epoch -3.18182, cum reward/epoch -11.90677\n",
      "step 4120000, time 101292.8, loss 0.05059966, epochs 14550, reward/epoch -3.74074, cum reward/epoch -11.89161\n",
      "step 4130000, time 101538.8, loss 0.05160302, epochs 14571, reward/epoch -1.71429, cum reward/epoch -11.87695\n",
      "step 4140000, time 101784.5, loss 0.05150958, epochs 14595, reward/epoch -1.25000, cum reward/epoch -11.85947\n",
      "step 4150000, time 102030.3, loss 0.05294820, epochs 14616, reward/epoch -3.47619, cum reward/epoch -11.84743\n",
      "step 4160000, time 102275.7, loss 0.05226695, epochs 14639, reward/epoch -3.69565, cum reward/epoch -11.83462\n",
      "step 4170000, time 102521.4, loss 0.05093591, epochs 14662, reward/epoch -2.30435, cum reward/epoch -11.81967\n",
      "step 4180000, time 102767.4, loss 0.05157213, epochs 14684, reward/epoch 0.77273, cum reward/epoch -11.80080\n",
      "step 4190000, time 103013.1, loss 0.05271044, epochs 14707, reward/epoch -1.04348, cum reward/epoch -11.78398\n",
      "step 4200000, time 103259.4, loss 0.05146321, epochs 14729, reward/epoch 1.00000, cum reward/epoch -11.76489\n",
      "step 4210000, time 103505.2, loss 0.05136606, epochs 14752, reward/epoch -2.13043, cum reward/epoch -11.74986\n",
      "step 4220000, time 103751.6, loss 0.05088418, epochs 14773, reward/epoch -3.90476, cum reward/epoch -11.73871\n",
      "step 4230000, time 103996.9, loss 0.05260556, epochs 14798, reward/epoch -3.60000, cum reward/epoch -11.72496\n",
      "step 4240000, time 104242.9, loss 0.05206566, epochs 14820, reward/epoch -1.81818, cum reward/epoch -11.71026\n",
      "step 4250000, time 104488.3, loss 0.05190911, epochs 14846, reward/epoch -0.61538, cum reward/epoch -11.69083\n",
      "step 4260000, time 104734.0, loss 0.05549917, epochs 14875, reward/epoch -8.31034, cum reward/epoch -11.68424\n",
      "step 4270000, time 104979.2, loss 0.05922795, epochs 14914, reward/epoch -12.17949, cum reward/epoch -11.68553\n",
      "step 4280000, time 105225.6, loss 0.05683332, epochs 14937, reward/epoch -6.13043, cum reward/epoch -11.67698\n",
      "step 4290000, time 105471.5, loss 0.05467415, epochs 14963, reward/epoch -0.30769, cum reward/epoch -11.65722\n",
      "step 4300000, time 105717.0, loss 0.05299491, epochs 14986, reward/epoch -1.00000, cum reward/epoch -11.64086\n",
      "step 4310000, time 105961.8, loss 0.05255005, epochs 15007, reward/epoch -1.04762, cum reward/epoch -11.62604\n",
      "step 4320000, time 106207.2, loss 0.05277861, epochs 15032, reward/epoch -2.48000, cum reward/epoch -11.61083\n",
      "step 4330000, time 106453.4, loss 0.05474579, epochs 15061, reward/epoch -6.20690, cum reward/epoch -11.60042\n",
      "step 4340000, time 106699.6, loss 0.05251477, epochs 15087, reward/epoch 0.84615, cum reward/epoch -11.57898\n",
      "step 4350000, time 106945.0, loss 0.05093649, epochs 15109, reward/epoch -0.77273, cum reward/epoch -11.56324\n",
      "step 4360000, time 107190.6, loss 0.05140521, epochs 15128, reward/epoch 0.10526, cum reward/epoch -11.54858\n",
      "step 4370000, time 107436.6, loss 0.05201389, epochs 15158, reward/epoch -0.53333, cum reward/epoch -11.52678\n",
      "step 4380000, time 107682.6, loss 0.05209938, epochs 15177, reward/epoch 1.68421, cum reward/epoch -11.51025\n",
      "step 4390000, time 107928.5, loss 0.05086197, epochs 15199, reward/epoch -0.86364, cum reward/epoch -11.49483\n",
      "step 4400000, time 108174.2, loss 0.05055933, epochs 15222, reward/epoch -0.78261, cum reward/epoch -11.47865\n",
      "step 4410000, time 108420.9, loss 0.05084275, epochs 15247, reward/epoch -1.16000, cum reward/epoch -11.46173\n",
      "step 4420000, time 108667.1, loss 0.05144213, epochs 15269, reward/epoch -2.00000, cum reward/epoch -11.44810\n",
      "step 4430000, time 108913.6, loss 0.05101265, epochs 15294, reward/epoch 0.28000, cum reward/epoch -11.42893\n",
      "step 4440000, time 109159.9, loss 0.05152887, epochs 15317, reward/epoch 0.56522, cum reward/epoch -11.41092\n",
      "step 4450000, time 109406.3, loss 0.05158422, epochs 15340, reward/epoch 0.56522, cum reward/epoch -11.39296\n",
      "step 4460000, time 109652.5, loss 0.05053204, epochs 15364, reward/epoch 0.37500, cum reward/epoch -11.37458\n",
      "step 4470000, time 109899.3, loss 0.05091923, epochs 15390, reward/epoch 0.92308, cum reward/epoch -11.35380\n",
      "step 4480000, time 110145.5, loss 0.05126456, epochs 15412, reward/epoch -3.09091, cum reward/epoch -11.34201\n",
      "step 4490000, time 110392.2, loss 0.05187278, epochs 15433, reward/epoch -0.61905, cum reward/epoch -11.32742\n",
      "step 4500000, time 110638.7, loss 0.05186032, epochs 15460, reward/epoch -5.11111, cum reward/epoch -11.31656\n",
      "step 4510000, time 110885.2, loss 0.05090701, epochs 15478, reward/epoch -0.83333, cum reward/epoch -11.30437\n",
      "step 4520000, time 111132.8, loss 0.05326780, epochs 15507, reward/epoch -2.10345, cum reward/epoch -11.28716\n",
      "step 4530000, time 111378.6, loss 0.05343494, epochs 15528, reward/epoch -0.80952, cum reward/epoch -11.27299\n",
      "step 4540000, time 111625.0, loss 0.05236227, epochs 15554, reward/epoch -0.07692, cum reward/epoch -11.25428\n",
      "step 4550000, time 111870.7, loss 0.05113842, epochs 15576, reward/epoch 0.36364, cum reward/epoch -11.23787\n",
      "step 4560000, time 112116.7, loss 0.05166731, epochs 15602, reward/epoch 0.73077, cum reward/epoch -11.21792\n",
      "step 4570000, time 112363.5, loss 0.05182486, epochs 15624, reward/epoch -1.77273, cum reward/epoch -11.20462\n",
      "step 4580000, time 112610.1, loss 0.05327727, epochs 15650, reward/epoch -4.61538, cum reward/epoch -11.19367\n",
      "step 4590000, time 112856.5, loss 0.05139417, epochs 15672, reward/epoch 0.13636, cum reward/epoch -11.17777\n",
      "step 4600000, time 113103.4, loss 0.05209319, epochs 15697, reward/epoch 2.12000, cum reward/epoch -11.15659\n",
      "step 4610000, time 113350.9, loss 0.05012030, epochs 15718, reward/epoch -1.47619, cum reward/epoch -11.14366\n",
      "step 4620000, time 113598.4, loss 0.05146772, epochs 15741, reward/epoch -1.60870, cum reward/epoch -11.12972\n",
      "step 4630000, time 113845.4, loss 0.05271479, epochs 15766, reward/epoch -2.84000, cum reward/epoch -11.11658\n",
      "step 4640000, time 114093.3, loss 0.05471337, epochs 15791, reward/epoch -7.24000, cum reward/epoch -11.11044\n",
      "step 4650000, time 114340.0, loss 0.05197921, epochs 15817, reward/epoch -4.15385, cum reward/epoch -11.09901\n",
      "step 4660000, time 114586.5, loss 0.05091381, epochs 15836, reward/epoch -3.05263, cum reward/epoch -11.08935\n",
      "step 4670000, time 114833.3, loss 0.05077646, epochs 15861, reward/epoch 0.40000, cum reward/epoch -11.07124\n",
      "step 4680000, time 115081.5, loss 0.05139606, epochs 15883, reward/epoch -0.13636, cum reward/epoch -11.05610\n",
      "step 4690000, time 115327.9, loss 0.05107701, epochs 15907, reward/epoch 0.25000, cum reward/epoch -11.03904\n",
      "step 4700000, time 115575.2, loss 0.05066689, epochs 15930, reward/epoch -1.04348, cum reward/epoch -11.02461\n",
      "step 4710000, time 115822.1, loss 0.05154202, epochs 15951, reward/epoch 0.38095, cum reward/epoch -11.00959\n",
      "step 4720000, time 116069.3, loss 0.05206035, epochs 15976, reward/epoch -3.44000, cum reward/epoch -10.99775\n",
      "step 4730000, time 116316.3, loss 0.05176205, epochs 15998, reward/epoch -2.31818, cum reward/epoch -10.98581\n",
      "step 4740000, time 116562.4, loss 0.05198118, epochs 16024, reward/epoch 1.23077, cum reward/epoch -10.96599\n",
      "step 4750000, time 116809.6, loss 0.05158375, epochs 16045, reward/epoch -2.14286, cum reward/epoch -10.95444\n",
      "step 4760000, time 117057.0, loss 0.05096954, epochs 16068, reward/epoch 1.78261, cum reward/epoch -10.93621\n",
      "step 4770000, time 117303.0, loss 0.05232850, epochs 16091, reward/epoch -0.78261, cum reward/epoch -10.92170\n",
      "step 4780000, time 117549.6, loss 0.05061047, epochs 16115, reward/epoch 0.50000, cum reward/epoch -10.90469\n",
      "step 4790000, time 117796.4, loss 0.05051149, epochs 16139, reward/epoch -0.33333, cum reward/epoch -10.88896\n",
      "step 4800000, time 118043.4, loss 0.05083023, epochs 16159, reward/epoch 0.80000, cum reward/epoch -10.87450\n",
      "step 4810000, time 118291.9, loss 0.05047206, epochs 16183, reward/epoch -3.41667, cum reward/epoch -10.86344\n",
      "step 4820000, time 118538.8, loss 0.05150734, epochs 16206, reward/epoch -3.52174, cum reward/epoch -10.85302\n",
      "step 4830000, time 118786.2, loss 0.05181376, epochs 16233, reward/epoch -0.44444, cum reward/epoch -10.83570\n",
      "step 4840000, time 119033.2, loss 0.05074726, epochs 16255, reward/epoch -1.18182, cum reward/epoch -10.82264\n",
      "step 4850000, time 119279.7, loss 0.05171959, epochs 16279, reward/epoch 2.00000, cum reward/epoch -10.80373\n",
      "step 4860000, time 119527.1, loss 0.05146469, epochs 16301, reward/epoch -1.81818, cum reward/epoch -10.79161\n",
      "step 4870000, time 119773.8, loss 0.05157049, epochs 16323, reward/epoch -2.13636, cum reward/epoch -10.77994\n",
      "step 4880000, time 120020.8, loss 0.05155657, epochs 16347, reward/epoch 0.04167, cum reward/epoch -10.76405\n",
      "step 4890000, time 120267.6, loss 0.05053611, epochs 16371, reward/epoch -0.70833, cum reward/epoch -10.74931\n",
      "step 4900000, time 120515.2, loss 0.05113952, epochs 16392, reward/epoch -1.57143, cum reward/epoch -10.73755\n",
      "step 4910000, time 120761.8, loss 0.05097607, epochs 16414, reward/epoch 2.09091, cum reward/epoch -10.72036\n",
      "step 4920000, time 121008.9, loss 0.05098367, epochs 16435, reward/epoch 1.38095, cum reward/epoch -10.70490\n",
      "step 4930000, time 121256.4, loss 0.05058227, epochs 16461, reward/epoch 1.11538, cum reward/epoch -10.68623\n",
      "step 4940000, time 121503.4, loss 0.05197775, epochs 16481, reward/epoch 3.85000, cum reward/epoch -10.66859\n",
      "step 4950000, time 121750.0, loss 0.05114111, epochs 16507, reward/epoch -0.15385, cum reward/epoch -10.65203\n",
      "step 4960000, time 121997.3, loss 0.05114583, epochs 16532, reward/epoch -2.04000, cum reward/epoch -10.63900\n",
      "step 4970000, time 122244.2, loss 0.05219162, epochs 16555, reward/epoch -0.69565, cum reward/epoch -10.62519\n",
      "step 4980000, time 122491.7, loss 0.05147419, epochs 16577, reward/epoch -1.95455, cum reward/epoch -10.61368\n",
      "step 4990000, time 122739.1, loss 0.05567508, epochs 16609, reward/epoch -6.84375, cum reward/epoch -10.60642\n",
      "step 5000000, time 122986.5, loss 0.05217321, epochs 16630, reward/epoch -3.90476, cum reward/epoch -10.59796\n",
      "step 5010000, time 123233.6, loss 0.05041493, epochs 16654, reward/epoch -1.20833, cum reward/epoch -10.58442\n",
      "step 5020000, time 123480.6, loss 0.05011642, epochs 16675, reward/epoch -1.52381, cum reward/epoch -10.57301\n",
      "step 5030000, time 123727.5, loss 0.05022838, epochs 16696, reward/epoch 0.09524, cum reward/epoch -10.55960\n",
      "step 5040000, time 123974.3, loss 0.05002082, epochs 16720, reward/epoch -0.12500, cum reward/epoch -10.54462\n",
      "step 5050000, time 124221.6, loss 0.05235188, epochs 16743, reward/epoch -2.43478, cum reward/epoch -10.53348\n",
      "step 5060000, time 124468.7, loss 0.05113532, epochs 16769, reward/epoch 0.80769, cum reward/epoch -10.51589\n",
      "step 5070000, time 124715.2, loss 0.05284042, epochs 16794, reward/epoch -0.68000, cum reward/epoch -10.50125\n",
      "step 5080000, time 124963.1, loss 0.05190238, epochs 16819, reward/epoch 1.28000, cum reward/epoch -10.48374\n",
      "step 5090000, time 125210.5, loss 0.05186178, epochs 16841, reward/epoch 2.31818, cum reward/epoch -10.46702\n",
      "step 5100000, time 125458.2, loss 0.05291612, epochs 16868, reward/epoch 0.62963, cum reward/epoch -10.44925\n",
      "step 5110000, time 125705.0, loss 0.05035692, epochs 16889, reward/epoch 2.42857, cum reward/epoch -10.43324\n",
      "step 5120000, time 125952.2, loss 0.05250917, epochs 16915, reward/epoch 2.69231, cum reward/epoch -10.41306\n",
      "step 5130000, time 126199.6, loss 0.05103112, epochs 16936, reward/epoch 3.61905, cum reward/epoch -10.39567\n",
      "step 5140000, time 126447.2, loss 0.05168067, epochs 16960, reward/epoch 1.95833, cum reward/epoch -10.37818\n",
      "step 5150000, time 126694.8, loss 0.05101691, epochs 16984, reward/epoch -1.20833, cum reward/epoch -10.36523\n",
      "step 5160000, time 126942.0, loss 0.05032886, epochs 17002, reward/epoch 0.66667, cum reward/epoch -10.35355\n",
      "step 5170000, time 127189.1, loss 0.05083957, epochs 17028, reward/epoch -0.84615, cum reward/epoch -10.33903\n",
      "step 5180000, time 127435.9, loss 0.05472134, epochs 17054, reward/epoch -8.23077, cum reward/epoch -10.33582\n",
      "step 5190000, time 127683.5, loss 0.05313120, epochs 17079, reward/epoch -3.40000, cum reward/epoch -10.32566\n",
      "step 5200000, time 127930.9, loss 0.05136893, epochs 17102, reward/epoch 1.91304, cum reward/epoch -10.30920\n",
      "step 5210000, time 128177.8, loss 0.05029614, epochs 17124, reward/epoch -1.27273, cum reward/epoch -10.29759\n",
      "step 5220000, time 128424.9, loss 0.05073585, epochs 17150, reward/epoch 3.46154, cum reward/epoch -10.27673\n",
      "step 5230000, time 128672.4, loss 0.05027817, epochs 17171, reward/epoch 3.38095, cum reward/epoch -10.26003\n",
      "step 5240000, time 128920.0, loss 0.05052744, epochs 17196, reward/epoch 1.16000, cum reward/epoch -10.24343\n",
      "step 5250000, time 129167.5, loss 0.05044479, epochs 17215, reward/epoch -3.57895, cum reward/epoch -10.23607\n",
      "step 5260000, time 129414.8, loss 0.05089248, epochs 17241, reward/epoch -2.42308, cum reward/epoch -10.22429\n",
      "step 5270000, time 129661.4, loss 0.05032464, epochs 17261, reward/epoch -0.20000, cum reward/epoch -10.21268\n",
      "step 5280000, time 129909.2, loss 0.05068405, epochs 17284, reward/epoch 0.69565, cum reward/epoch -10.19816\n",
      "step 5290000, time 130156.7, loss 0.04982684, epochs 17305, reward/epoch 1.28571, cum reward/epoch -10.18422\n",
      "step 5300000, time 130404.3, loss 0.05027222, epochs 17329, reward/epoch -0.08333, cum reward/epoch -10.17023\n",
      "step 5310000, time 130652.5, loss 0.05107604, epochs 17351, reward/epoch -2.45455, cum reward/epoch -10.16045\n",
      "step 5320000, time 130899.5, loss 0.05030783, epochs 17372, reward/epoch 1.04762, cum reward/epoch -10.14690\n",
      "step 5330000, time 131146.5, loss 0.05071544, epochs 17399, reward/epoch 4.66667, cum reward/epoch -10.12391\n",
      "step 5340000, time 131394.9, loss 0.05054095, epochs 17419, reward/epoch 3.15000, cum reward/epoch -10.10867\n",
      "step 5350000, time 131641.7, loss 0.05015056, epochs 17444, reward/epoch 3.24000, cum reward/epoch -10.08954\n",
      "step 5360000, time 131889.8, loss 0.05315631, epochs 17471, reward/epoch -7.14815, cum reward/epoch -10.08500\n",
      "step 5370000, time 132137.1, loss 0.05469448, epochs 17494, reward/epoch -0.52174, cum reward/epoch -10.07242\n",
      "step 5380000, time 132383.3, loss 0.05082557, epochs 17514, reward/epoch 3.20000, cum reward/epoch -10.05727\n",
      "step 5390000, time 132630.3, loss 0.05093314, epochs 17537, reward/epoch 2.60870, cum reward/epoch -10.04066\n",
      "step 5400000, time 132877.5, loss 0.05066676, epochs 17560, reward/epoch 1.00000, cum reward/epoch -10.02620\n",
      "step 5410000, time 133125.0, loss 0.05122814, epochs 17584, reward/epoch 1.25000, cum reward/epoch -10.01081\n",
      "step 5420000, time 133371.7, loss 0.05036788, epochs 17605, reward/epoch 1.42857, cum reward/epoch -9.99716\n",
      "step 5430000, time 133618.2, loss 0.04935582, epochs 17627, reward/epoch 2.72727, cum reward/epoch -9.98128\n",
      "step 5440000, time 133865.5, loss 0.04931410, epochs 17649, reward/epoch 0.77273, cum reward/epoch -9.96787\n",
      "step 5450000, time 134113.9, loss 0.05067037, epochs 17673, reward/epoch 1.45833, cum reward/epoch -9.95236\n",
      "step 5460000, time 134362.0, loss 0.05115400, epochs 17695, reward/epoch 3.04545, cum reward/epoch -9.93620\n",
      "step 5470000, time 134609.1, loss 0.05003649, epochs 17718, reward/epoch -1.39130, cum reward/epoch -9.92510\n",
      "step 5480000, time 134856.8, loss 0.04952541, epochs 17741, reward/epoch -3.65217, cum reward/epoch -9.91697\n",
      "step 5490000, time 135104.2, loss 0.05046667, epochs 17764, reward/epoch -1.21739, cum reward/epoch -9.90571\n",
      "step 5500000, time 135351.7, loss 0.04988712, epochs 17786, reward/epoch 1.63636, cum reward/epoch -9.89143\n",
      "step 5510000, time 135599.8, loss 0.05010479, epochs 17810, reward/epoch 2.08333, cum reward/epoch -9.87529\n",
      "step 5520000, time 135847.5, loss 0.05036986, epochs 17832, reward/epoch 2.09091, cum reward/epoch -9.86053\n",
      "step 5530000, time 136095.0, loss 0.05075447, epochs 17852, reward/epoch 1.65000, cum reward/epoch -9.84764\n",
      "step 5540000, time 136342.5, loss 0.04965927, epochs 17875, reward/epoch 1.47826, cum reward/epoch -9.83306\n",
      "step 5550000, time 136590.3, loss 0.05006816, epochs 17897, reward/epoch -1.40909, cum reward/epoch -9.82271\n",
      "step 5560000, time 136839.1, loss 0.05060545, epochs 17919, reward/epoch 1.77273, cum reward/epoch -9.80847\n",
      "step 5570000, time 137087.3, loss 0.04938240, epochs 17944, reward/epoch 0.20000, cum reward/epoch -9.79453\n",
      "step 5580000, time 137334.5, loss 0.05058082, epochs 17964, reward/epoch 1.35000, cum reward/epoch -9.78212\n",
      "step 5590000, time 137582.1, loss 0.04979144, epochs 17987, reward/epoch 1.73913, cum reward/epoch -9.76739\n",
      "step 5600000, time 137830.4, loss 0.05153047, epochs 18013, reward/epoch -2.88462, cum reward/epoch -9.75745\n",
      "step 5610000, time 138078.6, loss 0.05035118, epochs 18035, reward/epoch 1.95455, cum reward/epoch -9.74317\n",
      "step 5620000, time 138326.1, loss 0.05117715, epochs 18058, reward/epoch 3.86957, cum reward/epoch -9.72583\n",
      "step 5630000, time 138573.5, loss 0.05078339, epochs 18082, reward/epoch 1.66667, cum reward/epoch -9.71071\n",
      "step 5640000, time 138822.0, loss 0.05141438, epochs 18102, reward/epoch -1.55000, cum reward/epoch -9.70169\n",
      "step 5650000, time 139069.4, loss 0.05056596, epochs 18129, reward/epoch 4.03704, cum reward/epoch -9.68123\n",
      "step 5660000, time 139316.9, loss 0.04971490, epochs 18149, reward/epoch 1.65000, cum reward/epoch -9.66874\n",
      "step 5670000, time 139565.0, loss 0.05062933, epochs 18176, reward/epoch 4.22222, cum reward/epoch -9.64811\n",
      "step 5680000, time 139812.4, loss 0.05000320, epochs 18199, reward/epoch 2.60870, cum reward/epoch -9.63262\n",
      "step 5690000, time 140060.3, loss 0.05306818, epochs 18226, reward/epoch -6.44444, cum reward/epoch -9.62789\n",
      "step 5700000, time 140308.2, loss 0.05191907, epochs 18251, reward/epoch -2.96000, cum reward/epoch -9.61876\n",
      "step 5710000, time 140556.5, loss 0.05068812, epochs 18270, reward/epoch 1.00000, cum reward/epoch -9.60772\n",
      "step 5720000, time 140804.5, loss 0.05069045, epochs 18293, reward/epoch -0.04348, cum reward/epoch -9.59569\n",
      "step 5730000, time 141052.0, loss 0.04986904, epochs 18316, reward/epoch 3.78261, cum reward/epoch -9.57889\n",
      "step 5740000, time 141300.4, loss 0.04969380, epochs 18338, reward/epoch 2.68182, cum reward/epoch -9.56418\n",
      "step 5750000, time 141548.0, loss 0.05189930, epochs 18361, reward/epoch -1.52174, cum reward/epoch -9.55411\n",
      "step 5760000, time 141795.8, loss 0.05123605, epochs 18388, reward/epoch -1.44444, cum reward/epoch -9.54220\n",
      "step 5770000, time 142043.4, loss 0.05083456, epochs 18408, reward/epoch 1.75000, cum reward/epoch -9.52993\n",
      "step 5780000, time 142291.6, loss 0.05103357, epochs 18430, reward/epoch 2.90909, cum reward/epoch -9.51508\n",
      "step 5790000, time 142539.6, loss 0.05082485, epochs 18454, reward/epoch -1.33333, cum reward/epoch -9.50444\n",
      "step 5800000, time 142787.6, loss 0.05067810, epochs 18476, reward/epoch -0.59091, cum reward/epoch -9.49383\n",
      "step 5810000, time 143035.8, loss 0.05055419, epochs 18496, reward/epoch 3.05000, cum reward/epoch -9.48027\n",
      "step 5820000, time 143283.5, loss 0.05016142, epochs 18522, reward/epoch 3.69231, cum reward/epoch -9.46177\n",
      "step 5830000, time 143531.3, loss 0.05240299, epochs 18543, reward/epoch -5.71429, cum reward/epoch -9.45753\n",
      "step 5840000, time 143778.8, loss 0.05228328, epochs 18570, reward/epoch -2.81481, cum reward/epoch -9.44787\n",
      "step 5850000, time 144026.8, loss 0.05002417, epochs 18592, reward/epoch 1.09091, cum reward/epoch -9.43540\n",
      "step 5860000, time 144274.1, loss 0.05115065, epochs 18612, reward/epoch 0.35000, cum reward/epoch -9.42489\n",
      "step 5870000, time 144521.5, loss 0.05014427, epochs 18634, reward/epoch 2.72727, cum reward/epoch -9.41054\n",
      "step 5880000, time 144769.5, loss 0.05087386, epochs 18656, reward/epoch 2.22727, cum reward/epoch -9.39682\n",
      "step 5890000, time 145016.5, loss 0.04947829, epochs 18679, reward/epoch 1.08696, cum reward/epoch -9.38391\n",
      "step 5900000, time 145263.7, loss 0.05015446, epochs 18699, reward/epoch 4.75000, cum reward/epoch -9.36879\n",
      "step 5910000, time 145511.0, loss 0.04970710, epochs 18723, reward/epoch 3.25000, cum reward/epoch -9.35261\n",
      "step 5920000, time 145758.6, loss 0.04919716, epochs 18747, reward/epoch 1.79167, cum reward/epoch -9.33835\n",
      "step 5930000, time 146006.1, loss 0.04913549, epochs 18765, reward/epoch -2.16667, cum reward/epoch -9.33147\n",
      "step 5940000, time 146253.8, loss 0.04883247, epochs 18792, reward/epoch -1.51852, cum reward/epoch -9.32024\n",
      "step 5950000, time 146501.9, loss 0.05078727, epochs 18813, reward/epoch 4.76190, cum reward/epoch -9.30452\n",
      "step 5960000, time 146749.8, loss 0.04941940, epochs 18837, reward/epoch 3.66667, cum reward/epoch -9.28800\n",
      "step 5970000, time 146997.8, loss 0.05000191, epochs 18859, reward/epoch 2.27273, cum reward/epoch -9.27451\n",
      "step 5980000, time 147246.2, loss 0.05038031, epochs 18877, reward/epoch 1.44444, cum reward/epoch -9.26429\n",
      "step 5990000, time 147493.9, loss 0.05070342, epochs 18903, reward/epoch 1.61538, cum reward/epoch -9.24933\n",
      "step 6000000, time 147741.3, loss 0.04889010, epochs 18924, reward/epoch 0.23810, cum reward/epoch -9.23880\n",
      "step 6010000, time 147989.4, loss 0.05033370, epochs 18944, reward/epoch -0.80000, cum reward/epoch -9.22989\n",
      "step 6020000, time 148238.3, loss 0.05038004, epochs 18969, reward/epoch -1.76000, cum reward/epoch -9.22004\n",
      "step 6030000, time 148486.9, loss 0.04971061, epochs 18990, reward/epoch 0.90476, cum reward/epoch -9.20885\n",
      "step 6040000, time 148735.1, loss 0.04944400, epochs 19013, reward/epoch -0.21739, cum reward/epoch -9.19797\n",
      "step 6050000, time 148982.7, loss 0.04966591, epochs 19032, reward/epoch 0.26316, cum reward/epoch -9.18852\n",
      "step 6060000, time 149230.3, loss 0.05141988, epochs 19055, reward/epoch 4.82609, cum reward/epoch -9.17161\n",
      "step 6070000, time 149478.7, loss 0.05072064, epochs 19079, reward/epoch 2.41667, cum reward/epoch -9.15703\n",
      "step 6080000, time 149726.6, loss 0.05073010, epochs 19104, reward/epoch 2.80000, cum reward/epoch -9.14138\n",
      "step 6090000, time 149974.2, loss 0.05053423, epochs 19126, reward/epoch 4.13636, cum reward/epoch -9.12611\n",
      "step 6100000, time 150221.8, loss 0.05051341, epochs 19150, reward/epoch 1.45833, cum reward/epoch -9.11285\n",
      "step 6110000, time 150469.5, loss 0.05048957, epochs 19168, reward/epoch 0.27778, cum reward/epoch -9.10403\n",
      "step 6120000, time 150717.6, loss 0.05021626, epochs 19196, reward/epoch 0.78571, cum reward/epoch -9.08960\n",
      "step 6130000, time 150965.6, loss 0.04874956, epochs 19214, reward/epoch 2.38889, cum reward/epoch -9.07885\n",
      "step 6140000, time 151213.4, loss 0.05022117, epochs 19236, reward/epoch 4.86364, cum reward/epoch -9.06290\n",
      "step 6150000, time 151462.4, loss 0.05044768, epochs 19260, reward/epoch 2.16667, cum reward/epoch -9.04891\n",
      "step 6160000, time 151710.8, loss 0.05062648, epochs 19281, reward/epoch -2.23810, cum reward/epoch -9.04149\n",
      "step 6170000, time 151959.5, loss 0.04960063, epochs 19305, reward/epoch 3.83333, cum reward/epoch -9.02549\n",
      "step 6180000, time 152208.1, loss 0.05007337, epochs 19325, reward/epoch 5.40000, cum reward/epoch -9.01056\n",
      "step 6190000, time 152456.7, loss 0.04930980, epochs 19349, reward/epoch 2.95833, cum reward/epoch -8.99571\n",
      "step 6200000, time 152704.5, loss 0.05117044, epochs 19377, reward/epoch -3.42857, cum reward/epoch -8.98767\n",
      "step 6210000, time 152953.1, loss 0.05154027, epochs 19397, reward/epoch -6.70000, cum reward/epoch -8.98531\n",
      "step 6220000, time 153201.9, loss 0.05058011, epochs 19420, reward/epoch 1.95652, cum reward/epoch -8.97235\n",
      "step 6230000, time 153450.7, loss 0.05018891, epochs 19444, reward/epoch 2.16667, cum reward/epoch -8.95860\n",
      "step 6240000, time 153699.0, loss 0.05035977, epochs 19464, reward/epoch 4.95000, cum reward/epoch -8.94431\n",
      "step 6250000, time 153946.9, loss 0.05024783, epochs 19488, reward/epoch -0.62500, cum reward/epoch -8.93406\n",
      "step 6260000, time 154195.0, loss 0.05142788, epochs 19512, reward/epoch 0.50000, cum reward/epoch -8.92246\n",
      "step 6270000, time 154444.4, loss 0.04945143, epochs 19535, reward/epoch 0.60870, cum reward/epoch -8.91124\n",
      "step 6280000, time 154692.1, loss 0.05135585, epochs 19558, reward/epoch -3.00000, cum reward/epoch -8.90428\n",
      "step 6290000, time 154940.0, loss 0.04965582, epochs 19581, reward/epoch -2.34783, cum reward/epoch -8.89658\n",
      "step 6300000, time 155188.5, loss 0.05001443, epochs 19603, reward/epoch 2.90909, cum reward/epoch -8.88333\n",
      "step 6310000, time 155437.2, loss 0.05151230, epochs 19629, reward/epoch -2.76923, cum reward/epoch -8.87524\n",
      "step 6320000, time 155685.3, loss 0.05290126, epochs 19652, reward/epoch -5.13043, cum reward/epoch -8.87085\n",
      "step 6330000, time 155933.4, loss 0.04983234, epochs 19677, reward/epoch 3.32000, cum reward/epoch -8.85536\n",
      "step 6340000, time 156181.5, loss 0.04963906, epochs 19700, reward/epoch 5.13043, cum reward/epoch -8.83904\n",
      "step 6350000, time 156430.4, loss 0.04988514, epochs 19720, reward/epoch 2.30000, cum reward/epoch -8.82774\n",
      "step 6360000, time 156677.9, loss 0.04953866, epochs 19745, reward/epoch 3.76000, cum reward/epoch -8.81180\n",
      "step 6370000, time 156926.1, loss 0.05030403, epochs 19767, reward/epoch 1.22727, cum reward/epoch -8.80063\n",
      "step 6380000, time 157174.0, loss 0.05051659, epochs 19793, reward/epoch 2.96154, cum reward/epoch -8.78518\n",
      "step 6390000, time 157422.7, loss 0.04991211, epochs 19819, reward/epoch 3.61538, cum reward/epoch -8.76891\n",
      "step 6400000, time 157672.0, loss 0.05122150, epochs 19841, reward/epoch 2.95455, cum reward/epoch -8.75591\n",
      "step 6410000, time 157920.2, loss 0.04999629, epochs 19864, reward/epoch 3.04348, cum reward/epoch -8.74225\n",
      "step 6420000, time 158168.8, loss 0.05095340, epochs 19888, reward/epoch 2.25000, cum reward/epoch -8.72898\n",
      "step 6430000, time 158417.0, loss 0.05356726, epochs 19916, reward/epoch -7.78571, cum reward/epoch -8.72766\n",
      "step 6440000, time 158664.9, loss 0.05081044, epochs 19939, reward/epoch 3.73913, cum reward/epoch -8.71328\n",
      "step 6450000, time 158912.3, loss 0.05076021, epochs 19964, reward/epoch 3.00000, cum reward/epoch -8.69861\n",
      "step 6460000, time 159160.4, loss 0.05065928, epochs 19987, reward/epoch -1.56522, cum reward/epoch -8.69040\n",
      "step 6470000, time 159408.7, loss 0.05000402, epochs 20011, reward/epoch 0.50000, cum reward/epoch -8.67938\n",
      "step 6480000, time 159656.4, loss 0.05031119, epochs 20034, reward/epoch 2.34783, cum reward/epoch -8.66672\n",
      "step 6490000, time 159904.6, loss 0.05156530, epochs 20059, reward/epoch 2.52000, cum reward/epoch -8.65277\n",
      "step 6500000, time 160153.0, loss 0.05096859, epochs 20079, reward/epoch 0.10000, cum reward/epoch -8.64406\n",
      "step 6510000, time 160402.2, loss 0.04995215, epochs 20103, reward/epoch 0.45833, cum reward/epoch -8.63319\n",
      "step 6520000, time 160651.0, loss 0.05299096, epochs 20128, reward/epoch 1.88000, cum reward/epoch -8.62013\n",
      "step 6530000, time 160899.3, loss 0.05107862, epochs 20150, reward/epoch 2.63636, cum reward/epoch -8.60784\n",
      "step 6540000, time 161147.4, loss 0.05122515, epochs 20173, reward/epoch 4.34783, cum reward/epoch -8.59307\n",
      "step 6550000, time 161395.4, loss 0.05125248, epochs 20199, reward/epoch 0.92308, cum reward/epoch -8.58082\n",
      "step 6560000, time 161643.5, loss 0.05088128, epochs 20217, reward/epoch 2.50000, cum reward/epoch -8.57096\n",
      "step 6570000, time 161892.1, loss 0.04965530, epochs 20242, reward/epoch 1.96000, cum reward/epoch -8.55795\n",
      "step 6580000, time 162139.6, loss 0.05020507, epochs 20263, reward/epoch 0.47619, cum reward/epoch -8.54859\n",
      "step 6590000, time 162387.7, loss 0.05002822, epochs 20289, reward/epoch -3.80769, cum reward/epoch -8.54251\n",
      "step 6600000, time 162636.2, loss 0.04963059, epochs 20312, reward/epoch -4.60870, cum reward/epoch -8.53806\n",
      "step 6610000, time 162885.2, loss 0.05313845, epochs 20338, reward/epoch -6.46154, cum reward/epoch -8.53540\n",
      "step 6620000, time 163134.3, loss 0.05059728, epochs 20359, reward/epoch 0.76190, cum reward/epoch -8.52581\n",
      "step 6630000, time 163383.3, loss 0.05090397, epochs 20384, reward/epoch 3.32000, cum reward/epoch -8.51128\n",
      "step 6640000, time 163632.4, loss 0.05053241, epochs 20405, reward/epoch 4.04762, cum reward/epoch -8.49836\n",
      "step 6650000, time 163882.8, loss 0.04928149, epochs 20428, reward/epoch 2.69565, cum reward/epoch -8.48575\n",
      "step 6660000, time 164132.3, loss 0.04947239, epochs 20450, reward/epoch 4.22727, cum reward/epoch -8.47208\n",
      "step 6670000, time 164381.0, loss 0.04932616, epochs 20473, reward/epoch 4.39130, cum reward/epoch -8.45763\n",
      "step 6680000, time 164630.1, loss 0.04941471, epochs 20495, reward/epoch 4.72727, cum reward/epoch -8.44347\n",
      "step 6690000, time 164878.4, loss 0.05005362, epochs 20520, reward/epoch 5.52000, cum reward/epoch -8.42646\n",
      "step 6700000, time 165127.1, loss 0.05073885, epochs 20545, reward/epoch 4.44000, cum reward/epoch -8.41081\n",
      "step 6710000, time 165376.1, loss 0.04910996, epochs 20565, reward/epoch 5.40000, cum reward/epoch -8.39737\n",
      "step 6720000, time 165625.0, loss 0.04981141, epochs 20588, reward/epoch 6.17391, cum reward/epoch -8.38110\n",
      "step 6730000, time 165873.6, loss 0.05011738, epochs 20610, reward/epoch 2.22727, cum reward/epoch -8.36977\n",
      "step 6740000, time 166122.3, loss 0.05174186, epochs 20639, reward/epoch -3.41379, cum reward/epoch -8.36281\n",
      "step 6750000, time 166370.2, loss 0.05052465, epochs 20661, reward/epoch 6.04545, cum reward/epoch -8.34747\n",
      "step 6760000, time 166619.0, loss 0.04999045, epochs 20688, reward/epoch 4.55556, cum reward/epoch -8.33063\n",
      "step 6770000, time 166868.5, loss 0.04927054, epochs 20712, reward/epoch 7.04167, cum reward/epoch -8.31281\n",
      "step 6780000, time 167117.3, loss 0.04965552, epochs 20733, reward/epoch 3.33333, cum reward/epoch -8.30102\n",
      "step 6790000, time 167366.8, loss 0.05298077, epochs 20761, reward/epoch -3.60714, cum reward/epoch -8.29469\n",
      "step 6800000, time 167616.1, loss 0.05122435, epochs 20786, reward/epoch 4.08000, cum reward/epoch -8.27980\n",
      "step 6810000, time 167864.8, loss 0.05034551, epochs 20808, reward/epoch 2.36364, cum reward/epoch -8.26855\n",
      "step 6820000, time 168113.2, loss 0.05113036, epochs 20832, reward/epoch 0.37500, cum reward/epoch -8.25859\n",
      "step 6830000, time 168362.0, loss 0.05203629, epochs 20861, reward/epoch -2.55172, cum reward/epoch -8.25066\n",
      "step 6840000, time 168611.2, loss 0.05266080, epochs 20885, reward/epoch 2.58333, cum reward/epoch -8.23821\n",
      "step 6850000, time 168859.6, loss 0.05113959, epochs 20909, reward/epoch 2.79167, cum reward/epoch -8.22555\n",
      "step 6860000, time 169108.5, loss 0.04982368, epochs 20933, reward/epoch 2.04167, cum reward/epoch -8.21378\n",
      "step 6870000, time 169357.7, loss 0.05096608, epochs 20957, reward/epoch 4.00000, cum reward/epoch -8.19979\n",
      "step 6880000, time 169607.4, loss 0.05209577, epochs 20978, reward/epoch -0.09524, cum reward/epoch -8.19168\n",
      "step 6890000, time 169856.2, loss 0.05315923, epochs 21006, reward/epoch -0.57143, cum reward/epoch -8.18152\n",
      "step 6900000, time 170105.6, loss 0.05005256, epochs 21029, reward/epoch -0.47826, cum reward/epoch -8.17309\n",
      "step 6910000, time 170354.5, loss 0.05083161, epochs 21052, reward/epoch 0.82609, cum reward/epoch -8.16326\n",
      "step 6920000, time 170603.8, loss 0.05112797, epochs 21075, reward/epoch 2.39130, cum reward/epoch -8.15174\n",
      "step 6930000, time 170854.0, loss 0.05386766, epochs 21104, reward/epoch -6.55172, cum reward/epoch -8.14954\n",
      "step 6940000, time 171104.3, loss 0.05148694, epochs 21127, reward/epoch 3.21739, cum reward/epoch -8.13717\n",
      "step 6950000, time 171354.0, loss 0.05060765, epochs 21150, reward/epoch 3.65217, cum reward/epoch -8.12435\n",
      "step 6960000, time 171602.8, loss 0.04985213, epochs 21170, reward/epoch 4.60000, cum reward/epoch -8.11233\n",
      "step 6970000, time 171852.2, loss 0.04955071, epochs 21193, reward/epoch 1.43478, cum reward/epoch -8.10197\n",
      "step 6980000, time 172100.9, loss 0.05073750, epochs 21215, reward/epoch 0.18182, cum reward/epoch -8.09338\n",
      "step 6990000, time 172350.0, loss 0.05047382, epochs 21242, reward/epoch 3.74074, cum reward/epoch -8.07834\n",
      "step 7000000, time 172598.3, loss 0.05014908, epochs 21264, reward/epoch 2.09091, cum reward/epoch -8.06781\n",
      "step 7010000, time 172847.7, loss 0.05086167, epochs 21287, reward/epoch 4.95652, cum reward/epoch -8.05374\n",
      "step 7020000, time 173096.7, loss 0.04975873, epochs 21313, reward/epoch 4.80769, cum reward/epoch -8.03805\n",
      "step 7030000, time 173346.3, loss 0.04952701, epochs 21332, reward/epoch 2.73684, cum reward/epoch -8.02845\n",
      "step 7040000, time 173596.1, loss 0.04967467, epochs 21356, reward/epoch 1.95833, cum reward/epoch -8.01723\n",
      "step 7050000, time 173845.8, loss 0.04936258, epochs 21380, reward/epoch 3.25000, cum reward/epoch -8.00458\n",
      "step 7060000, time 174095.0, loss 0.05021907, epochs 21404, reward/epoch 4.83333, cum reward/epoch -7.99019\n",
      "step 7070000, time 174343.7, loss 0.05157645, epochs 21429, reward/epoch -3.16000, cum reward/epoch -7.98455\n",
      "step 7080000, time 174592.7, loss 0.05274411, epochs 21456, reward/epoch -4.59259, cum reward/epoch -7.98029\n",
      "step 7090000, time 174841.9, loss 0.05217748, epochs 21482, reward/epoch 3.07692, cum reward/epoch -7.96690\n",
      "step 7100000, time 175091.5, loss 0.05063451, epochs 21506, reward/epoch 3.66667, cum reward/epoch -7.95392\n",
      "step 7110000, time 175341.1, loss 0.04971505, epochs 21530, reward/epoch 1.33333, cum reward/epoch -7.94357\n",
      "step 7120000, time 175590.8, loss 0.04995512, epochs 21554, reward/epoch 0.45833, cum reward/epoch -7.93421\n",
      "step 7130000, time 175840.0, loss 0.05151032, epochs 21575, reward/epoch 1.42857, cum reward/epoch -7.92510\n",
      "step 7140000, time 176088.7, loss 0.05064895, epochs 21602, reward/epoch 0.44444, cum reward/epoch -7.91464\n",
      "step 7150000, time 176338.1, loss 0.04995463, epochs 21622, reward/epoch 4.50000, cum reward/epoch -7.90315\n",
      "step 7160000, time 176587.6, loss 0.04965229, epochs 21646, reward/epoch 0.83333, cum reward/epoch -7.89347\n",
      "step 7170000, time 176836.7, loss 0.05025404, epochs 21669, reward/epoch 1.30435, cum reward/epoch -7.88370\n",
      "step 7180000, time 177086.0, loss 0.05034668, epochs 21693, reward/epoch 2.79167, cum reward/epoch -7.87189\n",
      "step 7190000, time 177335.4, loss 0.05211736, epochs 21718, reward/epoch -3.12000, cum reward/epoch -7.86642\n",
      "step 7200000, time 177584.3, loss 0.05183179, epochs 21742, reward/epoch 3.58333, cum reward/epoch -7.85379\n",
      "step 7210000, time 177833.3, loss 0.05041089, epochs 21765, reward/epoch 5.26087, cum reward/epoch -7.83993\n",
      "step 7220000, time 178082.1, loss 0.05066911, epochs 21790, reward/epoch 2.88000, cum reward/epoch -7.82763\n",
      "step 7230000, time 178331.5, loss 0.04914116, epochs 21815, reward/epoch 3.80000, cum reward/epoch -7.81430\n",
      "step 7240000, time 178580.4, loss 0.05034639, epochs 21838, reward/epoch 4.00000, cum reward/epoch -7.80186\n",
      "step 7250000, time 178829.4, loss 0.04991791, epochs 21860, reward/epoch 2.27273, cum reward/epoch -7.79172\n",
      "step 7260000, time 179079.6, loss 0.04983709, epochs 21886, reward/epoch 3.15385, cum reward/epoch -7.77872\n",
      "step 7270000, time 179328.5, loss 0.04947034, epochs 21907, reward/epoch 2.76190, cum reward/epoch -7.76861\n",
      "step 7280000, time 179578.3, loss 0.04887776, epochs 21932, reward/epoch 3.72000, cum reward/epoch -7.75552\n",
      "step 7290000, time 179827.8, loss 0.05001305, epochs 21954, reward/epoch 0.54545, cum reward/epoch -7.74720\n",
      "step 7300000, time 180078.0, loss 0.05135192, epochs 21980, reward/epoch 2.19231, cum reward/epoch -7.73544\n",
      "step 7310000, time 180328.0, loss 0.05141428, epochs 22002, reward/epoch 4.18182, cum reward/epoch -7.72353\n",
      "step 7320000, time 180577.9, loss 0.05009215, epochs 22026, reward/epoch 5.29167, cum reward/epoch -7.70934\n",
      "step 7330000, time 180827.3, loss 0.05084328, epochs 22048, reward/epoch 3.31818, cum reward/epoch -7.69834\n",
      "step 7340000, time 181077.5, loss 0.04948731, epochs 22073, reward/epoch 3.68000, cum reward/epoch -7.68545\n",
      "step 7350000, time 181326.8, loss 0.05028738, epochs 22096, reward/epoch 4.78261, cum reward/epoch -7.67247\n",
      "step 7360000, time 181576.1, loss 0.05021225, epochs 22120, reward/epoch -0.83333, cum reward/epoch -7.66505\n",
      "step 7370000, time 181826.2, loss 0.05020478, epochs 22143, reward/epoch 1.91304, cum reward/epoch -7.65511\n",
      "step 7380000, time 182076.0, loss 0.04988121, epochs 22167, reward/epoch 1.29167, cum reward/epoch -7.64542\n",
      "step 7390000, time 182325.4, loss 0.04944649, epochs 22190, reward/epoch 1.26087, cum reward/epoch -7.63619\n",
      "step 7400000, time 182574.7, loss 0.05002647, epochs 22212, reward/epoch 0.09091, cum reward/epoch -7.62853\n",
      "step 7410000, time 182824.3, loss 0.05005614, epochs 22235, reward/epoch -2.73913, cum reward/epoch -7.62348\n",
      "step 7420000, time 183073.7, loss 0.05013772, epochs 22260, reward/epoch 1.52000, cum reward/epoch -7.61321\n",
      "step 7430000, time 183325.2, loss 0.04953963, epochs 22283, reward/epoch 4.13043, cum reward/epoch -7.60109\n",
      "step 7440000, time 183574.9, loss 0.04981565, epochs 22307, reward/epoch 2.12500, cum reward/epoch -7.59062\n",
      "step 7450000, time 183825.6, loss 0.04952723, epochs 22330, reward/epoch 2.73913, cum reward/epoch -7.57998\n",
      "step 7460000, time 184076.3, loss 0.04969935, epochs 22353, reward/epoch 3.04348, cum reward/epoch -7.56905\n",
      "step 7470000, time 184326.8, loss 0.04979737, epochs 22378, reward/epoch 0.24000, cum reward/epoch -7.56033\n",
      "step 7480000, time 184576.9, loss 0.05119393, epochs 22401, reward/epoch 0.13043, cum reward/epoch -7.55243\n",
      "step 7490000, time 184826.6, loss 0.05040212, epochs 22426, reward/epoch 0.16000, cum reward/epoch -7.54383\n",
      "step 7500000, time 185076.5, loss 0.05052329, epochs 22449, reward/epoch 0.86957, cum reward/epoch -7.53521\n",
      "step 7510000, time 185326.5, loss 0.05052942, epochs 22474, reward/epoch 5.00000, cum reward/epoch -7.52127\n",
      "step 7520000, time 185576.5, loss 0.05148368, epochs 22498, reward/epoch -1.20833, cum reward/epoch -7.51453\n",
      "step 7530000, time 185825.7, loss 0.04990601, epochs 22520, reward/epoch 4.04545, cum reward/epoch -7.50324\n",
      "step 7540000, time 186075.9, loss 0.05010488, epochs 22545, reward/epoch 2.56000, cum reward/epoch -7.49208\n",
      "step 7550000, time 186325.3, loss 0.04950262, epochs 22566, reward/epoch 5.57143, cum reward/epoch -7.47993\n",
      "step 7560000, time 186574.3, loss 0.04910769, epochs 22588, reward/epoch 4.31818, cum reward/epoch -7.46843\n",
      "step 7570000, time 186823.8, loss 0.05060851, epochs 22614, reward/epoch 4.65385, cum reward/epoch -7.45450\n",
      "step 7580000, time 187073.0, loss 0.04959661, epochs 22638, reward/epoch 4.20833, cum reward/epoch -7.44213\n",
      "step 7590000, time 187322.3, loss 0.04939718, epochs 22663, reward/epoch 4.44000, cum reward/epoch -7.42903\n",
      "step 7600000, time 187571.6, loss 0.05059345, epochs 22687, reward/epoch 4.29167, cum reward/epoch -7.41663\n",
      "step 7610000, time 187821.8, loss 0.05032040, epochs 22709, reward/epoch 3.13636, cum reward/epoch -7.40640\n",
      "step 7620000, time 188072.0, loss 0.04919506, epochs 22731, reward/epoch 2.40909, cum reward/epoch -7.39690\n",
      "step 7630000, time 188321.8, loss 0.05016765, epochs 22754, reward/epoch 2.78261, cum reward/epoch -7.38661\n",
      "step 7640000, time 188573.2, loss 0.04926819, epochs 22782, reward/epoch 5.25000, cum reward/epoch -7.37108\n",
      "step 7650000, time 188823.9, loss 0.04863830, epochs 22802, reward/epoch 5.20000, cum reward/epoch -7.36006\n",
      "step 7660000, time 189073.5, loss 0.05105998, epochs 22828, reward/epoch -1.11538, cum reward/epoch -7.35294\n",
      "step 7670000, time 189323.8, loss 0.05088560, epochs 22852, reward/epoch 1.04167, cum reward/epoch -7.34413\n",
      "step 7680000, time 189573.6, loss 0.05012678, epochs 22877, reward/epoch 2.64000, cum reward/epoch -7.33322\n",
      "step 7690000, time 189823.8, loss 0.05182753, epochs 22902, reward/epoch -6.60000, cum reward/epoch -7.33242\n",
      "step 7700000, time 190073.5, loss 0.05104756, epochs 22925, reward/epoch 1.69565, cum reward/epoch -7.32336\n",
      "step 7710000, time 190323.4, loss 0.05037425, epochs 22947, reward/epoch 3.63636, cum reward/epoch -7.31285\n",
      "step 7720000, time 190572.7, loss 0.04974340, epochs 22969, reward/epoch 4.04545, cum reward/epoch -7.30197\n",
      "step 7730000, time 190822.1, loss 0.04941652, epochs 22991, reward/epoch 3.36364, cum reward/epoch -7.29177\n",
      "step 7740000, time 191071.3, loss 0.04892990, epochs 23015, reward/epoch 0.91667, cum reward/epoch -7.28321\n",
      "step 7750000, time 191320.9, loss 0.04926542, epochs 23038, reward/epoch 5.43478, cum reward/epoch -7.27051\n",
      "step 7760000, time 191571.0, loss 0.04924706, epochs 23060, reward/epoch 4.72727, cum reward/epoch -7.25906\n",
      "step 7770000, time 191821.0, loss 0.04913822, epochs 23080, reward/epoch 2.40000, cum reward/epoch -7.25069\n",
      "step 7780000, time 192070.4, loss 0.04961358, epochs 23105, reward/epoch 2.16000, cum reward/epoch -7.24051\n",
      "step 7790000, time 192321.1, loss 0.04990473, epochs 23124, reward/epoch 1.00000, cum reward/epoch -7.23374\n",
      "step 7800000, time 192571.2, loss 0.04881716, epochs 23150, reward/epoch 5.07692, cum reward/epoch -7.21991\n",
      "step 7810000, time 192820.6, loss 0.04963552, epochs 23172, reward/epoch 4.81818, cum reward/epoch -7.20848\n",
      "step 7820000, time 193069.8, loss 0.04971752, epochs 23194, reward/epoch 3.22727, cum reward/epoch -7.19859\n",
      "step 7830000, time 193318.7, loss 0.04921046, epochs 23219, reward/epoch 5.20000, cum reward/epoch -7.18524\n",
      "step 7840000, time 193569.3, loss 0.05005433, epochs 23242, reward/epoch 2.86957, cum reward/epoch -7.17529\n",
      "step 7850000, time 193819.0, loss 0.04960189, epochs 23268, reward/epoch 5.15385, cum reward/epoch -7.16151\n",
      "step 7860000, time 194068.8, loss 0.04825849, epochs 23289, reward/epoch 5.19048, cum reward/epoch -7.15037\n",
      "step 7870000, time 194317.9, loss 0.04964343, epochs 23314, reward/epoch 4.80000, cum reward/epoch -7.13756\n",
      "step 7880000, time 194568.0, loss 0.04988737, epochs 23336, reward/epoch 4.77273, cum reward/epoch -7.12633\n",
      "step 7890000, time 194817.6, loss 0.04907198, epochs 23358, reward/epoch 6.50000, cum reward/epoch -7.11349\n",
      "step 7900000, time 195067.3, loss 0.04917831, epochs 23382, reward/epoch 0.87500, cum reward/epoch -7.10529\n",
      "step 7910000, time 195316.9, loss 0.05011413, epochs 23401, reward/epoch 4.84211, cum reward/epoch -7.09559\n",
      "step 7920000, time 195567.0, loss 0.04942857, epochs 23428, reward/epoch 5.44444, cum reward/epoch -7.08114\n",
      "step 7930000, time 195817.3, loss 0.04927622, epochs 23449, reward/epoch 5.85714, cum reward/epoch -7.06956\n",
      "step 7940000, time 196067.0, loss 0.04970302, epochs 23473, reward/epoch 4.25000, cum reward/epoch -7.05798\n",
      "step 7950000, time 196316.7, loss 0.04937278, epochs 23492, reward/epoch 2.68421, cum reward/epoch -7.05010\n",
      "step 7960000, time 196566.8, loss 0.04896264, epochs 23516, reward/epoch 5.20833, cum reward/epoch -7.03759\n",
      "step 7970000, time 196816.1, loss 0.04967563, epochs 23536, reward/epoch 2.70000, cum reward/epoch -7.02932\n",
      "step 7980000, time 197065.7, loss 0.05076696, epochs 23561, reward/epoch 1.60000, cum reward/epoch -7.02016\n",
      "step 7990000, time 197315.8, loss 0.05005123, epochs 23583, reward/epoch -0.04545, cum reward/epoch -7.01365\n",
      "step 8000000, time 197566.2, loss 0.05055552, epochs 23607, reward/epoch 3.25000, cum reward/epoch -7.00322\n",
      "step 8010000, time 197816.0, loss 0.04861525, epochs 23629, reward/epoch 0.77273, cum reward/epoch -6.99598\n",
      "step 8020000, time 198066.7, loss 0.04910669, epochs 23653, reward/epoch 1.50000, cum reward/epoch -6.98736\n",
      "step 8030000, time 198316.5, loss 0.04981286, epochs 23676, reward/epoch 5.56522, cum reward/epoch -6.97516\n",
      "step 8040000, time 198566.8, loss 0.05049872, epochs 23701, reward/epoch 4.92000, cum reward/epoch -6.96262\n",
      "step 8050000, time 198817.6, loss 0.05053338, epochs 23723, reward/epoch 2.77273, cum reward/epoch -6.95359\n",
      "step 8060000, time 199068.9, loss 0.04869090, epochs 23744, reward/epoch 5.47619, cum reward/epoch -6.94260\n",
      "step 8070000, time 199318.4, loss 0.05001287, epochs 23768, reward/epoch 4.16667, cum reward/epoch -6.93138\n",
      "step 8080000, time 199568.7, loss 0.05134797, epochs 23791, reward/epoch 3.78261, cum reward/epoch -6.92102\n",
      "step 8090000, time 199818.8, loss 0.04965018, epochs 23814, reward/epoch 5.04348, cum reward/epoch -6.90946\n",
      "step 8100000, time 200068.9, loss 0.05030861, epochs 23837, reward/epoch 3.56522, cum reward/epoch -6.89936\n",
      "step 8110000, time 200319.4, loss 0.05000906, epochs 23859, reward/epoch 3.18182, cum reward/epoch -6.89006\n",
      "step 8120000, time 200568.9, loss 0.05079317, epochs 23881, reward/epoch 2.50000, cum reward/epoch -6.88141\n",
      "step 8130000, time 200819.7, loss 0.05062129, epochs 23905, reward/epoch 3.87500, cum reward/epoch -6.87061\n",
      "step 8140000, time 201070.0, loss 0.05133262, epochs 23929, reward/epoch -3.50000, cum reward/epoch -6.86723\n",
      "step 8150000, time 201320.5, loss 0.05163412, epochs 23953, reward/epoch 2.00000, cum reward/epoch -6.85835\n",
      "step 8160000, time 201570.4, loss 0.04971591, epochs 23976, reward/epoch 4.56522, cum reward/epoch -6.84739\n",
      "step 8170000, time 201821.4, loss 0.05020250, epochs 24001, reward/epoch 3.24000, cum reward/epoch -6.83688\n",
      "step 8180000, time 202072.4, loss 0.05018089, epochs 24021, reward/epoch 6.80000, cum reward/epoch -6.82553\n",
      "step 8190000, time 202321.8, loss 0.04977958, epochs 24043, reward/epoch 4.00000, cum reward/epoch -6.81562\n",
      "step 8200000, time 202572.7, loss 0.04915441, epochs 24067, reward/epoch 2.04167, cum reward/epoch -6.80679\n",
      "step 8210000, time 202822.5, loss 0.04959654, epochs 24088, reward/epoch 1.23810, cum reward/epoch -6.79978\n",
      "step 8220000, time 203072.8, loss 0.04995539, epochs 24112, reward/epoch 5.66667, cum reward/epoch -6.78737\n",
      "step 8230000, time 203322.1, loss 0.05258818, epochs 24138, reward/epoch -4.15385, cum reward/epoch -6.78453\n",
      "step 8240000, time 203571.9, loss 0.04994457, epochs 24161, reward/epoch 5.47826, cum reward/epoch -6.77286\n",
      "step 8250000, time 203821.2, loss 0.05155057, epochs 24185, reward/epoch 3.95833, cum reward/epoch -6.76221\n",
      "step 8260000, time 204071.3, loss 0.04939649, epochs 24208, reward/epoch 5.56522, cum reward/epoch -6.75050\n",
      "step 8270000, time 204321.2, loss 0.04912321, epochs 24235, reward/epoch 4.18518, cum reward/epoch -6.73831\n",
      "step 8280000, time 204570.9, loss 0.04927668, epochs 24256, reward/epoch -0.76190, cum reward/epoch -6.73314\n",
      "step 8290000, time 204820.9, loss 0.04901321, epochs 24281, reward/epoch 2.16000, cum reward/epoch -6.72398\n",
      "step 8300000, time 205070.1, loss 0.04924989, epochs 24303, reward/epoch 1.22727, cum reward/epoch -6.71678\n",
      "step 8310000, time 205320.0, loss 0.05076533, epochs 24327, reward/epoch 3.87500, cum reward/epoch -6.70633\n",
      "step 8320000, time 205570.1, loss 0.05046282, epochs 24348, reward/epoch 2.04762, cum reward/epoch -6.69878\n",
      "step 8330000, time 205820.0, loss 0.04922945, epochs 24371, reward/epoch 7.34783, cum reward/epoch -6.68553\n",
      "step 8340000, time 206070.7, loss 0.04943793, epochs 24395, reward/epoch 6.00000, cum reward/epoch -6.67305\n",
      "step 8350000, time 206321.2, loss 0.05475154, epochs 24420, reward/epoch -2.44000, cum reward/epoch -6.66871\n",
      "step 8360000, time 206571.3, loss 0.05016470, epochs 24444, reward/epoch 6.83333, cum reward/epoch -6.65546\n",
      "step 8370000, time 206822.8, loss 0.05106841, epochs 24469, reward/epoch 2.52000, cum reward/epoch -6.64608\n",
      "step 8380000, time 207072.9, loss 0.04959073, epochs 24491, reward/epoch 3.59091, cum reward/epoch -6.63689\n",
      "step 8390000, time 207324.8, loss 0.05194572, epochs 24518, reward/epoch -4.92593, cum reward/epoch -6.63500\n",
      "step 8400000, time 207575.5, loss 0.05056340, epochs 24538, reward/epoch 3.40000, cum reward/epoch -6.62682\n",
      "step 8410000, time 207826.2, loss 0.04848947, epochs 24564, reward/epoch 4.92308, cum reward/epoch -6.61460\n",
      "step 8420000, time 208077.4, loss 0.05004117, epochs 24585, reward/epoch 3.52381, cum reward/epoch -6.60594\n",
      "step 8430000, time 208327.6, loss 0.05005192, epochs 24608, reward/epoch 4.08696, cum reward/epoch -6.59594\n",
      "step 8440000, time 208578.8, loss 0.05021567, epochs 24632, reward/epoch 6.83333, cum reward/epoch -6.58286\n",
      "step 8450000, time 208828.8, loss 0.04987832, epochs 24660, reward/epoch 5.00000, cum reward/epoch -6.56971\n",
      "step 8460000, time 209079.4, loss 0.05048071, epochs 24681, reward/epoch 7.09524, cum reward/epoch -6.55808\n",
      "step 8470000, time 209330.4, loss 0.04980423, epochs 24706, reward/epoch 4.80000, cum reward/epoch -6.54659\n",
      "step 8480000, time 209581.1, loss 0.04915620, epochs 24728, reward/epoch 5.36364, cum reward/epoch -6.53599\n",
      "step 8490000, time 209832.7, loss 0.05026871, epochs 24752, reward/epoch 4.75000, cum reward/epoch -6.52505\n",
      "step 8500000, time 210083.8, loss 0.04968426, epochs 24774, reward/epoch 5.72727, cum reward/epoch -6.51417\n",
      "step 8510000, time 210335.0, loss 0.04851413, epochs 24796, reward/epoch 5.72727, cum reward/epoch -6.50331\n",
      "step 8520000, time 210585.9, loss 0.04841836, epochs 24820, reward/epoch 4.83333, cum reward/epoch -6.49234\n",
      "step 8530000, time 210837.3, loss 0.04894161, epochs 24843, reward/epoch 7.13043, cum reward/epoch -6.47973\n",
      "step 8540000, time 211087.4, loss 0.04790307, epochs 24867, reward/epoch 6.75000, cum reward/epoch -6.46696\n",
      "step 8550000, time 211338.6, loss 0.04871766, epochs 24892, reward/epoch 5.08000, cum reward/epoch -6.45537\n",
      "step 8560000, time 211590.8, loss 0.05084975, epochs 24917, reward/epoch -2.04000, cum reward/epoch -6.45094\n",
      "step 8570000, time 211841.3, loss 0.05088028, epochs 24937, reward/epoch 2.25000, cum reward/epoch -6.44396\n",
      "step 8580000, time 212091.8, loss 0.04862801, epochs 24962, reward/epoch 3.72000, cum reward/epoch -6.43378\n",
      "step 8590000, time 212342.8, loss 0.05055398, epochs 24983, reward/epoch 3.38095, cum reward/epoch -6.42553\n",
      "step 8600000, time 212593.7, loss 0.04989164, epochs 25007, reward/epoch 7.00000, cum reward/epoch -6.41264\n",
      "step 8610000, time 212845.1, loss 0.04858937, epochs 25030, reward/epoch 7.73913, cum reward/epoch -6.39964\n",
      "step 8620000, time 213095.9, loss 0.04868858, epochs 25050, reward/epoch 1.15000, cum reward/epoch -6.39361\n",
      "step 8630000, time 213346.9, loss 0.04871587, epochs 25077, reward/epoch 3.55556, cum reward/epoch -6.38290\n",
      "step 8640000, time 213597.7, loss 0.04973454, epochs 25098, reward/epoch 5.00000, cum reward/epoch -6.37338\n",
      "step 8650000, time 213848.4, loss 0.05090892, epochs 25121, reward/epoch 0.52174, cum reward/epoch -6.36706\n",
      "step 8660000, time 214100.0, loss 0.04970365, epochs 25144, reward/epoch 2.56522, cum reward/epoch -6.35889\n",
      "step 8670000, time 214351.4, loss 0.04990298, epochs 25169, reward/epoch 3.80000, cum reward/epoch -6.34880\n",
      "step 8680000, time 214602.7, loss 0.04856725, epochs 25192, reward/epoch 5.13043, cum reward/epoch -6.33832\n",
      "step 8690000, time 214853.3, loss 0.04861888, epochs 25214, reward/epoch 3.13636, cum reward/epoch -6.33005\n",
      "step 8700000, time 215105.4, loss 0.04951626, epochs 25237, reward/epoch 1.65217, cum reward/epoch -6.32278\n",
      "step 8710000, time 215356.7, loss 0.05205339, epochs 25269, reward/epoch -5.25000, cum reward/epoch -6.32142\n",
      "step 8720000, time 215607.7, loss 0.05492485, epochs 25293, reward/epoch -0.95833, cum reward/epoch -6.31633\n",
      "step 8730000, time 215858.5, loss 0.05034669, epochs 25318, reward/epoch 6.76000, cum reward/epoch -6.30342\n",
      "step 8740000, time 216109.0, loss 0.04894558, epochs 25339, reward/epoch 4.23810, cum reward/epoch -6.29468\n",
      "step 8750000, time 216359.6, loss 0.04826593, epochs 25361, reward/epoch 6.04545, cum reward/epoch -6.28398\n",
      "step 8760000, time 216610.0, loss 0.04785967, epochs 25386, reward/epoch 3.72000, cum reward/epoch -6.27413\n",
      "step 8770000, time 216859.9, loss 0.04792523, epochs 25407, reward/epoch 3.04762, cum reward/epoch -6.26642\n",
      "step 8780000, time 217110.5, loss 0.04786463, epochs 25430, reward/epoch 6.91304, cum reward/epoch -6.25450\n",
      "step 8790000, time 217361.6, loss 0.04895030, epochs 25453, reward/epoch 6.26087, cum reward/epoch -6.24319\n",
      "step 8800000, time 217613.2, loss 0.04920310, epochs 25475, reward/epoch 5.54545, cum reward/epoch -6.23301\n",
      "step 8810000, time 217865.0, loss 0.04894821, epochs 25499, reward/epoch 4.33333, cum reward/epoch -6.22307\n",
      "step 8820000, time 218116.6, loss 0.04972652, epochs 25522, reward/epoch 4.00000, cum reward/epoch -6.21385\n",
      "step 8830000, time 218368.1, loss 0.04889505, epochs 25544, reward/epoch 6.27273, cum reward/epoch -6.20310\n",
      "step 8840000, time 218619.9, loss 0.04829815, epochs 25568, reward/epoch 4.79167, cum reward/epoch -6.19278\n",
      "step 8850000, time 218871.1, loss 0.04854805, epochs 25590, reward/epoch 7.27273, cum reward/epoch -6.18120\n",
      "step 8860000, time 219122.8, loss 0.04944493, epochs 25614, reward/epoch 6.16667, cum reward/epoch -6.16963\n",
      "step 8870000, time 219374.2, loss 0.04802404, epochs 25638, reward/epoch 5.37500, cum reward/epoch -6.15883\n",
      "step 8880000, time 219625.0, loss 0.04817474, epochs 25660, reward/epoch 5.54545, cum reward/epoch -6.14879\n",
      "step 8890000, time 219876.1, loss 0.04817398, epochs 25683, reward/epoch 7.00000, cum reward/epoch -6.13702\n",
      "step 8900000, time 220126.8, loss 0.04925672, epochs 25705, reward/epoch 4.63636, cum reward/epoch -6.12780\n",
      "step 8910000, time 220378.5, loss 0.04814157, epochs 25728, reward/epoch 6.86957, cum reward/epoch -6.11618\n",
      "step 8920000, time 220629.9, loss 0.04861169, epochs 25753, reward/epoch 4.28000, cum reward/epoch -6.10608\n",
      "step 8930000, time 220881.5, loss 0.04751122, epochs 25773, reward/epoch 4.20000, cum reward/epoch -6.09809\n",
      "step 8940000, time 221132.8, loss 0.05029003, epochs 25799, reward/epoch 5.30769, cum reward/epoch -6.08659\n",
      "step 8950000, time 221384.3, loss 0.05026561, epochs 25823, reward/epoch 2.04167, cum reward/epoch -6.07904\n",
      "step 8960000, time 221635.9, loss 0.04892002, epochs 25844, reward/epoch 5.61905, cum reward/epoch -6.06953\n",
      "step 8970000, time 221887.0, loss 0.04818884, epochs 25868, reward/epoch 5.87500, cum reward/epoch -6.05845\n",
      "step 8980000, time 222138.5, loss 0.04784127, epochs 25889, reward/epoch 4.66667, cum reward/epoch -6.04975\n",
      "step 8990000, time 222390.3, loss 0.04833330, epochs 25914, reward/epoch 7.52000, cum reward/epoch -6.03666\n",
      "step 9000000, time 222641.5, loss 0.04868142, epochs 25938, reward/epoch 7.16667, cum reward/epoch -6.02444\n",
      "step 9010000, time 222892.7, loss 0.04716073, epochs 25959, reward/epoch 7.61905, cum reward/epoch -6.01341\n",
      "step 9020000, time 223144.2, loss 0.04801314, epochs 25984, reward/epoch 3.28000, cum reward/epoch -6.00446\n",
      "step 9030000, time 223396.3, loss 0.04759197, epochs 26007, reward/epoch 7.65217, cum reward/epoch -5.99239\n",
      "step 9040000, time 223648.1, loss 0.04805377, epochs 26034, reward/epoch 7.22222, cum reward/epoch -5.97868\n",
      "step 9050000, time 223899.8, loss 0.04755509, epochs 26056, reward/epoch 7.04545, cum reward/epoch -5.96769\n",
      "step 9060000, time 224152.0, loss 0.04818114, epochs 26080, reward/epoch 3.20833, cum reward/epoch -5.95924\n",
      "step 9070000, time 224403.4, loss 0.04808357, epochs 26099, reward/epoch 8.57895, cum reward/epoch -5.94866\n",
      "step 9080000, time 224655.3, loss 0.04882288, epochs 26122, reward/epoch 6.56522, cum reward/epoch -5.93764\n",
      "step 9090000, time 224907.1, loss 0.04759938, epochs 26145, reward/epoch 6.08696, cum reward/epoch -5.92706\n",
      "step 9100000, time 225159.0, loss 0.04743103, epochs 26165, reward/epoch 6.65000, cum reward/epoch -5.91745\n",
      "step 9110000, time 225411.1, loss 0.04779685, epochs 26188, reward/epoch 4.60870, cum reward/epoch -5.90820\n",
      "step 9120000, time 225662.8, loss 0.04772778, epochs 26211, reward/epoch 4.65217, cum reward/epoch -5.89894\n",
      "step 9130000, time 225914.3, loss 0.04842821, epochs 26232, reward/epoch 1.66667, cum reward/epoch -5.89288\n",
      "step 9140000, time 226166.9, loss 0.04841095, epochs 26256, reward/epoch 3.83333, cum reward/epoch -5.88399\n",
      "step 9150000, time 226418.6, loss 0.04865092, epochs 26280, reward/epoch 3.25000, cum reward/epoch -5.87565\n",
      "step 9160000, time 226669.4, loss 0.04705483, epochs 26297, reward/epoch 5.58824, cum reward/epoch -5.86824\n",
      "step 9170000, time 226921.0, loss 0.04877749, epochs 26322, reward/epoch 4.28000, cum reward/epoch -5.85860\n",
      "step 9180000, time 227173.0, loss 0.04897323, epochs 26345, reward/epoch 5.08696, cum reward/epoch -5.84904\n",
      "step 9190000, time 227426.1, loss 0.04843908, epochs 26367, reward/epoch 5.13636, cum reward/epoch -5.83988\n",
      "step 9200000, time 227677.9, loss 0.04972789, epochs 26391, reward/epoch 5.83333, cum reward/epoch -5.82926\n",
      "step 9210000, time 227929.2, loss 0.04930477, epochs 26415, reward/epoch 6.79167, cum reward/epoch -5.81779\n",
      "step 9220000, time 228180.0, loss 0.04795211, epochs 26436, reward/epoch 7.66667, cum reward/epoch -5.80708\n",
      "step 9230000, time 228432.0, loss 0.04909749, epochs 26461, reward/epoch 4.36000, cum reward/epoch -5.79748\n",
      "step 9240000, time 228682.5, loss 0.04875251, epochs 26485, reward/epoch 6.25000, cum reward/epoch -5.78656\n",
      "step 9250000, time 228933.3, loss 0.04750035, epochs 26508, reward/epoch 8.30435, cum reward/epoch -5.77433\n",
      "step 9260000, time 229184.5, loss 0.04747754, epochs 26530, reward/epoch 5.50000, cum reward/epoch -5.76498\n",
      "step 9270000, time 229436.0, loss 0.04811099, epochs 26554, reward/epoch 5.45833, cum reward/epoch -5.75484\n",
      "step 9280000, time 229687.6, loss 0.04793621, epochs 26576, reward/epoch 5.13636, cum reward/epoch -5.74582\n",
      "step 9290000, time 229938.4, loss 0.04799248, epochs 26600, reward/epoch 5.50000, cum reward/epoch -5.73568\n",
      "step 9300000, time 230190.0, loss 0.04825932, epochs 26624, reward/epoch 5.66667, cum reward/epoch -5.72540\n",
      "step 9310000, time 230441.0, loss 0.04816504, epochs 26647, reward/epoch 4.91304, cum reward/epoch -5.71622\n",
      "step 9320000, time 230693.0, loss 0.04905114, epochs 26669, reward/epoch 5.59091, cum reward/epoch -5.70689\n",
      "step 9330000, time 230945.2, loss 0.04806067, epochs 26695, reward/epoch 5.84615, cum reward/epoch -5.69564\n",
      "step 9340000, time 231196.8, loss 0.04863203, epochs 26719, reward/epoch 6.54167, cum reward/epoch -5.68464\n",
      "step 9350000, time 231449.0, loss 0.04793782, epochs 26741, reward/epoch 8.27273, cum reward/epoch -5.67316\n",
      "step 9360000, time 231700.2, loss 0.04825051, epochs 26765, reward/epoch 6.83333, cum reward/epoch -5.66195\n",
      "step 9370000, time 231951.9, loss 0.04764342, epochs 26786, reward/epoch 6.61905, cum reward/epoch -5.65232\n",
      "step 9380000, time 232203.4, loss 0.04778109, epochs 26812, reward/epoch 6.07692, cum reward/epoch -5.64094\n",
      "step 9390000, time 232455.1, loss 0.04749278, epochs 26834, reward/epoch 6.54545, cum reward/epoch -5.63095\n",
      "step 9400000, time 232706.6, loss 0.04833321, epochs 26859, reward/epoch 5.44000, cum reward/epoch -5.62065\n",
      "step 9410000, time 232959.2, loss 0.04754837, epochs 26882, reward/epoch 7.34783, cum reward/epoch -5.60955\n",
      "step 9420000, time 233211.1, loss 0.04859718, epochs 26906, reward/epoch 6.00000, cum reward/epoch -5.59920\n",
      "step 9430000, time 233462.5, loss 0.04812159, epochs 26932, reward/epoch 8.26923, cum reward/epoch -5.58581\n",
      "step 9440000, time 233714.2, loss 0.04843525, epochs 26954, reward/epoch 6.27273, cum reward/epoch -5.57613\n",
      "step 9450000, time 233965.5, loss 0.04849396, epochs 26981, reward/epoch 6.40741, cum reward/epoch -5.56414\n",
      "step 9460000, time 234217.8, loss 0.04905185, epochs 27001, reward/epoch 10.10000, cum reward/epoch -5.55254\n",
      "step 9470000, time 234469.0, loss 0.04842327, epochs 27028, reward/epoch 6.96296, cum reward/epoch -5.54003\n",
      "step 9480000, time 234720.5, loss 0.04816135, epochs 27051, reward/epoch 7.52174, cum reward/epoch -5.52893\n",
      "step 9490000, time 234971.9, loss 0.04827067, epochs 27075, reward/epoch 7.16667, cum reward/epoch -5.51767\n",
      "step 9500000, time 235224.2, loss 0.04807428, epochs 27101, reward/epoch 6.57692, cum reward/epoch -5.50607\n",
      "step 9510000, time 235476.1, loss 0.04885070, epochs 27122, reward/epoch 6.57143, cum reward/epoch -5.49672\n",
      "step 9520000, time 235727.2, loss 0.04778483, epochs 27148, reward/epoch 7.65385, cum reward/epoch -5.48412\n",
      "step 9530000, time 235978.7, loss 0.04818512, epochs 27172, reward/epoch 4.50000, cum reward/epoch -5.47531\n",
      "step 9540000, time 236230.2, loss 0.04798453, epochs 27194, reward/epoch 3.50000, cum reward/epoch -5.46804\n",
      "step 9550000, time 236482.2, loss 0.04912133, epochs 27221, reward/epoch 1.85185, cum reward/epoch -5.46078\n",
      "step 9560000, time 236733.4, loss 0.04934583, epochs 27241, reward/epoch 7.15000, cum reward/epoch -5.45153\n",
      "step 9570000, time 236984.6, loss 0.04858377, epochs 27269, reward/epoch 4.78571, cum reward/epoch -5.44101\n",
      "step 9580000, time 237236.9, loss 0.04805643, epochs 27292, reward/epoch 7.34783, cum reward/epoch -5.43024\n",
      "step 9590000, time 237488.7, loss 0.04911804, epochs 27317, reward/epoch 7.68000, cum reward/epoch -5.41824\n",
      "step 9600000, time 237739.9, loss 0.04841295, epochs 27341, reward/epoch 7.62500, cum reward/epoch -5.40679\n",
      "step 9610000, time 237991.6, loss 0.04788850, epochs 27366, reward/epoch 7.28000, cum reward/epoch -5.39520\n",
      "step 9620000, time 238243.2, loss 0.04823949, epochs 27389, reward/epoch 5.73913, cum reward/epoch -5.38585\n",
      "step 9630000, time 238494.9, loss 0.04738108, epochs 27411, reward/epoch 7.04545, cum reward/epoch -5.37587\n",
      "step 9640000, time 238746.5, loss 0.04821972, epochs 27435, reward/epoch 5.87500, cum reward/epoch -5.36603\n",
      "step 9650000, time 238997.4, loss 0.04733770, epochs 27458, reward/epoch 6.30435, cum reward/epoch -5.35625\n",
      "step 9660000, time 239248.7, loss 0.04862151, epochs 27480, reward/epoch 5.18182, cum reward/epoch -5.34782\n",
      "step 9670000, time 239500.8, loss 0.04889723, epochs 27504, reward/epoch 7.95833, cum reward/epoch -5.33621\n",
      "step 9680000, time 239752.7, loss 0.04794631, epochs 27527, reward/epoch 3.39130, cum reward/epoch -5.32891\n",
      "step 9690000, time 240004.2, loss 0.04872892, epochs 27551, reward/epoch 6.29167, cum reward/epoch -5.31879\n",
      "step 9700000, time 240256.7, loss 0.04906902, epochs 27572, reward/epoch 6.95238, cum reward/epoch -5.30944\n",
      "step 9710000, time 240508.3, loss 0.04785569, epochs 27599, reward/epoch 7.44444, cum reward/epoch -5.29697\n",
      "step 9720000, time 240761.5, loss 0.04784263, epochs 27618, reward/epoch 3.73684, cum reward/epoch -5.29075\n",
      "step 9730000, time 241012.9, loss 0.04822911, epochs 27641, reward/epoch 6.91304, cum reward/epoch -5.28060\n",
      "step 9740000, time 241264.5, loss 0.04739535, epochs 27665, reward/epoch 7.41667, cum reward/epoch -5.26958\n",
      "step 9750000, time 241516.7, loss 0.04670314, epochs 27693, reward/epoch 7.25000, cum reward/epoch -5.25692\n",
      "step 9760000, time 241769.6, loss 0.04866891, epochs 27716, reward/epoch 6.00000, cum reward/epoch -5.24758\n",
      "step 9770000, time 242022.0, loss 0.04840830, epochs 27737, reward/epoch 4.52381, cum reward/epoch -5.24018\n",
      "step 9780000, time 242274.0, loss 0.04870591, epochs 27761, reward/epoch 6.08333, cum reward/epoch -5.23040\n",
      "step 9790000, time 242526.9, loss 0.04805585, epochs 27785, reward/epoch 6.50000, cum reward/epoch -5.22026\n",
      "step 9800000, time 242779.5, loss 0.04679639, epochs 27811, reward/epoch 6.69231, cum reward/epoch -5.20913\n",
      "step 9810000, time 243032.1, loss 0.04791975, epochs 27832, reward/epoch 9.14286, cum reward/epoch -5.19830\n",
      "step 9820000, time 243284.0, loss 0.04789326, epochs 27857, reward/epoch 6.52000, cum reward/epoch -5.18778\n",
      "step 9830000, time 243536.3, loss 0.04943955, epochs 27880, reward/epoch 0.47826, cum reward/epoch -5.18311\n",
      "step 9840000, time 243788.5, loss 0.04826680, epochs 27906, reward/epoch 7.34615, cum reward/epoch -5.17143\n",
      "step 9850000, time 244039.8, loss 0.04822481, epochs 27926, reward/epoch 7.75000, cum reward/epoch -5.16218\n",
      "step 9860000, time 244292.8, loss 0.04819697, epochs 27952, reward/epoch 5.15385, cum reward/epoch -5.15258\n",
      "step 9870000, time 244544.9, loss 0.04834174, epochs 27974, reward/epoch 6.04545, cum reward/epoch -5.14378\n",
      "step 9880000, time 244797.0, loss 0.04792758, epochs 27997, reward/epoch 6.95652, cum reward/epoch -5.13384\n",
      "step 9890000, time 245049.3, loss 0.04708137, epochs 28022, reward/epoch 5.76000, cum reward/epoch -5.12412\n",
      "step 9900000, time 245301.5, loss 0.04739057, epochs 28046, reward/epoch 5.20833, cum reward/epoch -5.11527\n",
      "step 9910000, time 245554.3, loss 0.04846710, epochs 28070, reward/epoch 5.79167, cum reward/epoch -5.10595\n",
      "step 9920000, time 245806.1, loss 0.04708557, epochs 28093, reward/epoch 7.91304, cum reward/epoch -5.09529\n",
      "step 9930000, time 246058.6, loss 0.04774368, epochs 28116, reward/epoch 6.69565, cum reward/epoch -5.08565\n",
      "step 9940000, time 246310.6, loss 0.04710510, epochs 28137, reward/epoch 7.52381, cum reward/epoch -5.07623\n",
      "step 9950000, time 246562.7, loss 0.04657442, epochs 28163, reward/epoch 5.26923, cum reward/epoch -5.06668\n",
      "step 9960000, time 246816.5, loss 0.04823480, epochs 28184, reward/epoch 7.76190, cum reward/epoch -5.05712\n",
      "step 9970000, time 247068.2, loss 0.04724455, epochs 28207, reward/epoch 6.39130, cum reward/epoch -5.04779\n",
      "step 9980000, time 247320.6, loss 0.04835235, epochs 28231, reward/epoch 5.95833, cum reward/epoch -5.03843\n",
      "step 9990000, time 247572.6, loss 0.04671859, epochs 28252, reward/epoch 8.14286, cum reward/epoch -5.02864\n",
      "step 10000000, time 247825.2, loss 0.04798680, epochs 28279, reward/epoch 5.74074, cum reward/epoch -5.01835\n",
      "step 10010000, time 248077.9, loss 0.04773431, epochs 28299, reward/epoch 7.30000, cum reward/epoch -5.00965\n",
      "step 10020000, time 248330.9, loss 0.04811718, epochs 28323, reward/epoch 6.29167, cum reward/epoch -5.00007\n",
      "step 10030000, time 248583.8, loss 0.04712757, epochs 28346, reward/epoch 8.08696, cum reward/epoch -4.98945\n",
      "step 10040000, time 248836.0, loss 0.05005004, epochs 28370, reward/epoch -0.20833, cum reward/epoch -4.98541\n",
      "step 10050000, time 249088.2, loss 0.04868983, epochs 28392, reward/epoch 5.50000, cum reward/epoch -4.97728\n",
      "step 10060000, time 249340.8, loss 0.04854129, epochs 28417, reward/epoch 2.36000, cum reward/epoch -4.97083\n",
      "step 10070000, time 249593.0, loss 0.04887234, epochs 28440, reward/epoch 4.52174, cum reward/epoch -4.96315\n",
      "step 10080000, time 249844.8, loss 0.04796544, epochs 28463, reward/epoch 5.73913, cum reward/epoch -4.95450\n",
      "step 10090000, time 250097.3, loss 0.04789322, epochs 28487, reward/epoch 4.66667, cum reward/epoch -4.94640\n",
      "step 10100000, time 250349.3, loss 0.04818713, epochs 28508, reward/epoch 8.52381, cum reward/epoch -4.93647\n",
      "step 10110000, time 250601.8, loss 0.04861341, epochs 28533, reward/epoch 4.52000, cum reward/epoch -4.92819\n",
      "step 10120000, time 250853.8, loss 0.04647177, epochs 28553, reward/epoch 7.00000, cum reward/epoch -4.91983\n",
      "step 10130000, time 251106.1, loss 0.04788776, epochs 28577, reward/epoch 6.75000, cum reward/epoch -4.91003\n",
      "step 10140000, time 251358.3, loss 0.04815792, epochs 28602, reward/epoch 4.16000, cum reward/epoch -4.90210\n",
      "step 10150000, time 251610.3, loss 0.04805173, epochs 28621, reward/epoch 4.94737, cum reward/epoch -4.89557\n",
      "step 10160000, time 251861.9, loss 0.04742823, epochs 28647, reward/epoch 7.50000, cum reward/epoch -4.88432\n",
      "step 10170000, time 252113.6, loss 0.04718043, epochs 28667, reward/epoch 7.55000, cum reward/epoch -4.87564\n",
      "step 10180000, time 252366.2, loss 0.04789868, epochs 28693, reward/epoch 6.19231, cum reward/epoch -4.86561\n",
      "step 10190000, time 252618.8, loss 0.04649389, epochs 28715, reward/epoch 6.50000, cum reward/epoch -4.85690\n",
      "step 10200000, time 252870.9, loss 0.04704682, epochs 28736, reward/epoch 6.61905, cum reward/epoch -4.84852\n",
      "step 10210000, time 253123.9, loss 0.04651143, epochs 28759, reward/epoch 7.95652, cum reward/epoch -4.83828\n",
      "step 10220000, time 253375.9, loss 0.04708184, epochs 28783, reward/epoch 7.00000, cum reward/epoch -4.82841\n",
      "step 10230000, time 253627.7, loss 0.04763244, epochs 28805, reward/epoch 5.36364, cum reward/epoch -4.82062\n",
      "step 10240000, time 253881.1, loss 0.04767703, epochs 28827, reward/epoch 4.95455, cum reward/epoch -4.81316\n",
      "step 10250000, time 254133.7, loss 0.04681163, epochs 28850, reward/epoch 6.78261, cum reward/epoch -4.80392\n",
      "step 10260000, time 254387.1, loss 0.04706853, epochs 28877, reward/epoch 6.55556, cum reward/epoch -4.79330\n",
      "step 10270000, time 254639.6, loss 0.04698090, epochs 28897, reward/epoch 8.50000, cum reward/epoch -4.78410\n",
      "step 10280000, time 254892.5, loss 0.04755666, epochs 28920, reward/epoch 5.13043, cum reward/epoch -4.77621\n",
      "step 10290000, time 255145.5, loss 0.04769193, epochs 28947, reward/epoch 3.18519, cum reward/epoch -4.76878\n",
      "step 10300000, time 255398.5, loss 0.04790289, epochs 28967, reward/epoch 6.40000, cum reward/epoch -4.76107\n",
      "step 10310000, time 255650.3, loss 0.04733409, epochs 28993, reward/epoch 1.38462, cum reward/epoch -4.75556\n",
      "step 10320000, time 255903.7, loss 0.04770159, epochs 29013, reward/epoch 4.30000, cum reward/epoch -4.74932\n",
      "step 10330000, time 256156.9, loss 0.04862337, epochs 29034, reward/epoch 2.23810, cum reward/epoch -4.74427\n",
      "step 10340000, time 256410.3, loss 0.04804017, epochs 29059, reward/epoch 6.32000, cum reward/epoch -4.73475\n",
      "step 10350000, time 256663.9, loss 0.04683942, epochs 29082, reward/epoch 5.26087, cum reward/epoch -4.72684\n",
      "step 10360000, time 256916.6, loss 0.04672568, epochs 29104, reward/epoch 8.00000, cum reward/epoch -4.71722\n",
      "step 10370000, time 257169.3, loss 0.04692183, epochs 29128, reward/epoch 7.25000, cum reward/epoch -4.70736\n",
      "step 10380000, time 257422.9, loss 0.04700174, epochs 29152, reward/epoch 7.58333, cum reward/epoch -4.69724\n",
      "step 10390000, time 257675.4, loss 0.04701458, epochs 29172, reward/epoch 9.35000, cum reward/epoch -4.68761\n",
      "step 10400000, time 257928.0, loss 0.04719653, epochs 29199, reward/epoch 5.59259, cum reward/epoch -4.67811\n",
      "step 10410000, time 258181.6, loss 0.04803320, epochs 29220, reward/epoch 5.38095, cum reward/epoch -4.67088\n",
      "step 10420000, time 258434.1, loss 0.04700534, epochs 29244, reward/epoch 6.54167, cum reward/epoch -4.66167\n",
      "step 10430000, time 258686.5, loss 0.04747792, epochs 29268, reward/epoch 7.50000, cum reward/epoch -4.65170\n",
      "step 10440000, time 258938.9, loss 0.04643853, epochs 29292, reward/epoch 5.08333, cum reward/epoch -4.64373\n",
      "step 10450000, time 259191.9, loss 0.04706017, epochs 29313, reward/epoch 7.14286, cum reward/epoch -4.63528\n",
      "step 10460000, time 259444.7, loss 0.04683743, epochs 29340, reward/epoch 6.33333, cum reward/epoch -4.62519\n",
      "step 10470000, time 259697.1, loss 0.04765830, epochs 29357, reward/epoch 5.82353, cum reward/epoch -4.61914\n",
      "step 10480000, time 259949.6, loss 0.04707076, epochs 29380, reward/epoch 5.34783, cum reward/epoch -4.61133\n",
      "step 10490000, time 260203.3, loss 0.04746468, epochs 29405, reward/epoch 5.84000, cum reward/epoch -4.60245\n",
      "step 10500000, time 260456.7, loss 0.04746159, epochs 29427, reward/epoch 6.50000, cum reward/epoch -4.59415\n",
      "step 10510000, time 260708.9, loss 0.04716416, epochs 29452, reward/epoch 8.24000, cum reward/epoch -4.58325\n",
      "step 10520000, time 260961.9, loss 0.04615532, epochs 29475, reward/epoch 5.30435, cum reward/epoch -4.57554\n",
      "step 10530000, time 261214.8, loss 0.04711740, epochs 29495, reward/epoch 6.95000, cum reward/epoch -4.56772\n",
      "step 10540000, time 261467.6, loss 0.04767858, epochs 29519, reward/epoch 8.04167, cum reward/epoch -4.55747\n",
      "step 10550000, time 261720.0, loss 0.04770872, epochs 29541, reward/epoch 8.31818, cum reward/epoch -4.54788\n",
      "step 10560000, time 261972.8, loss 0.04710322, epochs 29570, reward/epoch 5.72414, cum reward/epoch -4.53781\n",
      "step 10570000, time 262225.3, loss 0.04697669, epochs 29593, reward/epoch 6.04348, cum reward/epoch -4.52958\n",
      "step 10580000, time 262477.9, loss 0.04794740, epochs 29615, reward/epoch 4.77273, cum reward/epoch -4.52267\n",
      "step 10590000, time 262730.8, loss 0.04756095, epochs 29635, reward/epoch 6.35000, cum reward/epoch -4.51534\n",
      "step 10600000, time 262983.1, loss 0.04765641, epochs 29661, reward/epoch 5.46154, cum reward/epoch -4.50659\n",
      "step 10610000, time 263236.3, loss 0.04630844, epochs 29682, reward/epoch 6.61905, cum reward/epoch -4.49872\n",
      "step 10620000, time 263489.0, loss 0.04731574, epochs 29705, reward/epoch 6.08696, cum reward/epoch -4.49052\n",
      "step 10630000, time 263743.0, loss 0.04580799, epochs 29729, reward/epoch 8.33333, cum reward/epoch -4.48017\n",
      "step 10640000, time 263996.4, loss 0.04620147, epochs 29750, reward/epoch 6.57143, cum reward/epoch -4.47237\n",
      "step 10650000, time 264249.2, loss 0.04739288, epochs 29773, reward/epoch 6.13043, cum reward/epoch -4.46418\n",
      "step 10660000, time 264502.3, loss 0.04648209, epochs 29793, reward/epoch 6.90000, cum reward/epoch -4.45655\n",
      "step 10670000, time 264755.0, loss 0.04714028, epochs 29820, reward/epoch 5.59259, cum reward/epoch -4.44745\n",
      "step 10680000, time 265008.1, loss 0.04703194, epochs 29840, reward/epoch 6.00000, cum reward/epoch -4.44045\n",
      "step 10690000, time 265260.4, loss 0.04662607, epochs 29860, reward/epoch 6.50000, cum reward/epoch -4.43312\n",
      "step 10700000, time 265513.1, loss 0.04693495, epochs 29886, reward/epoch 5.46154, cum reward/epoch -4.42451\n",
      "step 10710000, time 265765.9, loss 0.04770276, epochs 29905, reward/epoch 4.63158, cum reward/epoch -4.41876\n",
      "step 10720000, time 266019.2, loss 0.04655322, epochs 29931, reward/epoch 8.11539, cum reward/epoch -4.40787\n",
      "step 10730000, time 266271.9, loss 0.04737135, epochs 29954, reward/epoch 4.30435, cum reward/epoch -4.40118\n",
      "step 10740000, time 266524.1, loss 0.04711787, epochs 29974, reward/epoch 6.20000, cum reward/epoch -4.39411\n",
      "step 10750000, time 266777.0, loss 0.04733859, epochs 29999, reward/epoch 7.24000, cum reward/epoch -4.38441\n",
      "step 10760000, time 267029.8, loss 0.04812390, epochs 30024, reward/epoch 3.80000, cum reward/epoch -4.37760\n",
      "step 10770000, time 267282.7, loss 0.04716282, epochs 30046, reward/epoch 4.13636, cum reward/epoch -4.37136\n",
      "step 10780000, time 267535.4, loss 0.04748811, epochs 30072, reward/epoch 5.19231, cum reward/epoch -4.36310\n",
      "step 10790000, time 267789.1, loss 0.04732435, epochs 30094, reward/epoch 7.09091, cum reward/epoch -4.35472\n",
      "step 10800000, time 268042.2, loss 0.04675138, epochs 30117, reward/epoch 5.73913, cum reward/epoch -4.34701\n",
      "step 10810000, time 268296.3, loss 0.04718319, epochs 30140, reward/epoch 8.60870, cum reward/epoch -4.33713\n",
      "step 10820000, time 268549.6, loss 0.04747615, epochs 30165, reward/epoch 8.32000, cum reward/epoch -4.32664\n",
      "step 10830000, time 268802.5, loss 0.04726744, epochs 30187, reward/epoch 6.90909, cum reward/epoch -4.31845\n",
      "step 10840000, time 269055.3, loss 0.04647750, epochs 30211, reward/epoch 5.83333, cum reward/epoch -4.31038\n",
      "step 10850000, time 269308.6, loss 0.04662019, epochs 30235, reward/epoch 8.12500, cum reward/epoch -4.30051\n",
      "step 10860000, time 269562.3, loss 0.04646786, epochs 30256, reward/epoch 6.61905, cum reward/epoch -4.29293\n",
      "step 10870000, time 269815.1, loss 0.04627597, epochs 30278, reward/epoch 6.63636, cum reward/epoch -4.28499\n",
      "step 10880000, time 270069.3, loss 0.04663569, epochs 30300, reward/epoch 4.63636, cum reward/epoch -4.27851\n",
      "step 10890000, time 270323.1, loss 0.04896023, epochs 30329, reward/epoch -0.75862, cum reward/epoch -4.27515\n",
      "step 10900000, time 270576.4, loss 0.04947051, epochs 30351, reward/epoch 2.31818, cum reward/epoch -4.27037\n",
      "step 10910000, time 270830.0, loss 0.04773948, epochs 30373, reward/epoch 4.90909, cum reward/epoch -4.26372\n",
      "step 10920000, time 271083.1, loss 0.04750862, epochs 30399, reward/epoch 5.73077, cum reward/epoch -4.25517\n",
      "step 10930000, time 271336.0, loss 0.04780610, epochs 30424, reward/epoch 8.32000, cum reward/epoch -4.24484\n",
      "step 10940000, time 271588.7, loss 0.04858169, epochs 30444, reward/epoch 6.80000, cum reward/epoch -4.23758\n",
      "step 10950000, time 271841.4, loss 0.04899178, epochs 30473, reward/epoch 2.86207, cum reward/epoch -4.23083\n",
      "step 10960000, time 272094.2, loss 0.04817754, epochs 30492, reward/epoch 7.00000, cum reward/epoch -4.22383\n",
      "step 10970000, time 272346.9, loss 0.04703865, epochs 30519, reward/epoch 7.14815, cum reward/epoch -4.21377\n",
      "step 10980000, time 272599.3, loss 0.04749566, epochs 30541, reward/epoch 6.54545, cum reward/epoch -4.20602\n",
      "step 10990000, time 272852.2, loss 0.04708952, epochs 30563, reward/epoch 4.50000, cum reward/epoch -4.19975\n",
      "step 11000000, time 273105.9, loss 0.04766684, epochs 30590, reward/epoch 5.29630, cum reward/epoch -4.19137\n",
      "step 11010000, time 273359.2, loss 0.04678350, epochs 30612, reward/epoch 8.36364, cum reward/epoch -4.18235\n",
      "step 11020000, time 273611.7, loss 0.04813667, epochs 30633, reward/epoch 6.14286, cum reward/epoch -4.17527\n",
      "step 11030000, time 273865.1, loss 0.04685767, epochs 30658, reward/epoch 7.64000, cum reward/epoch -4.16563\n",
      "step 11040000, time 274118.5, loss 0.04779547, epochs 30681, reward/epoch 6.78261, cum reward/epoch -4.15743\n",
      "step 11050000, time 274371.7, loss 0.04658983, epochs 30704, reward/epoch 7.08696, cum reward/epoch -4.14900\n",
      "step 11060000, time 274624.9, loss 0.04694703, epochs 30726, reward/epoch 6.09091, cum reward/epoch -4.14167\n",
      "step 11070000, time 274878.6, loss 0.04676940, epochs 30749, reward/epoch 6.73913, cum reward/epoch -4.13353\n",
      "step 11080000, time 275131.4, loss 0.04652756, epochs 30772, reward/epoch 9.17391, cum reward/epoch -4.12359\n",
      "step 11090000, time 275385.0, loss 0.04773206, epochs 30799, reward/epoch 5.55556, cum reward/epoch -4.11510\n",
      "step 11100000, time 275638.1, loss 0.04751495, epochs 30822, reward/epoch 4.47826, cum reward/epoch -4.10869\n",
      "step 11110000, time 275891.3, loss 0.04710060, epochs 30845, reward/epoch 8.00000, cum reward/epoch -4.09966\n",
      "step 11120000, time 276144.3, loss 0.04653217, epochs 30867, reward/epoch 7.27273, cum reward/epoch -4.09155\n",
      "step 11130000, time 276397.7, loss 0.04778654, epochs 30893, reward/epoch 6.03846, cum reward/epoch -4.08303\n",
      "step 11140000, time 276650.6, loss 0.04771081, epochs 30916, reward/epoch 6.08696, cum reward/epoch -4.07546\n",
      "step 11150000, time 276903.8, loss 0.04826225, epochs 30940, reward/epoch 5.66667, cum reward/epoch -4.06791\n",
      "step 11160000, time 277156.0, loss 0.04694709, epochs 30965, reward/epoch 7.08000, cum reward/epoch -4.05891\n",
      "step 11170000, time 277409.4, loss 0.04710706, epochs 30987, reward/epoch 4.27273, cum reward/epoch -4.05299\n",
      "step 11180000, time 277661.7, loss 0.04739434, epochs 31008, reward/epoch 4.04762, cum reward/epoch -4.04750\n",
      "step 11190000, time 277915.0, loss 0.04647988, epochs 31034, reward/epoch 6.07692, cum reward/epoch -4.03902\n",
      "step 11200000, time 278168.3, loss 0.04744643, epochs 31055, reward/epoch 6.42857, cum reward/epoch -4.03194\n",
      "step 11210000, time 278420.9, loss 0.04632477, epochs 31079, reward/epoch 5.62500, cum reward/epoch -4.02449\n",
      "step 11220000, time 278674.7, loss 0.04747564, epochs 31099, reward/epoch 5.85000, cum reward/epoch -4.01814\n",
      "step 11230000, time 278927.3, loss 0.04654618, epochs 31122, reward/epoch 6.47826, cum reward/epoch -4.01038\n",
      "step 11240000, time 279180.9, loss 0.04607861, epochs 31145, reward/epoch 7.17391, cum reward/epoch -4.00212\n",
      "step 11250000, time 279434.3, loss 0.04861772, epochs 31171, reward/epoch 1.03846, cum reward/epoch -3.99791\n",
      "step 11260000, time 279688.8, loss 0.04806778, epochs 31193, reward/epoch 6.95455, cum reward/epoch -3.99019\n",
      "step 11270000, time 279942.4, loss 0.04743888, epochs 31213, reward/epoch 5.95000, cum reward/epoch -3.98382\n",
      "step 11280000, time 280195.3, loss 0.04702054, epochs 31239, reward/epoch 6.19231, cum reward/epoch -3.97535\n",
      "step 11290000, time 280448.2, loss 0.04823916, epochs 31261, reward/epoch 6.18182, cum reward/epoch -3.96820\n",
      "step 11300000, time 280701.1, loss 0.04700595, epochs 31284, reward/epoch 4.91304, cum reward/epoch -3.96167\n",
      "step 11310000, time 280953.8, loss 0.04711132, epochs 31306, reward/epoch 8.27273, cum reward/epoch -3.95308\n",
      "step 11320000, time 281206.7, loss 0.04699187, epochs 31330, reward/epoch 6.75000, cum reward/epoch -3.94488\n",
      "step 11330000, time 281459.1, loss 0.04666077, epochs 31355, reward/epoch 8.80000, cum reward/epoch -3.93472\n",
      "step 11340000, time 281711.5, loss 0.04694479, epochs 31376, reward/epoch 4.85714, cum reward/epoch -3.92883\n",
      "step 11350000, time 281964.7, loss 0.04609876, epochs 31397, reward/epoch 4.52381, cum reward/epoch -3.92318\n",
      "step 11360000, time 282217.6, loss 0.04703443, epochs 31417, reward/epoch 4.95000, cum reward/epoch -3.91753\n",
      "step 11370000, time 282470.3, loss 0.04685310, epochs 31440, reward/epoch 6.65217, cum reward/epoch -3.90980\n",
      "step 11380000, time 282723.3, loss 0.04718314, epochs 31466, reward/epoch 6.61538, cum reward/epoch -3.90110\n",
      "step 11390000, time 282976.5, loss 0.04741316, epochs 31490, reward/epoch 7.20833, cum reward/epoch -3.89263\n",
      "step 11400000, time 283229.2, loss 0.04698166, epochs 31513, reward/epoch 6.26087, cum reward/epoch -3.88522\n",
      "step 11410000, time 283482.3, loss 0.04604019, epochs 31538, reward/epoch 8.52000, cum reward/epoch -3.87539\n",
      "step 11420000, time 283735.1, loss 0.04648962, epochs 31562, reward/epoch 6.87500, cum reward/epoch -3.86721\n",
      "step 11430000, time 283987.7, loss 0.04601647, epochs 31586, reward/epoch 8.54167, cum reward/epoch -3.85778\n",
      "step 11440000, time 284240.6, loss 0.04651290, epochs 31609, reward/epoch 8.82609, cum reward/epoch -3.84856\n",
      "step 11450000, time 284493.2, loss 0.04647577, epochs 31636, reward/epoch 7.48148, cum reward/epoch -3.83889\n",
      "step 11460000, time 284746.8, loss 0.04771274, epochs 31658, reward/epoch 5.68182, cum reward/epoch -3.83227\n",
      "step 11470000, time 284999.8, loss 0.04750964, epochs 31684, reward/epoch 6.88462, cum reward/epoch -3.82348\n",
      "step 11480000, time 285252.8, loss 0.04620451, epochs 31706, reward/epoch 9.18182, cum reward/epoch -3.81445\n",
      "step 11490000, time 285505.8, loss 0.04644646, epochs 31730, reward/epoch 6.12500, cum reward/epoch -3.80693\n",
      "step 11500000, time 285758.6, loss 0.04654929, epochs 31751, reward/epoch 7.14286, cum reward/epoch -3.79969\n",
      "step 11510000, time 286012.1, loss 0.04586826, epochs 31776, reward/epoch 8.44000, cum reward/epoch -3.79006\n",
      "step 11520000, time 286265.9, loss 0.04708438, epochs 31795, reward/epoch 6.84211, cum reward/epoch -3.78371\n",
      "step 11530000, time 286519.8, loss 0.04693481, epochs 31821, reward/epoch 7.03846, cum reward/epoch -3.77487\n",
      "step 11540000, time 286773.9, loss 0.04741398, epochs 31846, reward/epoch 6.64000, cum reward/epoch -3.76669\n",
      "step 11550000, time 287027.0, loss 0.04629335, epochs 31869, reward/epoch 6.56522, cum reward/epoch -3.75923\n",
      "step 11560000, time 287280.5, loss 0.04654735, epochs 31894, reward/epoch 9.68000, cum reward/epoch -3.74870\n",
      "step 11570000, time 287533.0, loss 0.04764691, epochs 31916, reward/epoch 7.22727, cum reward/epoch -3.74113\n",
      "step 11580000, time 287785.9, loss 0.04646626, epochs 31942, reward/epoch 6.26923, cum reward/epoch -3.73298\n",
      "step 11590000, time 288038.8, loss 0.04747937, epochs 31962, reward/epoch 3.75000, cum reward/epoch -3.72830\n",
      "step 11600000, time 288293.1, loss 0.04754716, epochs 31983, reward/epoch 6.66667, cum reward/epoch -3.72148\n",
      "step 11610000, time 288545.7, loss 0.04697298, epochs 32008, reward/epoch 5.92000, cum reward/epoch -3.71395\n",
      "step 11620000, time 288798.1, loss 0.04658492, epochs 32029, reward/epoch 6.52381, cum reward/epoch -3.70723\n",
      "step 11630000, time 289050.5, loss 0.04661793, epochs 32056, reward/epoch 5.48148, cum reward/epoch -3.69949\n",
      "step 11640000, time 289304.2, loss 0.04698331, epochs 32078, reward/epoch 8.13636, cum reward/epoch -3.69138\n",
      "step 11650000, time 289557.6, loss 0.04706080, epochs 32097, reward/epoch 6.94737, cum reward/epoch -3.68508\n",
      "step 11660000, time 289810.4, loss 0.04605275, epochs 32122, reward/epoch 6.72000, cum reward/epoch -3.67698\n",
      "step 11670000, time 290063.8, loss 0.04662039, epochs 32145, reward/epoch 9.04348, cum reward/epoch -3.66788\n",
      "step 11680000, time 290317.5, loss 0.04715384, epochs 32173, reward/epoch 7.07143, cum reward/epoch -3.65853\n",
      "step 11690000, time 290570.0, loss 0.04683006, epochs 32195, reward/epoch 8.31818, cum reward/epoch -3.65035\n",
      "step 11700000, time 290822.8, loss 0.04718761, epochs 32219, reward/epoch 5.08333, cum reward/epoch -3.64384\n",
      "step 11710000, time 291075.4, loss 0.04690014, epochs 32244, reward/epoch 6.76000, cum reward/epoch -3.63578\n",
      "step 11720000, time 291328.1, loss 0.04716834, epochs 32267, reward/epoch 8.43478, cum reward/epoch -3.62717\n",
      "step 11730000, time 291580.6, loss 0.04608202, epochs 32290, reward/epoch 10.04348, cum reward/epoch -3.61744\n",
      "step 11740000, time 291832.9, loss 0.04723066, epochs 32316, reward/epoch 7.76923, cum reward/epoch -3.60827\n",
      "step 11750000, time 292086.0, loss 0.04658454, epochs 32339, reward/epoch 9.30435, cum reward/epoch -3.59909\n",
      "step 11760000, time 292338.9, loss 0.04623786, epochs 32364, reward/epoch 6.52000, cum reward/epoch -3.59127\n",
      "step 11770000, time 292591.8, loss 0.04651030, epochs 32386, reward/epoch 6.13636, cum reward/epoch -3.58467\n",
      "step 11780000, time 292844.2, loss 0.04591392, epochs 32409, reward/epoch 8.43478, cum reward/epoch -3.57614\n",
      "step 11790000, time 293097.5, loss 0.04687168, epochs 32435, reward/epoch 6.23077, cum reward/epoch -3.56827\n",
      "step 11800000, time 293349.8, loss 0.04656389, epochs 32456, reward/epoch 8.76190, cum reward/epoch -3.56030\n",
      "step 11810000, time 293601.9, loss 0.04654026, epochs 32480, reward/epoch 10.62500, cum reward/epoch -3.54982\n",
      "step 11820000, time 293855.2, loss 0.04680940, epochs 32508, reward/epoch 7.50000, cum reward/epoch -3.54030\n",
      "step 11830000, time 294108.1, loss 0.04611971, epochs 32530, reward/epoch 9.63636, cum reward/epoch -3.53139\n",
      "step 11840000, time 294361.1, loss 0.04680537, epochs 32557, reward/epoch 7.55556, cum reward/epoch -3.52219\n",
      "step 11850000, time 294613.8, loss 0.04696760, epochs 32578, reward/epoch 9.19048, cum reward/epoch -3.51400\n",
      "step 11860000, time 294866.9, loss 0.04547378, epochs 32604, reward/epoch 7.23077, cum reward/epoch -3.50543\n",
      "step 11870000, time 295119.6, loss 0.04622374, epochs 32628, reward/epoch 8.66667, cum reward/epoch -3.49648\n",
      "step 11880000, time 295372.8, loss 0.04665847, epochs 32651, reward/epoch 7.91304, cum reward/epoch -3.48844\n",
      "step 11890000, time 295625.6, loss 0.04632456, epochs 32677, reward/epoch 8.34615, cum reward/epoch -3.47902\n",
      "step 11900000, time 295878.3, loss 0.04661804, epochs 32704, reward/epoch 9.55556, cum reward/epoch -3.46826\n",
      "step 11910000, time 296130.4, loss 0.04687396, epochs 32729, reward/epoch 9.52000, cum reward/epoch -3.45834\n",
      "step 11920000, time 296382.6, loss 0.04666924, epochs 32753, reward/epoch 7.75000, cum reward/epoch -3.45013\n",
      "step 11930000, time 296635.7, loss 0.04592422, epochs 32776, reward/epoch 5.39130, cum reward/epoch -3.44392\n",
      "step 11940000, time 296888.8, loss 0.04683971, epochs 32799, reward/epoch 7.52174, cum reward/epoch -3.43623\n",
      "step 11950000, time 297141.8, loss 0.04607627, epochs 32823, reward/epoch 8.08333, cum reward/epoch -3.42781\n",
      "step 11960000, time 297395.2, loss 0.04561134, epochs 32847, reward/epoch 8.75000, cum reward/epoch -3.41891\n",
      "step 11970000, time 297648.1, loss 0.04723302, epochs 32872, reward/epoch 7.76000, cum reward/epoch -3.41041\n",
      "step 11980000, time 297900.8, loss 0.04750900, epochs 32893, reward/epoch 6.57143, cum reward/epoch -3.40404\n",
      "step 11990000, time 298153.1, loss 0.04696959, epochs 32920, reward/epoch 6.11111, cum reward/epoch -3.39623\n",
      "step 12000000, time 298405.2, loss 0.04636847, epochs 32941, reward/epoch 10.61905, cum reward/epoch -3.38730\n",
      "step 12010000, time 298657.6, loss 0.04715004, epochs 32967, reward/epoch 8.96154, cum reward/epoch -3.37756\n",
      "step 12020000, time 298910.9, loss 0.04762501, epochs 32990, reward/epoch 6.47826, cum reward/epoch -3.37069\n",
      "step 12030000, time 299163.9, loss 0.04753715, epochs 33017, reward/epoch 8.48148, cum reward/epoch -3.36100\n",
      "step 12040000, time 299416.6, loss 0.04671710, epochs 33043, reward/epoch 8.11539, cum reward/epoch -3.35197\n",
      "step 12050000, time 299668.6, loss 0.04784106, epochs 33067, reward/epoch 6.62500, cum reward/epoch -3.34472\n",
      "step 12060000, time 299921.9, loss 0.04712231, epochs 33088, reward/epoch 5.71429, cum reward/epoch -3.33897\n",
      "step 12070000, time 300175.1, loss 0.04695287, epochs 33111, reward/epoch 5.13043, cum reward/epoch -3.33309\n",
      "step 12080000, time 300427.5, loss 0.04633117, epochs 33134, reward/epoch 6.13043, cum reward/epoch -3.32652\n",
      "step 12090000, time 300680.4, loss 0.04704112, epochs 33158, reward/epoch 6.00000, cum reward/epoch -3.31977\n",
      "step 12100000, time 300932.6, loss 0.04715534, epochs 33180, reward/epoch 4.59091, cum reward/epoch -3.31453\n",
      "step 12110000, time 301186.0, loss 0.04629070, epochs 33207, reward/epoch 7.74074, cum reward/epoch -3.30554\n",
      "step 12120000, time 301439.8, loss 0.04705751, epochs 33229, reward/epoch 7.59091, cum reward/epoch -3.29832\n",
      "step 12130000, time 301692.8, loss 0.04846141, epochs 33257, reward/epoch 8.10714, cum reward/epoch -3.28872\n",
      "step 12140000, time 301945.7, loss 0.04725705, epochs 33279, reward/epoch 8.54545, cum reward/epoch -3.28090\n",
      "step 12150000, time 302198.7, loss 0.04591604, epochs 33302, reward/epoch 7.65217, cum reward/epoch -3.27335\n",
      "step 12160000, time 302451.5, loss 0.04658443, epochs 33329, reward/epoch 6.96296, cum reward/epoch -3.26505\n",
      "step 12170000, time 302703.5, loss 0.04647421, epochs 33352, reward/epoch 6.47826, cum reward/epoch -3.25834\n",
      "step 12180000, time 302956.3, loss 0.04624934, epochs 33375, reward/epoch 6.13043, cum reward/epoch -3.25187\n",
      "step 12190000, time 303209.1, loss 0.04662773, epochs 33397, reward/epoch 4.40909, cum reward/epoch -3.24682\n",
      "step 12200000, time 303461.7, loss 0.04699829, epochs 33419, reward/epoch 5.68182, cum reward/epoch -3.24094\n",
      "step 12210000, time 303714.8, loss 0.04647890, epochs 33446, reward/epoch 6.07407, cum reward/epoch -3.23342\n",
      "step 12220000, time 303968.3, loss 0.04674806, epochs 33465, reward/epoch 7.42105, cum reward/epoch -3.22737\n",
      "step 12230000, time 304221.7, loss 0.04713410, epochs 33491, reward/epoch 5.53846, cum reward/epoch -3.22057\n",
      "step 12240000, time 304474.5, loss 0.04659657, epochs 33514, reward/epoch 7.78261, cum reward/epoch -3.21302\n",
      "step 12250000, time 304727.9, loss 0.04596958, epochs 33537, reward/epoch 7.43478, cum reward/epoch -3.20571\n",
      "step 12260000, time 304981.0, loss 0.04684848, epochs 33562, reward/epoch 6.32000, cum reward/epoch -3.19862\n",
      "step 12270000, time 305233.6, loss 0.04590083, epochs 33585, reward/epoch 9.34783, cum reward/epoch -3.19003\n",
      "step 12280000, time 305486.7, loss 0.04696319, epochs 33608, reward/epoch 8.00000, cum reward/epoch -3.18237\n",
      "step 12290000, time 305739.5, loss 0.04683175, epochs 33630, reward/epoch 5.04545, cum reward/epoch -3.17698\n",
      "step 12300000, time 305992.4, loss 0.04639748, epochs 33655, reward/epoch 8.56000, cum reward/epoch -3.16827\n",
      "step 12310000, time 306245.4, loss 0.04543354, epochs 33678, reward/epoch 9.17391, cum reward/epoch -3.15984\n",
      "step 12320000, time 306498.3, loss 0.04702176, epochs 33703, reward/epoch 3.12000, cum reward/epoch -3.15518\n",
      "step 12330000, time 306751.1, loss 0.04716001, epochs 33723, reward/epoch 3.35000, cum reward/epoch -3.15132\n",
      "step 12340000, time 307004.2, loss 0.04708950, epochs 33747, reward/epoch 8.37500, cum reward/epoch -3.14312\n",
      "step 12350000, time 307256.9, loss 0.05017963, epochs 33773, reward/epoch -0.80769, cum reward/epoch -3.14133\n",
      "step 12360000, time 307509.5, loss 0.04876520, epochs 33796, reward/epoch 5.69565, cum reward/epoch -3.13531\n",
      "step 12370000, time 307762.5, loss 0.04657081, epochs 33818, reward/epoch 8.50000, cum reward/epoch -3.12774\n",
      "step 12380000, time 308015.0, loss 0.04663758, epochs 33842, reward/epoch 6.79167, cum reward/epoch -3.12071\n",
      "step 12390000, time 308266.9, loss 0.04630220, epochs 33866, reward/epoch 8.87500, cum reward/epoch -3.11221\n",
      "step 12400000, time 308519.5, loss 0.04678300, epochs 33890, reward/epoch 8.33333, cum reward/epoch -3.10410\n",
      "step 12410000, time 308771.4, loss 0.04674224, epochs 33913, reward/epoch 6.47826, cum reward/epoch -3.09760\n",
      "step 12420000, time 309023.6, loss 0.04567789, epochs 33940, reward/epoch 9.40741, cum reward/epoch -3.08765\n",
      "step 12430000, time 309275.1, loss 0.04635449, epochs 33965, reward/epoch 7.32000, cum reward/epoch -3.07999\n",
      "step 12440000, time 309527.8, loss 0.04659443, epochs 33984, reward/epoch 8.89474, cum reward/epoch -3.07330\n",
      "step 12450000, time 309780.2, loss 0.04523323, epochs 34009, reward/epoch 9.32000, cum reward/epoch -3.06419\n",
      "step 12460000, time 310032.9, loss 0.04721428, epochs 34034, reward/epoch 7.04000, cum reward/epoch -3.05677\n",
      "step 12470000, time 310285.4, loss 0.04650583, epochs 34056, reward/epoch 6.77273, cum reward/epoch -3.05042\n",
      "step 12480000, time 310538.3, loss 0.04789880, epochs 34080, reward/epoch 7.75000, cum reward/epoch -3.04281\n",
      "step 12490000, time 310790.9, loss 0.04634900, epochs 34102, reward/epoch 5.68182, cum reward/epoch -3.03718\n",
      "step 12500000, time 311043.9, loss 0.04662987, epochs 34123, reward/epoch 7.61905, cum reward/epoch -3.03062\n",
      "step 12510000, time 311296.4, loss 0.04638278, epochs 34148, reward/epoch 8.12000, cum reward/epoch -3.02246\n",
      "step 12520000, time 311549.2, loss 0.04605485, epochs 34172, reward/epoch 9.33333, cum reward/epoch -3.01378\n",
      "step 12530000, time 311801.7, loss 0.04638489, epochs 34197, reward/epoch 7.96000, cum reward/epoch -3.00576\n",
      "step 12540000, time 312054.4, loss 0.04589191, epochs 34219, reward/epoch 9.81818, cum reward/epoch -2.99752\n",
      "step 12550000, time 312307.0, loss 0.04644494, epochs 34244, reward/epoch 8.08000, cum reward/epoch -2.98943\n",
      "step 12560000, time 312559.7, loss 0.04671756, epochs 34266, reward/epoch 7.40909, cum reward/epoch -2.98275\n",
      "step 12570000, time 312812.4, loss 0.04572272, epochs 34290, reward/epoch 9.04167, cum reward/epoch -2.97434\n",
      "step 12580000, time 313064.9, loss 0.04595268, epochs 34314, reward/epoch 8.70833, cum reward/epoch -2.96617\n",
      "step 12590000, time 313317.3, loss 0.04599858, epochs 34339, reward/epoch 6.96000, cum reward/epoch -2.95894\n",
      "step 12600000, time 313569.8, loss 0.04685893, epochs 34360, reward/epoch 8.42857, cum reward/epoch -2.95198\n",
      "step 12610000, time 313822.4, loss 0.04701607, epochs 34384, reward/epoch 4.62500, cum reward/epoch -2.94669\n",
      "step 12620000, time 314076.0, loss 0.04681853, epochs 34410, reward/epoch 9.07692, cum reward/epoch -2.93761\n",
      "step 12630000, time 314328.2, loss 0.04738491, epochs 34434, reward/epoch 7.75000, cum reward/epoch -2.93016\n",
      "step 12640000, time 314580.9, loss 0.04599012, epochs 34459, reward/epoch 8.88000, cum reward/epoch -2.92159\n",
      "step 12650000, time 314833.6, loss 0.04597493, epochs 34482, reward/epoch 9.00000, cum reward/epoch -2.91364\n",
      "step 12660000, time 315087.0, loss 0.04645498, epochs 34506, reward/epoch 7.12500, cum reward/epoch -2.90665\n",
      "step 12670000, time 315340.3, loss 0.04695515, epochs 34529, reward/epoch 7.95652, cum reward/epoch -2.89942\n",
      "step 12680000, time 315592.6, loss 0.04560093, epochs 34555, reward/epoch 8.57692, cum reward/epoch -2.89078\n",
      "step 12690000, time 315845.3, loss 0.04637710, epochs 34578, reward/epoch 7.65217, cum reward/epoch -2.88377\n",
      "step 12700000, time 316097.9, loss 0.04671138, epochs 34599, reward/epoch 7.80952, cum reward/epoch -2.87728\n",
      "step 12710000, time 316350.3, loss 0.04596896, epochs 34623, reward/epoch 8.41667, cum reward/epoch -2.86945\n",
      "step 12720000, time 316603.0, loss 0.04701617, epochs 34649, reward/epoch 8.76923, cum reward/epoch -2.86072\n",
      "step 12730000, time 316855.8, loss 0.04614260, epochs 34671, reward/epoch 7.81818, cum reward/epoch -2.85394\n",
      "step 12740000, time 317108.7, loss 0.04481953, epochs 34694, reward/epoch 8.08696, cum reward/epoch -2.84669\n",
      "step 12750000, time 317360.8, loss 0.04599989, epochs 34719, reward/epoch 6.28000, cum reward/epoch -2.84012\n",
      "step 12760000, time 317613.3, loss 0.04555956, epochs 34740, reward/epoch 7.28571, cum reward/epoch -2.83400\n",
      "step 12770000, time 317866.3, loss 0.04667096, epochs 34765, reward/epoch 4.76000, cum reward/epoch -2.82853\n",
      "step 12780000, time 318119.1, loss 0.04624050, epochs 34789, reward/epoch 10.50000, cum reward/epoch -2.81934\n",
      "step 12790000, time 318372.1, loss 0.04604803, epochs 34813, reward/epoch 7.95833, cum reward/epoch -2.81191\n",
      "step 12800000, time 318625.1, loss 0.04645916, epochs 34837, reward/epoch 7.70833, cum reward/epoch -2.80466\n",
      "step 12810000, time 318877.7, loss 0.04635812, epochs 34859, reward/epoch 8.72727, cum reward/epoch -2.79738\n",
      "step 12820000, time 319130.0, loss 0.04706490, epochs 34884, reward/epoch 6.40000, cum reward/epoch -2.79079\n",
      "step 12830000, time 319383.2, loss 0.04646773, epochs 34906, reward/epoch 7.95455, cum reward/epoch -2.78402\n",
      "step 12840000, time 319635.8, loss 0.04684585, epochs 34929, reward/epoch 8.04348, cum reward/epoch -2.77689\n",
      "step 12850000, time 319888.3, loss 0.04611674, epochs 34951, reward/epoch 6.63636, cum reward/epoch -2.77097\n",
      "step 12860000, time 320140.8, loss 0.04702843, epochs 34973, reward/epoch 4.09091, cum reward/epoch -2.76665\n",
      "step 12870000, time 320393.3, loss 0.04648656, epochs 34996, reward/epoch 7.30435, cum reward/epoch -2.76003\n",
      "step 12880000, time 320645.8, loss 0.04669826, epochs 35020, reward/epoch 6.70833, cum reward/epoch -2.75354\n",
      "step 12890000, time 320898.5, loss 0.04578736, epochs 35042, reward/epoch 6.95455, cum reward/epoch -2.74745\n",
      "step 12900000, time 321150.8, loss 0.04551362, epochs 35065, reward/epoch 6.69565, cum reward/epoch -2.74125\n",
      "step 12910000, time 321403.2, loss 0.04763707, epochs 35089, reward/epoch 6.83333, cum reward/epoch -2.73470\n",
      "step 12920000, time 321656.1, loss 0.04721833, epochs 35111, reward/epoch 7.68182, cum reward/epoch -2.72818\n",
      "step 12930000, time 321908.9, loss 0.04506222, epochs 35135, reward/epoch 6.62500, cum reward/epoch -2.72179\n",
      "step 12940000, time 322161.9, loss 0.04640207, epochs 35157, reward/epoch 5.04545, cum reward/epoch -2.71693\n",
      "step 12950000, time 322415.1, loss 0.04611899, epochs 35179, reward/epoch 5.95455, cum reward/epoch -2.71150\n",
      "step 12960000, time 322668.4, loss 0.04699605, epochs 35201, reward/epoch 7.72727, cum reward/epoch -2.70498\n",
      "step 12970000, time 322920.7, loss 0.04826020, epochs 35228, reward/epoch 2.74074, cum reward/epoch -2.70081\n",
      "step 12980000, time 323173.5, loss 0.04891125, epochs 35252, reward/epoch -0.33333, cum reward/epoch -2.69919\n",
      "step 12990000, time 323425.4, loss 0.04729356, epochs 35276, reward/epoch 6.70833, cum reward/epoch -2.69279\n",
      "step 13000000, time 323678.3, loss 0.04628607, epochs 35298, reward/epoch 7.81818, cum reward/epoch -2.68624\n",
      "step 13010000, time 323930.2, loss 0.04670276, epochs 35321, reward/epoch 7.13043, cum reward/epoch -2.67985\n",
      "step 13020000, time 324181.9, loss 0.04714790, epochs 35347, reward/epoch 6.11538, cum reward/epoch -2.67338\n",
      "step 13030000, time 324434.0, loss 0.04766401, epochs 35369, reward/epoch 5.59091, cum reward/epoch -2.66824\n",
      "step 13040000, time 324685.8, loss 0.04612247, epochs 35394, reward/epoch 8.28000, cum reward/epoch -2.66051\n",
      "step 13050000, time 324937.9, loss 0.04612556, epochs 35417, reward/epoch 6.60870, cum reward/epoch -2.65449\n",
      "step 13060000, time 325189.9, loss 0.04642256, epochs 35439, reward/epoch 6.77273, cum reward/epoch -2.64864\n",
      "step 13070000, time 325442.7, loss 0.04650542, epochs 35462, reward/epoch 9.00000, cum reward/epoch -2.64108\n",
      "step 13080000, time 325695.1, loss 0.04634394, epochs 35485, reward/epoch 5.47826, cum reward/epoch -2.63582\n",
      "step 13090000, time 325947.8, loss 0.04741175, epochs 35508, reward/epoch 8.52174, cum reward/epoch -2.62859\n",
      "step 13100000, time 326200.6, loss 0.04625953, epochs 35530, reward/epoch 9.86364, cum reward/epoch -2.62086\n",
      "step 13110000, time 326451.9, loss 0.04535933, epochs 35556, reward/epoch 6.46154, cum reward/epoch -2.61421\n",
      "step 13120000, time 326704.8, loss 0.04633467, epochs 35576, reward/epoch 8.40000, cum reward/epoch -2.60802\n",
      "step 13130000, time 326956.4, loss 0.04607267, epochs 35599, reward/epoch 7.04348, cum reward/epoch -2.60179\n",
      "step 13140000, time 327208.8, loss 0.04718161, epochs 35623, reward/epoch 7.95833, cum reward/epoch -2.59467\n",
      "step 13150000, time 327460.8, loss 0.04680674, epochs 35646, reward/epoch 5.00000, cum reward/epoch -2.58977\n",
      "step 13160000, time 327713.4, loss 0.04728341, epochs 35670, reward/epoch 5.41667, cum reward/epoch -2.58438\n",
      "step 13170000, time 327966.2, loss 0.04692552, epochs 35693, reward/epoch 7.95652, cum reward/epoch -2.57759\n",
      "step 13180000, time 328219.3, loss 0.04660618, epochs 35719, reward/epoch 9.03846, cum reward/epoch -2.56914\n",
      "step 13190000, time 328472.0, loss 0.04669939, epochs 35738, reward/epoch 3.47368, cum reward/epoch -2.56592\n",
      "step 13200000, time 328724.6, loss 0.04718610, epochs 35763, reward/epoch 8.12000, cum reward/epoch -2.55845\n",
      "step 13210000, time 328976.4, loss 0.04679690, epochs 35785, reward/epoch 6.40909, cum reward/epoch -2.55294\n",
      "step 13220000, time 329228.9, loss 0.04606477, epochs 35812, reward/epoch 6.74074, cum reward/epoch -2.54593\n",
      "step 13230000, time 329481.4, loss 0.04672338, epochs 35830, reward/epoch 8.44444, cum reward/epoch -2.54041\n",
      "step 13240000, time 329733.4, loss 0.04696050, epochs 35857, reward/epoch 5.74074, cum reward/epoch -2.53418\n",
      "step 13250000, time 329985.9, loss 0.04530443, epochs 35880, reward/epoch 11.86957, cum reward/epoch -2.52494\n",
      "step 13260000, time 330237.8, loss 0.04580532, epochs 35907, reward/epoch 6.33333, cum reward/epoch -2.51828\n",
      "step 13270000, time 330490.6, loss 0.04593309, epochs 35927, reward/epoch 5.20000, cum reward/epoch -2.51399\n",
      "step 13280000, time 330742.9, loss 0.04572764, epochs 35951, reward/epoch 6.87500, cum reward/epoch -2.50772\n",
      "step 13290000, time 330995.5, loss 0.04529294, epochs 35971, reward/epoch 6.95000, cum reward/epoch -2.50246\n",
      "step 13300000, time 331248.0, loss 0.04700736, epochs 35994, reward/epoch 6.43478, cum reward/epoch -2.49675\n",
      "step 13310000, time 331500.9, loss 0.04599626, epochs 36017, reward/epoch 7.21739, cum reward/epoch -2.49055\n",
      "step 13320000, time 331753.3, loss 0.04614753, epochs 36040, reward/epoch 6.17391, cum reward/epoch -2.48502\n",
      "step 13330000, time 332007.0, loss 0.04580208, epochs 36063, reward/epoch 6.95652, cum reward/epoch -2.47900\n",
      "step 13340000, time 332259.7, loss 0.04702080, epochs 36086, reward/epoch 5.21739, cum reward/epoch -2.47409\n",
      "step 13350000, time 332512.2, loss 0.04722372, epochs 36108, reward/epoch 7.77273, cum reward/epoch -2.46785\n",
      "step 13360000, time 332764.0, loss 0.04734819, epochs 36134, reward/epoch 7.80769, cum reward/epoch -2.46045\n",
      "step 13370000, time 333016.3, loss 0.04626888, epochs 36157, reward/epoch 9.86957, cum reward/epoch -2.45261\n",
      "step 13380000, time 333268.8, loss 0.04676673, epochs 36180, reward/epoch 7.69565, cum reward/epoch -2.44616\n",
      "step 13390000, time 333520.9, loss 0.04637624, epochs 36205, reward/epoch 7.44000, cum reward/epoch -2.43933\n",
      "step 13400000, time 333773.3, loss 0.04620056, epochs 36228, reward/epoch 6.73913, cum reward/epoch -2.43350\n",
      "step 13410000, time 334025.5, loss 0.04593576, epochs 36252, reward/epoch 9.54167, cum reward/epoch -2.42558\n",
      "step 13420000, time 334277.8, loss 0.04613561, epochs 36274, reward/epoch 7.00000, cum reward/epoch -2.41986\n",
      "step 13430000, time 334530.3, loss 0.04635744, epochs 36297, reward/epoch 8.17391, cum reward/epoch -2.41315\n",
      "step 13440000, time 334782.2, loss 0.04702507, epochs 36318, reward/epoch 8.95238, cum reward/epoch -2.40658\n",
      "step 13450000, time 335034.1, loss 0.04682032, epochs 36344, reward/epoch 7.61538, cum reward/epoch -2.39941\n",
      "step 13460000, time 335286.5, loss 0.04618846, epochs 36366, reward/epoch 9.09091, cum reward/epoch -2.39245\n",
      "step 13470000, time 335538.5, loss 0.04615404, epochs 36394, reward/epoch 5.85714, cum reward/epoch -2.38611\n",
      "step 13480000, time 335790.8, loss 0.04683023, epochs 36412, reward/epoch 6.05556, cum reward/epoch -2.38193\n",
      "step 13490000, time 336043.3, loss 0.04638089, epochs 36438, reward/epoch 8.15385, cum reward/epoch -2.37442\n",
      "step 13500000, time 336295.6, loss 0.04719609, epochs 36459, reward/epoch 7.47619, cum reward/epoch -2.36874\n",
      "step 13510000, time 336547.7, loss 0.04631636, epochs 36484, reward/epoch 7.00000, cum reward/epoch -2.36232\n",
      "step 13520000, time 336799.9, loss 0.04760287, epochs 36505, reward/epoch 5.52381, cum reward/epoch -2.35779\n",
      "step 13530000, time 337052.9, loss 0.04994034, epochs 36530, reward/epoch -2.32000, cum reward/epoch -2.35776\n",
      "step 13540000, time 337305.1, loss 0.04815352, epochs 36554, reward/epoch 4.87500, cum reward/epoch -2.35301\n",
      "step 13550000, time 337557.7, loss 0.04687413, epochs 36579, reward/epoch 8.04000, cum reward/epoch -2.34591\n",
      "step 13560000, time 337809.2, loss 0.04631103, epochs 36602, reward/epoch 6.91304, cum reward/epoch -2.34009\n",
      "step 13570000, time 338061.1, loss 0.04585017, epochs 36624, reward/epoch 6.00000, cum reward/epoch -2.33508\n",
      "step 13580000, time 338313.2, loss 0.04681604, epochs 36648, reward/epoch 6.62500, cum reward/epoch -2.32921\n",
      "step 13590000, time 338565.0, loss 0.04651190, epochs 36670, reward/epoch 9.31818, cum reward/epoch -2.32223\n",
      "step 13600000, time 338818.2, loss 0.04588059, epochs 36696, reward/epoch 7.38462, cum reward/epoch -2.31535\n",
      "step 13610000, time 339070.3, loss 0.04590164, epochs 36721, reward/epoch 8.48000, cum reward/epoch -2.30800\n",
      "step 13620000, time 339323.3, loss 0.04673542, epochs 36743, reward/epoch 8.36364, cum reward/epoch -2.30161\n",
      "step 13630000, time 339575.9, loss 0.04639317, epochs 36767, reward/epoch 8.54167, cum reward/epoch -2.29453\n",
      "step 13640000, time 339828.6, loss 0.04800089, epochs 36791, reward/epoch 6.12500, cum reward/epoch -2.28904\n",
      "step 13650000, time 340080.4, loss 0.04683491, epochs 36815, reward/epoch 8.12500, cum reward/epoch -2.28225\n",
      "step 13660000, time 340333.5, loss 0.04618778, epochs 36836, reward/epoch 8.47619, cum reward/epoch -2.27612\n",
      "step 13670000, time 340585.6, loss 0.04535871, epochs 36861, reward/epoch 6.36000, cum reward/epoch -2.27026\n",
      "step 13680000, time 340837.9, loss 0.04622092, epochs 36883, reward/epoch 8.31818, cum reward/epoch -2.26394\n",
      "step 13690000, time 341090.9, loss 0.04609188, epochs 36906, reward/epoch 7.30435, cum reward/epoch -2.25798\n",
      "step 13700000, time 341342.7, loss 0.04643700, epochs 36929, reward/epoch 8.30435, cum reward/epoch -2.25140\n",
      "step 13710000, time 341595.6, loss 0.04597692, epochs 36955, reward/epoch 6.92308, cum reward/epoch -2.24495\n",
      "step 13720000, time 341848.3, loss 0.04588477, epochs 36977, reward/epoch 7.54545, cum reward/epoch -2.23912\n",
      "step 13730000, time 342101.3, loss 0.04611974, epochs 37001, reward/epoch 5.95833, cum reward/epoch -2.23380\n",
      "step 13740000, time 342353.5, loss 0.04635609, epochs 37021, reward/epoch 9.40000, cum reward/epoch -2.22752\n",
      "step 13750000, time 342606.6, loss 0.04512692, epochs 37045, reward/epoch 9.50000, cum reward/epoch -2.21992\n",
      "step 13760000, time 342858.7, loss 0.04581900, epochs 37069, reward/epoch 6.79167, cum reward/epoch -2.21409\n",
      "step 13770000, time 343111.7, loss 0.04706888, epochs 37091, reward/epoch 8.45455, cum reward/epoch -2.20776\n",
      "step 13780000, time 343364.1, loss 0.04665658, epochs 37117, reward/epoch 8.84615, cum reward/epoch -2.20002\n",
      "step 13790000, time 343616.8, loss 0.04701488, epochs 37140, reward/epoch 7.43478, cum reward/epoch -2.19405\n",
      "step 13800000, time 343870.0, loss 0.04674536, epochs 37161, reward/epoch 7.47619, cum reward/epoch -2.18858\n",
      "step 13810000, time 344123.0, loss 0.04600512, epochs 37188, reward/epoch 6.59259, cum reward/epoch -2.18221\n",
      "step 13820000, time 344375.9, loss 0.04648756, epochs 37208, reward/epoch 8.60000, cum reward/epoch -2.17641\n",
      "step 13830000, time 344628.3, loss 0.04504146, epochs 37234, reward/epoch 9.11539, cum reward/epoch -2.16853\n",
      "step 13840000, time 344880.7, loss 0.04627652, epochs 37257, reward/epoch 8.34783, cum reward/epoch -2.16204\n",
      "step 13850000, time 345133.7, loss 0.04598586, epochs 37283, reward/epoch 7.15385, cum reward/epoch -2.15554\n",
      "step 13860000, time 345387.0, loss 0.04750421, epochs 37304, reward/epoch 8.00000, cum reward/epoch -2.14982\n",
      "step 13870000, time 345639.8, loss 0.04757749, epochs 37328, reward/epoch 6.95833, cum reward/epoch -2.14397\n",
      "step 13880000, time 345891.8, loss 0.04711621, epochs 37351, reward/epoch 7.52174, cum reward/epoch -2.13802\n",
      "step 13890000, time 346144.7, loss 0.04528508, epochs 37377, reward/epoch 8.61539, cum reward/epoch -2.13053\n",
      "step 13900000, time 346397.6, loss 0.04658090, epochs 37403, reward/epoch 7.80769, cum reward/epoch -2.12363\n",
      "step 13910000, time 346650.1, loss 0.04716641, epochs 37426, reward/epoch 6.60870, cum reward/epoch -2.11826\n",
      "step 13920000, time 346902.6, loss 0.04768140, epochs 37450, reward/epoch 5.29167, cum reward/epoch -2.11351\n",
      "step 13930000, time 347156.0, loss 0.04582206, epochs 37474, reward/epoch 6.58333, cum reward/epoch -2.10794\n",
      "step 13940000, time 347408.0, loss 0.04818266, epochs 37496, reward/epoch 6.81818, cum reward/epoch -2.10270\n",
      "step 13950000, time 347660.9, loss 0.04729154, epochs 37520, reward/epoch 5.00000, cum reward/epoch -2.09816\n",
      "step 13960000, time 347913.1, loss 0.05129206, epochs 37548, reward/epoch -3.71429, cum reward/epoch -2.09937\n",
      "step 13970000, time 348165.9, loss 0.04835815, epochs 37573, reward/epoch 4.32000, cum reward/epoch -2.09509\n",
      "step 13980000, time 348417.8, loss 0.04694511, epochs 37592, reward/epoch 4.84211, cum reward/epoch -2.09159\n",
      "step 13990000, time 348669.8, loss 0.04598366, epochs 37618, reward/epoch 6.00000, cum reward/epoch -2.08600\n",
      "step 14000000, time 348923.4, loss 0.04652439, epochs 37641, reward/epoch 10.43478, cum reward/epoch -2.07835\n",
      "step 14010000, time 349175.6, loss 0.04628461, epochs 37666, reward/epoch 7.92000, cum reward/epoch -2.07171\n",
      "step 14020000, time 349427.8, loss 0.04637085, epochs 37689, reward/epoch 9.69565, cum reward/epoch -2.06453\n",
      "step 14030000, time 349680.4, loss 0.04600323, epochs 37713, reward/epoch 8.16667, cum reward/epoch -2.05802\n",
      "step 14040000, time 349933.4, loss 0.04584641, epochs 37735, reward/epoch 8.09091, cum reward/epoch -2.05210\n",
      "step 14050000, time 350186.0, loss 0.04679682, epochs 37757, reward/epoch 6.13636, cum reward/epoch -2.04733\n",
      "step 14060000, time 350438.6, loss 0.04609649, epochs 37782, reward/epoch 5.96000, cum reward/epoch -2.04203\n",
      "step 14070000, time 350691.3, loss 0.04654520, epochs 37804, reward/epoch 8.13636, cum reward/epoch -2.03611\n",
      "step 14080000, time 350944.4, loss 0.04669411, epochs 37825, reward/epoch 7.04762, cum reward/epoch -2.03106\n",
      "step 14090000, time 351197.0, loss 0.04659636, epochs 37852, reward/epoch 7.81482, cum reward/epoch -2.02404\n",
      "step 14100000, time 351450.4, loss 0.04703522, epochs 37876, reward/epoch 8.70833, cum reward/epoch -2.01724\n",
      "step 14110000, time 351703.2, loss 0.04596193, epochs 37902, reward/epoch 8.34615, cum reward/epoch -2.01013\n",
      "step 14120000, time 351955.3, loss 0.04695148, epochs 37923, reward/epoch 4.57143, cum reward/epoch -2.00649\n",
      "step 14130000, time 352208.1, loss 0.04549935, epochs 37947, reward/epoch 9.16667, cum reward/epoch -1.99942\n",
      "step 14140000, time 352461.5, loss 0.04690510, epochs 37970, reward/epoch 10.08696, cum reward/epoch -1.99210\n",
      "step 14150000, time 352714.1, loss 0.04590319, epochs 37994, reward/epoch 7.79167, cum reward/epoch -1.98592\n",
      "step 14160000, time 352966.9, loss 0.04657484, epochs 38020, reward/epoch 7.15385, cum reward/epoch -1.97967\n",
      "step 14170000, time 353220.5, loss 0.04610412, epochs 38044, reward/epoch 10.25000, cum reward/epoch -1.97195\n",
      "step 14180000, time 353474.0, loss 0.04661390, epochs 38072, reward/epoch 8.82143, cum reward/epoch -1.96402\n",
      "step 14190000, time 353727.4, loss 0.04547078, epochs 38093, reward/epoch 10.38095, cum reward/epoch -1.95721\n",
      "step 14200000, time 353981.4, loss 0.04586932, epochs 38120, reward/epoch 6.51852, cum reward/epoch -1.95121\n",
      "step 14210000, time 354234.8, loss 0.04711082, epochs 38142, reward/epoch 7.36364, cum reward/epoch -1.94583\n",
      "step 14220000, time 354488.3, loss 0.04655004, epochs 38170, reward/epoch 6.85714, cum reward/epoch -1.93938\n",
      "step 14230000, time 354741.9, loss 0.04701624, epochs 38191, reward/epoch 9.47619, cum reward/epoch -1.93310\n",
      "step 14240000, time 354995.8, loss 0.04721565, epochs 38219, reward/epoch 7.53571, cum reward/epoch -1.92616\n",
      "step 14250000, time 355249.6, loss 0.04623284, epochs 38241, reward/epoch 7.72727, cum reward/epoch -1.92061\n",
      "step 14260000, time 355502.6, loss 0.04609994, epochs 38266, reward/epoch 8.12000, cum reward/epoch -1.91405\n",
      "step 14270000, time 355756.6, loss 0.04624481, epochs 38289, reward/epoch 7.43478, cum reward/epoch -1.90843\n",
      "step 14280000, time 356010.0, loss 0.04655942, epochs 38311, reward/epoch 7.59091, cum reward/epoch -1.90298\n",
      "step 14290000, time 356262.8, loss 0.04642911, epochs 38336, reward/epoch 6.48000, cum reward/epoch -1.89751\n",
      "step 14300000, time 356516.6, loss 0.04595688, epochs 38359, reward/epoch 8.60870, cum reward/epoch -1.89121\n",
      "step 14310000, time 356770.9, loss 0.04682421, epochs 38384, reward/epoch 6.68000, cum reward/epoch -1.88563\n",
      "step 14320000, time 357023.9, loss 0.04660711, epochs 38406, reward/epoch 6.45455, cum reward/epoch -1.88085\n",
      "step 14330000, time 357277.6, loss 0.04692217, epochs 38427, reward/epoch 7.71429, cum reward/epoch -1.87561\n",
      "step 14340000, time 357530.8, loss 0.04540393, epochs 38454, reward/epoch 7.55556, cum reward/epoch -1.86899\n",
      "step 14350000, time 357784.5, loss 0.04604526, epochs 38477, reward/epoch 7.43478, cum reward/epoch -1.86342\n",
      "step 14360000, time 358038.0, loss 0.04812319, epochs 38499, reward/epoch 8.31818, cum reward/epoch -1.85761\n",
      "step 14370000, time 358292.2, loss 0.04623939, epochs 38526, reward/epoch 7.66667, cum reward/epoch -1.85093\n",
      "step 14380000, time 358546.0, loss 0.04627544, epochs 38548, reward/epoch 9.18182, cum reward/epoch -1.84464\n",
      "step 14390000, time 358799.8, loss 0.04757777, epochs 38573, reward/epoch 6.08000, cum reward/epoch -1.83950\n",
      "step 14400000, time 359053.8, loss 0.04752456, epochs 38599, reward/epoch 5.07692, cum reward/epoch -1.83484\n",
      "step 14410000, time 359307.5, loss 0.04663429, epochs 38622, reward/epoch 6.52174, cum reward/epoch -1.82986\n",
      "step 14420000, time 359560.3, loss 0.04728444, epochs 38642, reward/epoch 7.95000, cum reward/epoch -1.82480\n",
      "step 14430000, time 359813.6, loss 0.04782486, epochs 38670, reward/epoch 5.50000, cum reward/epoch -1.81950\n",
      "step 14440000, time 360067.5, loss 0.04727455, epochs 38693, reward/epoch 9.43478, cum reward/epoch -1.81281\n",
      "step 14450000, time 360320.5, loss 0.04661577, epochs 38718, reward/epoch 6.48000, cum reward/epoch -1.80745\n",
      "step 14460000, time 360573.7, loss 0.04630804, epochs 38738, reward/epoch 8.70000, cum reward/epoch -1.80203\n",
      "step 14470000, time 360827.2, loss 0.04709372, epochs 38766, reward/epoch 5.82143, cum reward/epoch -1.79652\n",
      "step 14480000, time 361079.7, loss 0.04693693, epochs 38789, reward/epoch 7.04348, cum reward/epoch -1.79128\n",
      "step 14490000, time 361332.2, loss 0.04750369, epochs 38814, reward/epoch 7.44000, cum reward/epoch -1.78534\n",
      "step 14500000, time 361585.8, loss 0.04579698, epochs 38841, reward/epoch 7.74074, cum reward/epoch -1.77871\n",
      "step 14510000, time 361839.1, loss 0.04584989, epochs 38868, reward/epoch 10.07407, cum reward/epoch -1.77048\n",
      "step 14520000, time 362092.7, loss 0.04714715, epochs 38889, reward/epoch 10.42857, cum reward/epoch -1.76389\n",
      "step 14530000, time 362346.5, loss 0.04661912, epochs 38918, reward/epoch 6.00000, cum reward/epoch -1.75811\n",
      "step 14540000, time 362599.3, loss 0.04729188, epochs 38939, reward/epoch 7.33333, cum reward/epoch -1.75320\n",
      "step 14550000, time 362853.6, loss 0.04708161, epochs 38967, reward/epoch 9.46429, cum reward/epoch -1.74514\n",
      "step 14560000, time 363107.0, loss 0.04743224, epochs 38992, reward/epoch 9.64000, cum reward/epoch -1.73784\n",
      "step 14570000, time 363360.4, loss 0.04684886, epochs 39017, reward/epoch 7.12000, cum reward/epoch -1.73217\n",
      "step 14580000, time 363614.5, loss 0.04689152, epochs 39042, reward/epoch 8.20000, cum reward/epoch -1.72581\n",
      "step 14590000, time 363867.8, loss 0.04770051, epochs 39067, reward/epoch 8.96000, cum reward/epoch -1.71897\n",
      "step 14600000, time 364121.0, loss 0.04743996, epochs 39094, reward/epoch 6.25926, cum reward/epoch -1.71346\n",
      "step 14610000, time 364373.8, loss 0.04697022, epochs 39119, reward/epoch 9.44000, cum reward/epoch -1.70633\n",
      "step 14620000, time 364627.4, loss 0.04757630, epochs 39144, reward/epoch 8.52000, cum reward/epoch -1.69980\n",
      "step 14630000, time 364880.6, loss 0.04719680, epochs 39170, reward/epoch 6.65385, cum reward/epoch -1.69426\n",
      "step 14640000, time 365133.8, loss 0.04750096, epochs 39195, reward/epoch 7.32000, cum reward/epoch -1.68851\n",
      "step 14650000, time 365388.0, loss 0.04719390, epochs 39218, reward/epoch 7.13043, cum reward/epoch -1.68333\n",
      "step 14660000, time 365640.9, loss 0.04758684, epochs 39241, reward/epoch 8.26087, cum reward/epoch -1.67751\n",
      "step 14670000, time 365893.9, loss 0.04670950, epochs 39266, reward/epoch 7.20000, cum reward/epoch -1.67185\n",
      "step 14680000, time 366147.5, loss 0.04677414, epochs 39291, reward/epoch 8.84000, cum reward/epoch -1.66517\n",
      "step 14690000, time 366400.8, loss 0.04690616, epochs 39319, reward/epoch 7.57143, cum reward/epoch -1.65859\n",
      "step 14700000, time 366654.8, loss 0.04860181, epochs 39343, reward/epoch 8.41667, cum reward/epoch -1.65244\n",
      "step 14710000, time 366908.5, loss 0.04886622, epochs 39370, reward/epoch 6.22222, cum reward/epoch -1.64704\n",
      "step 14720000, time 367162.6, loss 0.04728957, epochs 39392, reward/epoch 10.45455, cum reward/epoch -1.64028\n",
      "step 14730000, time 367416.6, loss 0.04771750, epochs 39419, reward/epoch 6.00000, cum reward/epoch -1.63505\n",
      "step 14740000, time 367670.9, loss 0.04729591, epochs 39442, reward/epoch 8.47826, cum reward/epoch -1.62915\n",
      "step 14750000, time 367925.3, loss 0.04705553, epochs 39469, reward/epoch 8.88889, cum reward/epoch -1.62196\n",
      "step 14760000, time 368179.0, loss 0.04737332, epochs 39493, reward/epoch 8.16667, cum reward/epoch -1.61601\n",
      "step 14770000, time 368433.1, loss 0.04756187, epochs 39519, reward/epoch 8.80769, cum reward/epoch -1.60915\n",
      "step 14780000, time 368687.2, loss 0.04780560, epochs 39542, reward/epoch 5.69565, cum reward/epoch -1.60490\n",
      "step 14790000, time 368942.1, loss 0.04785180, epochs 39567, reward/epoch 6.24000, cum reward/epoch -1.59994\n",
      "step 14800000, time 369196.2, loss 0.04699136, epochs 39592, reward/epoch 7.56000, cum reward/epoch -1.59416\n",
      "step 14810000, time 369450.2, loss 0.04612643, epochs 39617, reward/epoch 8.16000, cum reward/epoch -1.58801\n",
      "step 14820000, time 369704.2, loss 0.04757088, epochs 39642, reward/epoch 8.72000, cum reward/epoch -1.58150\n",
      "step 14830000, time 369958.2, loss 0.04711989, epochs 39670, reward/epoch 7.67857, cum reward/epoch -1.57497\n",
      "step 14840000, time 370212.0, loss 0.04578037, epochs 39694, reward/epoch 7.33333, cum reward/epoch -1.56958\n",
      "step 14850000, time 370465.9, loss 0.04668032, epochs 39717, reward/epoch 9.73913, cum reward/epoch -1.56303\n",
      "step 14860000, time 370720.6, loss 0.04745744, epochs 39744, reward/epoch 7.85185, cum reward/epoch -1.55664\n",
      "step 14870000, time 370975.0, loss 0.04754617, epochs 39769, reward/epoch 6.76000, cum reward/epoch -1.55141\n",
      "step 14880000, time 371229.7, loss 0.04758706, epochs 39795, reward/epoch 8.76923, cum reward/epoch -1.54467\n",
      "step 14890000, time 371484.0, loss 0.04720246, epochs 39819, reward/epoch 8.08333, cum reward/epoch -1.53886\n",
      "step 14900000, time 371738.3, loss 0.04705000, epochs 39843, reward/epoch 8.00000, cum reward/epoch -1.53312\n",
      "step 14910000, time 371992.9, loss 0.04749253, epochs 39870, reward/epoch 3.74074, cum reward/epoch -1.52955\n",
      "step 14920000, time 372247.3, loss 0.04742369, epochs 39889, reward/epoch 2.94737, cum reward/epoch -1.52741\n",
      "step 14930000, time 372502.4, loss 0.04731284, epochs 39915, reward/epoch 4.19231, cum reward/epoch -1.52369\n",
      "step 14940000, time 372757.1, loss 0.04810929, epochs 39938, reward/epoch 2.78261, cum reward/epoch -1.52121\n",
      "step 14950000, time 373012.6, loss 0.04746545, epochs 39963, reward/epoch 4.32000, cum reward/epoch -1.51755\n",
      "step 14960000, time 373268.1, loss 0.04698329, epochs 39988, reward/epoch 4.68000, cum reward/epoch -1.51368\n",
      "step 14970000, time 373523.2, loss 0.04741708, epochs 40011, reward/epoch 5.52174, cum reward/epoch -1.50963\n",
      "step 14980000, time 373778.1, loss 0.04800422, epochs 40037, reward/epoch 7.65385, cum reward/epoch -1.50368\n",
      "step 14990000, time 374033.3, loss 0.04779450, epochs 40060, reward/epoch 7.08696, cum reward/epoch -1.49875\n",
      "step 15000000, time 374288.3, loss 0.04737164, epochs 40084, reward/epoch 8.95833, cum reward/epoch -1.49249\n",
      "step 15010000, time 374544.0, loss 0.04667935, epochs 40110, reward/epoch 6.88462, cum reward/epoch -1.48706\n",
      "step 15020000, time 374799.0, loss 0.04804374, epochs 40135, reward/epoch 9.96000, cum reward/epoch -1.47993\n",
      "step 15030000, time 375054.5, loss 0.04853197, epochs 40158, reward/epoch 6.21739, cum reward/epoch -1.47552\n",
      "step 15040000, time 375308.7, loss 0.04709472, epochs 40184, reward/epoch 9.73077, cum reward/epoch -1.46827\n",
      "step 15050000, time 375563.9, loss 0.04774843, epochs 40212, reward/epoch 6.42857, cum reward/epoch -1.46277\n",
      "step 15060000, time 375818.2, loss 0.04636763, epochs 40236, reward/epoch 6.75000, cum reward/epoch -1.45787\n",
      "step 15070000, time 376073.2, loss 0.04858711, epochs 40260, reward/epoch 5.66667, cum reward/epoch -1.45363\n",
      "step 15080000, time 376328.0, loss 0.04847149, epochs 40281, reward/epoch 10.42857, cum reward/epoch -1.44743\n",
      "step 15090000, time 376582.4, loss 0.04722628, epochs 40306, reward/epoch 6.52000, cum reward/epoch -1.44249\n",
      "step 15100000, time 376836.2, loss 0.04777597, epochs 40331, reward/epoch 7.80000, cum reward/epoch -1.43676\n",
      "step 15110000, time 377090.4, loss 0.04767391, epochs 40358, reward/epoch 7.48148, cum reward/epoch -1.43079\n",
      "step 15120000, time 377345.2, loss 0.04713398, epochs 40383, reward/epoch 9.12000, cum reward/epoch -1.42426\n",
      "step 15130000, time 377600.4, loss 0.04731449, epochs 40407, reward/epoch 7.70833, cum reward/epoch -1.41884\n",
      "step 15140000, time 377854.3, loss 0.04744965, epochs 40435, reward/epoch 7.42857, cum reward/epoch -1.41271\n",
      "step 15150000, time 378109.3, loss 0.04720751, epochs 40457, reward/epoch 10.63636, cum reward/epoch -1.40616\n",
      "step 15160000, time 378364.9, loss 0.04681399, epochs 40486, reward/epoch 7.44828, cum reward/epoch -1.39982\n",
      "step 15170000, time 378619.8, loss 0.04767495, epochs 40511, reward/epoch 8.44000, cum reward/epoch -1.39374\n",
      "step 15180000, time 378875.1, loss 0.04894755, epochs 40533, reward/epoch 9.59091, cum reward/epoch -1.38778\n",
      "step 15190000, time 379129.6, loss 0.04746535, epochs 40562, reward/epoch 8.62069, cum reward/epoch -1.38063\n",
      "step 15200000, time 379385.6, loss 0.04732387, epochs 40584, reward/epoch 8.54545, cum reward/epoch -1.37525\n",
      "step 15210000, time 379640.7, loss 0.04698623, epochs 40611, reward/epoch 9.07407, cum reward/epoch -1.36830\n",
      "step 15220000, time 379895.4, loss 0.04745782, epochs 40636, reward/epoch 10.56000, cum reward/epoch -1.36096\n",
      "step 15230000, time 380150.3, loss 0.04685484, epochs 40663, reward/epoch 7.74074, cum reward/epoch -1.35492\n",
      "step 15240000, time 380404.8, loss 0.04735226, epochs 40688, reward/epoch 7.36000, cum reward/epoch -1.34956\n",
      "step 15250000, time 380660.3, loss 0.04791392, epochs 40714, reward/epoch 8.03846, cum reward/epoch -1.34357\n",
      "step 15260000, time 380915.0, loss 0.04750264, epochs 40737, reward/epoch 8.73913, cum reward/epoch -1.33787\n",
      "step 15270000, time 381170.2, loss 0.04697671, epochs 40759, reward/epoch 7.68182, cum reward/epoch -1.33301\n",
      "step 15280000, time 381425.3, loss 0.04709783, epochs 40785, reward/epoch 7.03846, cum reward/epoch -1.32767\n",
      "step 15290000, time 381681.3, loss 0.04679567, epochs 40809, reward/epoch 9.04167, cum reward/epoch -1.32157\n",
      "step 15300000, time 381937.0, loss 0.04782839, epochs 40836, reward/epoch 9.77778, cum reward/epoch -1.31423\n",
      "step 15310000, time 382192.5, loss 0.04654934, epochs 40863, reward/epoch 9.22222, cum reward/epoch -1.30727\n",
      "step 15320000, time 382448.6, loss 0.04604714, epochs 40887, reward/epoch 10.62500, cum reward/epoch -1.30027\n",
      "step 15330000, time 382704.3, loss 0.04761868, epochs 40913, reward/epoch 7.88462, cum reward/epoch -1.29443\n",
      "step 15340000, time 382959.6, loss 0.04784385, epochs 40936, reward/epoch 4.52174, cum reward/epoch -1.29116\n",
      "step 15350000, time 383215.3, loss 0.04793028, epochs 40961, reward/epoch 6.40000, cum reward/epoch -1.28647\n",
      "step 15360000, time 383470.4, loss 0.04658438, epochs 40988, reward/epoch 9.51852, cum reward/epoch -1.27935\n",
      "step 15370000, time 383726.8, loss 0.04684253, epochs 41011, reward/epoch 8.13043, cum reward/epoch -1.27407\n",
      "step 15380000, time 383982.5, loss 0.04729543, epochs 41033, reward/epoch 9.13636, cum reward/epoch -1.26849\n",
      "step 15390000, time 384238.1, loss 0.04688730, epochs 41062, reward/epoch 8.51724, cum reward/epoch -1.26158\n",
      "step 15400000, time 384493.9, loss 0.04671718, epochs 41084, reward/epoch 10.40909, cum reward/epoch -1.25533\n",
      "step 15410000, time 384749.9, loss 0.04774299, epochs 41111, reward/epoch 7.81482, cum reward/epoch -1.24937\n",
      "step 15420000, time 385004.9, loss 0.04635070, epochs 41137, reward/epoch 8.88461, cum reward/epoch -1.24297\n",
      "step 15430000, time 385260.3, loss 0.04779873, epochs 41161, reward/epoch 10.16667, cum reward/epoch -1.23632\n",
      "step 15440000, time 385516.2, loss 0.04703813, epochs 41184, reward/epoch 7.82609, cum reward/epoch -1.23125\n",
      "step 15450000, time 385771.9, loss 0.04791000, epochs 41210, reward/epoch 9.65385, cum reward/epoch -1.22439\n",
      "step 15460000, time 386028.3, loss 0.04740514, epochs 41236, reward/epoch 8.61539, cum reward/epoch -1.21818\n",
      "step 15470000, time 386285.3, loss 0.04771868, epochs 41258, reward/epoch 9.81818, cum reward/epoch -1.21230\n",
      "step 15480000, time 386542.0, loss 0.04705174, epochs 41283, reward/epoch 7.32000, cum reward/epoch -1.20713\n",
      "step 15490000, time 386797.3, loss 0.04720244, epochs 41309, reward/epoch 8.69231, cum reward/epoch -1.20090\n",
      "step 15500000, time 387052.2, loss 0.04687123, epochs 41335, reward/epoch 12.19231, cum reward/epoch -1.19248\n",
      "step 15510000, time 387308.6, loss 0.04752001, epochs 41361, reward/epoch 8.76923, cum reward/epoch -1.18621\n",
      "step 15520000, time 387564.1, loss 0.04655049, epochs 41387, reward/epoch 7.76923, cum reward/epoch -1.18059\n",
      "step 15530000, time 387819.9, loss 0.04746206, epochs 41410, reward/epoch 10.47826, cum reward/epoch -1.17411\n",
      "step 15540000, time 388075.5, loss 0.04711374, epochs 41438, reward/epoch 8.53571, cum reward/epoch -1.16755\n",
      "step 15550000, time 388332.3, loss 0.04772451, epochs 41462, reward/epoch 7.00000, cum reward/epoch -1.16282\n",
      "step 15560000, time 388588.2, loss 0.04651691, epochs 41486, reward/epoch 9.54167, cum reward/epoch -1.15663\n",
      "step 15570000, time 388843.6, loss 0.04830219, epochs 41511, reward/epoch 8.16000, cum reward/epoch -1.15102\n",
      "step 15580000, time 389099.5, loss 0.04712347, epochs 41536, reward/epoch 8.48000, cum reward/epoch -1.14522\n",
      "step 15590000, time 389355.0, loss 0.04721448, epochs 41561, reward/epoch 7.68000, cum reward/epoch -1.13991\n",
      "step 15600000, time 389611.0, loss 0.04669116, epochs 41589, reward/epoch 10.75000, cum reward/epoch -1.13191\n",
      "step 15610000, time 389867.0, loss 0.04675940, epochs 41611, reward/epoch 9.54545, cum reward/epoch -1.12626\n",
      "step 15620000, time 390123.4, loss 0.04698562, epochs 41636, reward/epoch 9.12000, cum reward/epoch -1.12011\n",
      "step 15630000, time 390378.9, loss 0.04717770, epochs 41664, reward/epoch 8.53571, cum reward/epoch -1.11362\n",
      "step 15640000, time 390634.9, loss 0.04699963, epochs 41686, reward/epoch 9.77273, cum reward/epoch -1.10788\n",
      "step 15650000, time 390891.3, loss 0.05015381, epochs 41715, reward/epoch 0.58621, cum reward/epoch -1.10670\n",
      "step 15660000, time 391147.1, loss 0.05130347, epochs 41740, reward/epoch -3.52000, cum reward/epoch -1.10815\n",
      "step 15670000, time 391402.2, loss 0.05014571, epochs 41763, reward/epoch 7.21739, cum reward/epoch -1.10356\n",
      "step 15680000, time 391657.8, loss 0.04863750, epochs 41791, reward/epoch 8.50000, cum reward/epoch -1.09713\n",
      "step 15690000, time 391912.9, loss 0.04652412, epochs 41815, reward/epoch 9.12500, cum reward/epoch -1.09126\n",
      "step 15700000, time 392167.8, loss 0.04808251, epochs 41838, reward/epoch 8.30435, cum reward/epoch -1.08609\n",
      "step 15710000, time 392422.3, loss 0.04694859, epochs 41862, reward/epoch 8.41667, cum reward/epoch -1.08065\n",
      "step 15720000, time 392677.1, loss 0.04795362, epochs 41887, reward/epoch 8.80000, cum reward/epoch -1.07475\n",
      "step 15730000, time 392932.8, loss 0.04556530, epochs 41912, reward/epoch 8.92000, cum reward/epoch -1.06879\n",
      "step 15740000, time 393187.5, loss 0.04780695, epochs 41935, reward/epoch 9.26087, cum reward/epoch -1.06312\n",
      "step 15750000, time 393443.2, loss 0.04709421, epochs 41963, reward/epoch 9.82143, cum reward/epoch -1.05586\n",
      "step 15760000, time 393698.3, loss 0.04640730, epochs 41985, reward/epoch 9.13636, cum reward/epoch -1.05052\n",
      "step 15770000, time 393955.4, loss 0.04590593, epochs 42009, reward/epoch 7.54167, cum reward/epoch -1.04561\n",
      "step 15780000, time 394211.7, loss 0.04668480, epochs 42033, reward/epoch 6.04167, cum reward/epoch -1.04156\n",
      "step 15790000, time 394468.3, loss 0.04616028, epochs 42061, reward/epoch 9.92857, cum reward/epoch -1.03426\n",
      "step 15800000, time 394724.7, loss 0.04710869, epochs 42085, reward/epoch 7.37500, cum reward/epoch -1.02946\n",
      "step 15810000, time 394980.9, loss 0.04737946, epochs 42108, reward/epoch 9.04348, cum reward/epoch -1.02396\n",
      "step 15820000, time 395237.2, loss 0.04596067, epochs 42133, reward/epoch 7.48000, cum reward/epoch -1.01892\n",
      "step 15830000, time 395494.6, loss 0.04671539, epochs 42155, reward/epoch 11.13636, cum reward/epoch -1.01257\n",
      "step 15840000, time 395751.4, loss 0.04554446, epochs 42179, reward/epoch 8.91667, cum reward/epoch -1.00692\n",
      "step 15850000, time 396008.0, loss 0.04613310, epochs 42206, reward/epoch 7.03704, cum reward/epoch -1.00178\n",
      "step 15860000, time 396264.3, loss 0.04620113, epochs 42228, reward/epoch 7.77273, cum reward/epoch -0.99721\n",
      "step 15870000, time 396521.8, loss 0.04711248, epochs 42254, reward/epoch 7.03846, cum reward/epoch -0.99226\n",
      "step 15880000, time 396778.1, loss 0.04643689, epochs 42275, reward/epoch 8.09524, cum reward/epoch -0.98775\n",
      "step 15890000, time 397034.9, loss 0.04765128, epochs 42303, reward/epoch 7.25000, cum reward/epoch -0.98229\n",
      "step 15900000, time 397291.1, loss 0.04656261, epochs 42323, reward/epoch 6.90000, cum reward/epoch -0.97857\n",
      "step 15910000, time 397548.5, loss 0.04629374, epochs 42349, reward/epoch 8.03846, cum reward/epoch -0.97303\n",
      "step 15920000, time 397805.6, loss 0.04577061, epochs 42374, reward/epoch 9.72000, cum reward/epoch -0.96672\n",
      "step 15930000, time 398061.7, loss 0.04713670, epochs 42395, reward/epoch 10.28571, cum reward/epoch -0.96115\n",
      "step 15940000, time 398318.0, loss 0.04682903, epochs 42424, reward/epoch 6.89655, cum reward/epoch -0.95578\n",
      "step 15950000, time 398574.0, loss 0.04696896, epochs 42444, reward/epoch 9.10000, cum reward/epoch -0.95104\n",
      "step 15960000, time 398829.6, loss 0.04574941, epochs 42471, reward/epoch 8.40741, cum reward/epoch -0.94509\n",
      "step 15970000, time 399086.0, loss 0.04631783, epochs 42494, reward/epoch 11.95652, cum reward/epoch -0.93811\n",
      "step 15980000, time 399342.3, loss 0.04690747, epochs 42523, reward/epoch 9.17241, cum reward/epoch -0.93121\n",
      "step 15990000, time 399598.7, loss 0.04629508, epochs 42544, reward/epoch 10.47619, cum reward/epoch -0.92558\n",
      "step 16000000, time 399855.2, loss 0.04687967, epochs 42571, reward/epoch 8.22222, cum reward/epoch -0.91978\n",
      "step 16010000, time 400111.9, loss 0.04678598, epochs 42593, reward/epoch 6.45455, cum reward/epoch -0.91597\n",
      "step 16020000, time 400368.3, loss 0.04664403, epochs 42618, reward/epoch 7.12000, cum reward/epoch -0.91126\n",
      "step 16030000, time 400625.4, loss 0.04718695, epochs 42641, reward/epoch 8.82609, cum reward/epoch -0.90601\n",
      "step 16040000, time 400881.8, loss 0.04588576, epochs 42666, reward/epoch 10.80000, cum reward/epoch -0.89915\n",
      "step 16050000, time 401137.8, loss 0.04734565, epochs 42693, reward/epoch 10.00000, cum reward/epoch -0.89225\n",
      "step 16060000, time 401394.5, loss 0.04634699, epochs 42718, reward/epoch 8.56000, cum reward/epoch -0.88672\n",
      "step 16070000, time 401650.7, loss 0.04627395, epochs 42744, reward/epoch 9.65385, cum reward/epoch -0.88031\n",
      "step 16080000, time 401906.8, loss 0.04830668, epochs 42769, reward/epoch 9.64000, cum reward/epoch -0.87416\n",
      "step 16090000, time 402163.5, loss 0.04649802, epochs 42796, reward/epoch 10.14815, cum reward/epoch -0.86721\n",
      "step 16100000, time 402419.9, loss 0.04668470, epochs 42820, reward/epoch 11.41667, cum reward/epoch -0.86032\n",
      "step 16110000, time 402676.4, loss 0.04722931, epochs 42845, reward/epoch 9.16000, cum reward/epoch -0.85448\n",
      "step 16120000, time 402932.7, loss 0.04640720, epochs 42873, reward/epoch 10.10714, cum reward/epoch -0.84732\n",
      "step 16130000, time 403189.1, loss 0.04675827, epochs 42895, reward/epoch 8.59091, cum reward/epoch -0.84248\n",
      "step 16140000, time 403445.2, loss 0.04860702, epochs 42923, reward/epoch 9.64286, cum reward/epoch -0.83564\n",
      "step 16150000, time 403701.4, loss 0.04803535, epochs 42946, reward/epoch 9.69565, cum reward/epoch -0.83000\n",
      "step 16160000, time 403957.8, loss 0.04677675, epochs 42968, reward/epoch 8.22727, cum reward/epoch -0.82536\n",
      "step 16170000, time 404215.0, loss 0.04706749, epochs 42995, reward/epoch 6.33333, cum reward/epoch -0.82086\n",
      "step 16180000, time 404470.9, loss 0.04610148, epochs 43020, reward/epoch 11.24000, cum reward/epoch -0.81385\n",
      "step 16190000, time 404728.1, loss 0.04740802, epochs 43044, reward/epoch 7.04167, cum reward/epoch -0.80947\n",
      "step 16200000, time 404984.8, loss 0.04699608, epochs 43070, reward/epoch 7.07692, cum reward/epoch -0.80471\n",
      "step 16210000, time 405240.8, loss 0.04649111, epochs 43093, reward/epoch 9.69565, cum reward/epoch -0.79911\n",
      "step 16220000, time 405497.7, loss 0.04633529, epochs 43120, reward/epoch 10.96296, cum reward/epoch -0.79174\n",
      "step 16230000, time 405754.7, loss 0.04695065, epochs 43144, reward/epoch 10.00000, cum reward/epoch -0.78574\n",
      "step 16240000, time 406012.2, loss 0.04720712, epochs 43166, reward/epoch 9.09091, cum reward/epoch -0.78071\n",
      "step 16250000, time 406268.8, loss 0.04712208, epochs 43192, reward/epoch 9.38461, cum reward/epoch -0.77459\n",
      "step 16260000, time 406526.1, loss 0.04567098, epochs 43219, reward/epoch 8.40741, cum reward/epoch -0.76885\n",
      "step 16270000, time 406782.3, loss 0.04641615, epochs 43240, reward/epoch 10.57143, cum reward/epoch -0.76334\n",
      "step 16280000, time 407039.1, loss 0.04573737, epochs 43270, reward/epoch 7.50000, cum reward/epoch -0.75761\n",
      "step 16290000, time 407296.5, loss 0.04651175, epochs 43292, reward/epoch 9.36364, cum reward/epoch -0.75247\n",
      "step 16300000, time 407553.2, loss 0.04622439, epochs 43316, reward/epoch 8.25000, cum reward/epoch -0.74748\n",
      "step 16310000, time 407810.2, loss 0.04714171, epochs 43341, reward/epoch 9.12000, cum reward/epoch -0.74179\n",
      "step 16320000, time 408066.8, loss 0.04584209, epochs 43364, reward/epoch 11.04348, cum reward/epoch -0.73554\n",
      "step 16330000, time 408324.1, loss 0.04577282, epochs 43391, reward/epoch 10.77778, cum reward/epoch -0.72838\n",
      "step 16340000, time 408580.7, loss 0.04648459, epochs 43414, reward/epoch 8.47826, cum reward/epoch -0.72350\n",
      "step 16350000, time 408837.3, loss 0.04593079, epochs 43442, reward/epoch 9.53571, cum reward/epoch -0.71689\n",
      "step 16360000, time 409094.1, loss 0.04703088, epochs 43465, reward/epoch 11.34783, cum reward/epoch -0.71050\n",
      "step 16370000, time 409350.8, loss 0.04712585, epochs 43495, reward/epoch 9.30000, cum reward/epoch -0.70360\n",
      "step 16380000, time 409607.1, loss 0.04678360, epochs 43519, reward/epoch 10.66667, cum reward/epoch -0.69733\n",
      "step 16390000, time 409863.6, loss 0.04614224, epochs 43542, reward/epoch 9.00000, cum reward/epoch -0.69221\n",
      "step 16400000, time 410119.9, loss 0.04619957, epochs 43569, reward/epoch 7.48148, cum reward/epoch -0.68714\n",
      "step 16410000, time 410376.7, loss 0.04676701, epochs 43592, reward/epoch 10.78261, cum reward/epoch -0.68109\n",
      "step 16420000, time 410633.7, loss 0.04738054, epochs 43619, reward/epoch 8.25926, cum reward/epoch -0.67555\n",
      "step 16430000, time 410889.7, loss 0.04592384, epochs 43641, reward/epoch 10.63636, cum reward/epoch -0.66985\n",
      "step 16440000, time 411146.3, loss 0.04653089, epochs 43668, reward/epoch 6.44444, cum reward/epoch -0.66545\n",
      "step 16450000, time 411402.6, loss 0.04779977, epochs 43692, reward/epoch 6.20833, cum reward/epoch -0.66168\n",
      "step 16460000, time 411659.6, loss 0.04885305, epochs 43717, reward/epoch 3.96000, cum reward/epoch -0.65903\n",
      "step 16470000, time 411916.6, loss 0.04719296, epochs 43741, reward/epoch 6.87500, cum reward/epoch -0.65490\n",
      "step 16480000, time 412173.2, loss 0.04665189, epochs 43766, reward/epoch 10.56000, cum reward/epoch -0.64849\n",
      "step 16490000, time 412429.7, loss 0.04657999, epochs 43793, reward/epoch 7.70370, cum reward/epoch -0.64334\n",
      "step 16500000, time 412686.1, loss 0.04654249, epochs 43818, reward/epoch 10.60000, cum reward/epoch -0.63693\n",
      "step 16510000, time 412942.0, loss 0.04602065, epochs 43842, reward/epoch 10.08333, cum reward/epoch -0.63106\n",
      "step 16520000, time 413198.5, loss 0.04690641, epochs 43868, reward/epoch 8.92308, cum reward/epoch -0.62540\n",
      "step 16530000, time 413455.0, loss 0.04656307, epochs 43891, reward/epoch 10.13043, cum reward/epoch -0.61976\n",
      "step 16540000, time 413712.1, loss 0.04813089, epochs 43915, reward/epoch 5.50000, cum reward/epoch -0.61642\n",
      "step 16550000, time 413970.5, loss 0.04762657, epochs 43941, reward/epoch 5.73077, cum reward/epoch -0.61266\n",
      "step 16560000, time 414227.2, loss 0.04643575, epochs 43964, reward/epoch 8.13043, cum reward/epoch -0.60809\n",
      "step 16570000, time 414484.1, loss 0.04722509, epochs 43991, reward/epoch 8.55556, cum reward/epoch -0.60246\n",
      "step 16580000, time 414740.7, loss 0.04766119, epochs 44014, reward/epoch 8.00000, cum reward/epoch -0.59797\n",
      "step 16590000, time 414997.8, loss 0.04659255, epochs 44036, reward/epoch 10.54545, cum reward/epoch -0.59240\n",
      "step 16600000, time 415254.7, loss 0.04714971, epochs 44063, reward/epoch 8.18519, cum reward/epoch -0.58702\n",
      "step 16610000, time 415510.9, loss 0.04619572, epochs 44086, reward/epoch 9.95652, cum reward/epoch -0.58152\n",
      "step 16620000, time 415767.5, loss 0.04659978, epochs 44115, reward/epoch 8.41379, cum reward/epoch -0.57561\n",
      "step 16630000, time 416024.0, loss 0.04761112, epochs 44140, reward/epoch 9.60000, cum reward/epoch -0.56985\n",
      "step 16640000, time 416281.3, loss 0.04671877, epochs 44161, reward/epoch 10.66667, cum reward/epoch -0.56450\n",
      "step 16650000, time 416538.9, loss 0.04578450, epochs 44189, reward/epoch 9.21429, cum reward/epoch -0.55831\n",
      "step 16660000, time 416795.5, loss 0.04686449, epochs 44212, reward/epoch 9.17391, cum reward/epoch -0.55324\n",
      "step 16670000, time 417053.1, loss 0.04692709, epochs 44238, reward/epoch 9.80769, cum reward/epoch -0.54715\n",
      "step 16680000, time 417309.2, loss 0.04642872, epochs 44264, reward/epoch 7.96154, cum reward/epoch -0.54216\n",
      "step 16690000, time 417566.1, loss 0.04619541, epochs 44291, reward/epoch 10.51852, cum reward/epoch -0.53541\n",
      "step 16700000, time 417824.1, loss 0.04680005, epochs 44316, reward/epoch 10.32000, cum reward/epoch -0.52929\n",
      "step 16710000, time 418081.6, loss 0.04674413, epochs 44343, reward/epoch 8.22222, cum reward/epoch -0.52396\n",
      "step 16720000, time 418338.6, loss 0.04727283, epochs 44365, reward/epoch 10.22727, cum reward/epoch -0.51863\n",
      "step 16730000, time 418594.9, loss 0.04600817, epochs 44393, reward/epoch 7.39286, cum reward/epoch -0.51364\n",
      "step 16740000, time 418852.4, loss 0.04697152, epochs 44417, reward/epoch 12.29167, cum reward/epoch -0.50672\n",
      "step 16750000, time 419109.0, loss 0.04757290, epochs 44442, reward/epoch 11.48000, cum reward/epoch -0.49998\n",
      "step 16760000, time 419366.1, loss 0.04650018, epochs 44471, reward/epoch 8.06897, cum reward/epoch -0.49439\n",
      "step 16770000, time 419622.6, loss 0.04575270, epochs 44497, reward/epoch 11.73077, cum reward/epoch -0.48725\n",
      "step 16780000, time 419879.8, loss 0.04639672, epochs 44525, reward/epoch 8.67857, cum reward/epoch -0.48148\n",
      "step 16790000, time 420137.3, loss 0.04717973, epochs 44545, reward/epoch 9.85000, cum reward/epoch -0.47684\n",
      "step 16800000, time 420393.8, loss 0.04584462, epochs 44575, reward/epoch 10.20000, cum reward/epoch -0.46966\n",
      "step 16810000, time 420650.8, loss 0.04570101, epochs 44598, reward/epoch 10.13043, cum reward/epoch -0.46419\n",
      "step 16820000, time 420907.9, loss 0.04591824, epochs 44623, reward/epoch 9.04000, cum reward/epoch -0.45887\n",
      "step 16830000, time 421165.1, loss 0.04633215, epochs 44648, reward/epoch 8.28000, cum reward/epoch -0.45397\n",
      "step 16840000, time 421422.3, loss 0.04601240, epochs 44676, reward/epoch 10.10714, cum reward/epoch -0.44735\n",
      "step 16850000, time 421680.2, loss 0.04670028, epochs 44703, reward/epoch 10.25926, cum reward/epoch -0.44089\n",
      "step 16860000, time 421937.2, loss 0.04592431, epochs 44731, reward/epoch 9.71429, cum reward/epoch -0.43453\n",
      "step 16870000, time 422193.6, loss 0.04668692, epochs 44753, reward/epoch 11.59091, cum reward/epoch -0.42862\n",
      "step 16880000, time 422450.3, loss 0.04718005, epochs 44781, reward/epoch 8.85714, cum reward/epoch -0.42281\n",
      "step 16890000, time 422706.7, loss 0.04609937, epochs 44809, reward/epoch 10.85714, cum reward/epoch -0.41576\n",
      "step 16900000, time 422963.6, loss 0.04681332, epochs 44835, reward/epoch 9.88461, cum reward/epoch -0.40979\n",
      "step 16910000, time 423220.8, loss 0.04657555, epochs 44861, reward/epoch 8.42308, cum reward/epoch -0.40467\n",
      "step 16920000, time 423477.7, loss 0.04634998, epochs 44882, reward/epoch 9.85714, cum reward/epoch -0.39987\n",
      "step 16930000, time 423735.0, loss 0.04725979, epochs 44909, reward/epoch 8.40741, cum reward/epoch -0.39458\n",
      "step 16940000, time 423991.9, loss 0.04661766, epochs 44932, reward/epoch 8.43478, cum reward/epoch -0.39006\n",
      "step 16950000, time 424248.6, loss 0.04782297, epochs 44960, reward/epoch 9.53571, cum reward/epoch -0.38387\n",
      "step 16960000, time 424505.2, loss 0.04645777, epochs 44987, reward/epoch 9.18519, cum reward/epoch -0.37813\n",
      "step 16970000, time 424761.7, loss 0.04599621, epochs 45010, reward/epoch 10.52174, cum reward/epoch -0.37256\n",
      "step 16980000, time 425019.0, loss 0.04702510, epochs 45036, reward/epoch 4.50000, cum reward/epoch -0.36975\n",
      "step 16990000, time 425275.3, loss 0.04538253, epochs 45060, reward/epoch 11.95833, cum reward/epoch -0.36318\n",
      "step 17000000, time 425532.3, loss 0.04662966, epochs 45087, reward/epoch 9.14815, cum reward/epoch -0.35749\n",
      "step 17010000, time 425789.6, loss 0.04681421, epochs 45110, reward/epoch 11.30435, cum reward/epoch -0.35154\n",
      "step 17020000, time 426047.5, loss 0.04549632, epochs 45137, reward/epoch 10.22222, cum reward/epoch -0.34522\n",
      "step 17030000, time 426304.6, loss 0.04706954, epochs 45164, reward/epoch 8.48148, cum reward/epoch -0.33994\n",
      "step 17040000, time 426561.0, loss 0.04539878, epochs 45190, reward/epoch 11.84615, cum reward/epoch -0.33293\n",
      "step 17050000, time 426817.7, loss 0.04662155, epochs 45218, reward/epoch 9.85714, cum reward/epoch -0.32662\n",
      "step 17060000, time 427074.3, loss 0.04616923, epochs 45241, reward/epoch 9.69565, cum reward/epoch -0.32152\n",
      "step 17070000, time 427331.3, loss 0.04713533, epochs 45264, reward/epoch 7.17391, cum reward/epoch -0.31771\n",
      "step 17080000, time 427588.5, loss 0.04631964, epochs 45291, reward/epoch 8.62963, cum reward/epoch -0.31238\n",
      "step 17090000, time 427845.6, loss 0.04590028, epochs 45314, reward/epoch 6.60870, cum reward/epoch -0.30887\n",
      "step 17100000, time 428102.4, loss 0.04711078, epochs 45340, reward/epoch 6.84615, cum reward/epoch -0.30476\n",
      "step 17110000, time 428358.9, loss 0.04658295, epochs 45364, reward/epoch 9.66667, cum reward/epoch -0.29949\n",
      "step 17120000, time 428616.1, loss 0.04627583, epochs 45388, reward/epoch 8.91667, cum reward/epoch -0.29462\n",
      "step 17130000, time 428873.3, loss 0.04686306, epochs 45412, reward/epoch 9.00000, cum reward/epoch -0.28970\n",
      "step 17140000, time 429130.0, loss 0.04639151, epochs 45438, reward/epoch 8.50000, cum reward/epoch -0.28467\n",
      "step 17150000, time 429387.1, loss 0.04615187, epochs 45465, reward/epoch 8.55556, cum reward/epoch -0.27942\n",
      "step 17160000, time 429644.3, loss 0.04619187, epochs 45489, reward/epoch 8.45833, cum reward/epoch -0.27481\n",
      "step 17170000, time 429901.4, loss 0.04636558, epochs 45512, reward/epoch 8.95652, cum reward/epoch -0.27015\n",
      "step 17180000, time 430157.9, loss 0.04700605, epochs 45539, reward/epoch 7.48148, cum reward/epoch -0.26555\n",
      "step 17190000, time 430414.6, loss 0.04638871, epochs 45563, reward/epoch 9.45833, cum reward/epoch -0.26043\n",
      "step 17200000, time 430671.4, loss 0.04666592, epochs 45587, reward/epoch 6.91667, cum reward/epoch -0.25665\n",
      "step 17210000, time 430928.7, loss 0.04604165, epochs 45611, reward/epoch 9.41667, cum reward/epoch -0.25156\n",
      "step 17220000, time 431185.8, loss 0.04660242, epochs 45638, reward/epoch 8.85185, cum reward/epoch -0.24618\n",
      "step 17230000, time 431442.8, loss 0.04719066, epochs 45660, reward/epoch 8.36364, cum reward/epoch -0.24203\n",
      "step 17240000, time 431699.7, loss 0.04724351, epochs 45685, reward/epoch 5.96000, cum reward/epoch -0.23863\n",
      "step 17250000, time 431956.2, loss 0.04644859, epochs 45710, reward/epoch 8.88000, cum reward/epoch -0.23365\n",
      "step 17260000, time 432213.7, loss 0.04607441, epochs 45732, reward/epoch 9.86364, cum reward/epoch -0.22879\n",
      "step 17270000, time 432471.0, loss 0.04691994, epochs 45762, reward/epoch 7.10000, cum reward/epoch -0.22398\n",
      "step 17280000, time 432728.5, loss 0.04554674, epochs 45784, reward/epoch 11.04545, cum reward/epoch -0.21857\n",
      "step 17290000, time 432985.8, loss 0.04759105, epochs 45808, reward/epoch 7.12500, cum reward/epoch -0.21472\n",
      "step 17300000, time 433242.3, loss 0.04665090, epochs 45832, reward/epoch 10.08333, cum reward/epoch -0.20933\n",
      "step 17310000, time 433499.6, loss 0.04739413, epochs 45861, reward/epoch 8.00000, cum reward/epoch -0.20414\n",
      "step 17320000, time 433756.5, loss 0.04761102, epochs 45885, reward/epoch 9.20833, cum reward/epoch -0.19922\n",
      "step 17330000, time 434013.6, loss 0.04655611, epochs 45911, reward/epoch 7.84615, cum reward/epoch -0.19466\n",
      "step 17340000, time 434270.3, loss 0.04624780, epochs 45937, reward/epoch 10.80769, cum reward/epoch -0.18843\n",
      "step 17350000, time 434527.1, loss 0.04717961, epochs 45962, reward/epoch 8.84000, cum reward/epoch -0.18352\n",
      "step 17360000, time 434784.6, loss 0.04696576, epochs 45987, reward/epoch 6.72000, cum reward/epoch -0.17977\n",
      "step 17370000, time 435042.0, loss 0.04717356, epochs 46010, reward/epoch 9.95652, cum reward/epoch -0.17470\n",
      "step 17380000, time 435299.2, loss 0.04754402, epochs 46035, reward/epoch 8.60000, cum reward/epoch -0.16994\n",
      "step 17390000, time 435556.0, loss 0.04620529, epochs 46058, reward/epoch 8.17391, cum reward/epoch -0.16577\n",
      "step 17400000, time 435813.3, loss 0.04750744, epochs 46083, reward/epoch 9.80000, cum reward/epoch -0.16036\n",
      "step 17410000, time 436070.0, loss 0.04667018, epochs 46108, reward/epoch 9.40000, cum reward/epoch -0.15518\n",
      "step 17420000, time 436326.6, loss 0.04669990, epochs 46135, reward/epoch 8.03704, cum reward/epoch -0.15038\n",
      "step 17430000, time 436583.3, loss 0.04666825, epochs 46161, reward/epoch 11.34615, cum reward/epoch -0.14391\n",
      "step 17440000, time 436840.3, loss 0.04585997, epochs 46189, reward/epoch 8.39286, cum reward/epoch -0.13873\n",
      "step 17450000, time 437098.9, loss 0.04602191, epochs 46212, reward/epoch 10.26087, cum reward/epoch -0.13356\n",
      "step 17460000, time 437355.9, loss 0.04706633, epochs 46237, reward/epoch 7.04000, cum reward/epoch -0.12968\n",
      "step 17470000, time 437612.6, loss 0.04677464, epochs 46259, reward/epoch 7.95455, cum reward/epoch -0.12583\n",
      "step 17480000, time 437869.6, loss 0.04782337, epochs 46284, reward/epoch 8.28000, cum reward/epoch -0.12129\n",
      "step 17490000, time 438126.4, loss 0.05075508, epochs 46315, reward/epoch 0.19355, cum reward/epoch -0.12108\n",
      "step 17500000, time 438383.8, loss 0.04686328, epochs 46338, reward/epoch 9.04348, cum reward/epoch -0.11654\n",
      "step 17510000, time 438640.4, loss 0.04748906, epochs 46361, reward/epoch 9.56522, cum reward/epoch -0.11173\n",
      "step 17520000, time 438898.5, loss 0.04594743, epochs 46385, reward/epoch 8.87500, cum reward/epoch -0.10708\n",
      "step 17530000, time 439155.5, loss 0.04641320, epochs 46409, reward/epoch 10.87500, cum reward/epoch -0.10140\n",
      "step 17540000, time 439412.3, loss 0.04698203, epochs 46434, reward/epoch 7.72000, cum reward/epoch -0.09719\n",
      "step 17550000, time 439669.3, loss 0.04703699, epochs 46456, reward/epoch 7.18182, cum reward/epoch -0.09374\n",
      "step 17560000, time 439926.4, loss 0.04609959, epochs 46483, reward/epoch 10.22222, cum reward/epoch -0.08775\n",
      "step 17570000, time 440183.6, loss 0.04572229, epochs 46507, reward/epoch 8.79167, cum reward/epoch -0.08317\n",
      "step 17580000, time 440440.9, loss 0.04688296, epochs 46533, reward/epoch 9.23077, cum reward/epoch -0.07797\n",
      "step 17590000, time 440697.8, loss 0.04748045, epochs 46556, reward/epoch 8.47826, cum reward/epoch -0.07374\n",
      "step 17600000, time 440954.5, loss 0.04660344, epochs 46579, reward/epoch 8.47826, cum reward/epoch -0.06952\n",
      "step 17610000, time 441212.0, loss 0.04640967, epochs 46604, reward/epoch 5.24000, cum reward/epoch -0.06667\n",
      "step 17620000, time 441469.7, loss 0.04701480, epochs 46625, reward/epoch 9.38095, cum reward/epoch -0.06241\n",
      "step 17630000, time 441727.4, loss 0.04631261, epochs 46652, reward/epoch 7.55556, cum reward/epoch -0.05800\n",
      "step 17640000, time 441986.3, loss 0.04577742, epochs 46677, reward/epoch 11.12000, cum reward/epoch -0.05202\n",
      "step 17650000, time 442244.0, loss 0.04677965, epochs 46703, reward/epoch 8.88461, cum reward/epoch -0.04704\n",
      "step 17660000, time 442501.7, loss 0.04701313, epochs 46727, reward/epoch 10.12500, cum reward/epoch -0.04182\n",
      "step 17670000, time 442759.8, loss 0.04658985, epochs 46749, reward/epoch 8.63636, cum reward/epoch -0.03773\n",
      "step 17680000, time 443017.7, loss 0.04629299, epochs 46774, reward/epoch 7.32000, cum reward/epoch -0.03380\n",
      "step 17690000, time 443274.8, loss 0.04690212, epochs 46800, reward/epoch 9.30769, cum reward/epoch -0.02861\n",
      "step 17700000, time 443532.5, loss 0.04676374, epochs 46825, reward/epoch 5.88000, cum reward/epoch -0.02546\n",
      "step 17710000, time 443790.8, loss 0.04634348, epochs 46850, reward/epoch 11.68000, cum reward/epoch -0.01921\n",
      "step 17720000, time 444049.1, loss 0.04605401, epochs 46874, reward/epoch 6.16667, cum reward/epoch -0.01604\n",
      "step 17730000, time 444307.3, loss 0.04718658, epochs 46898, reward/epoch 10.16667, cum reward/epoch -0.01083\n",
      "step 17740000, time 444564.9, loss 0.04633136, epochs 46925, reward/epoch 9.33333, cum reward/epoch -0.00546\n",
      "step 17750000, time 444821.7, loss 0.04591819, epochs 46951, reward/epoch 8.30769, cum reward/epoch -0.00085\n",
      "step 17760000, time 445079.9, loss 0.04717257, epochs 46973, reward/epoch 9.00000, cum reward/epoch 0.00336\n",
      "step 17770000, time 445338.1, loss 0.04719021, epochs 46999, reward/epoch 8.80769, cum reward/epoch 0.00823\n",
      "step 17780000, time 445595.9, loss 0.04707440, epochs 47024, reward/epoch 9.16000, cum reward/epoch 0.01310\n",
      "step 17790000, time 445853.3, loss 0.04607908, epochs 47050, reward/epoch 9.23077, cum reward/epoch 0.01819\n",
      "step 17800000, time 446110.9, loss 0.04641753, epochs 47078, reward/epoch 7.78571, cum reward/epoch 0.02281\n",
      "step 17810000, time 446368.1, loss 0.04626803, epochs 47098, reward/epoch 10.85000, cum reward/epoch 0.02741\n",
      "step 17820000, time 446625.6, loss 0.04691206, epochs 47127, reward/epoch 7.89655, cum reward/epoch 0.03225\n",
      "step 17830000, time 446883.3, loss 0.04680010, epochs 47146, reward/epoch 7.26316, cum reward/epoch 0.03517\n",
      "step 17840000, time 447141.4, loss 0.04604311, epochs 47171, reward/epoch 8.36000, cum reward/epoch 0.03958\n",
      "step 17850000, time 447399.0, loss 0.04649581, epochs 47194, reward/epoch 10.86957, cum reward/epoch 0.04486\n",
      "step 17860000, time 447656.8, loss 0.04675934, epochs 47221, reward/epoch 6.92593, cum reward/epoch 0.04879\n",
      "step 17870000, time 447914.2, loss 0.04646059, epochs 47243, reward/epoch 8.59091, cum reward/epoch 0.05277\n",
      "step 17880000, time 448172.2, loss 0.04673428, epochs 47269, reward/epoch 6.69231, cum reward/epoch 0.05642\n",
      "step 17890000, time 448429.8, loss 0.04621119, epochs 47290, reward/epoch 7.04762, cum reward/epoch 0.05953\n",
      "step 17900000, time 448688.1, loss 0.04551058, epochs 47313, reward/epoch 9.17391, cum reward/epoch 0.06396\n",
      "step 17910000, time 448945.7, loss 0.04740010, epochs 47339, reward/epoch 8.76923, cum reward/epoch 0.06874\n",
      "step 17920000, time 449203.2, loss 0.04589283, epochs 47364, reward/epoch 9.28000, cum reward/epoch 0.07360\n",
      "step 17930000, time 449461.4, loss 0.04699100, epochs 47387, reward/epoch 7.30435, cum reward/epoch 0.07711\n",
      "step 17940000, time 449719.8, loss 0.04681182, epochs 47413, reward/epoch 7.53846, cum reward/epoch 0.08120\n",
      "step 17950000, time 449978.2, loss 0.04588205, epochs 47439, reward/epoch 11.76923, cum reward/epoch 0.08761\n",
      "step 17960000, time 450236.0, loss 0.04624318, epochs 47463, reward/epoch 9.08333, cum reward/epoch 0.09216\n",
      "step 17970000, time 450494.3, loss 0.04664533, epochs 47489, reward/epoch 6.80769, cum reward/epoch 0.09583\n",
      "step 17980000, time 450752.2, loss 0.04569198, epochs 47512, reward/epoch 9.04348, cum reward/epoch 0.10016\n",
      "step 17990000, time 451010.4, loss 0.04765026, epochs 47538, reward/epoch 9.03846, cum reward/epoch 0.10505\n",
      "step 18000000, time 451268.2, loss 0.04625311, epochs 47563, reward/epoch 8.64000, cum reward/epoch 0.10954\n",
      "step 18010000, time 451526.3, loss 0.04700015, epochs 47587, reward/epoch 7.16667, cum reward/epoch 0.11310\n",
      "step 18020000, time 451783.7, loss 0.04686351, epochs 47611, reward/epoch 10.50000, cum reward/epoch 0.11833\n",
      "step 18030000, time 452042.7, loss 0.04723600, epochs 47638, reward/epoch 8.96296, cum reward/epoch 0.12335\n",
      "step 18040000, time 452299.9, loss 0.04659051, epochs 47661, reward/epoch 10.04348, cum reward/epoch 0.12813\n",
      "step 18050000, time 452558.2, loss 0.04806888, epochs 47688, reward/epoch 7.40741, cum reward/epoch 0.13226\n",
      "step 18060000, time 452816.5, loss 0.04777592, epochs 47712, reward/epoch 6.50000, cum reward/epoch 0.13546\n",
      "step 18070000, time 453075.1, loss 0.04711626, epochs 47741, reward/epoch 9.79310, cum reward/epoch 0.14133\n",
      "step 18080000, time 453333.5, loss 0.04683157, epochs 47765, reward/epoch 9.25000, cum reward/epoch 0.14590\n",
      "step 18090000, time 453592.0, loss 0.04665659, epochs 47786, reward/epoch 10.33333, cum reward/epoch 0.15038\n",
      "step 18100000, time 453850.4, loss 0.04619533, epochs 47810, reward/epoch 7.91667, cum reward/epoch 0.15428\n",
      "step 18110000, time 454109.4, loss 0.04650685, epochs 47837, reward/epoch 8.51852, cum reward/epoch 0.15900\n",
      "step 18120000, time 454368.1, loss 0.04636053, epochs 47863, reward/epoch 8.11539, cum reward/epoch 0.16332\n",
      "step 18130000, time 454626.3, loss 0.04657543, epochs 47887, reward/epoch 11.12500, cum reward/epoch 0.16881\n",
      "step 18140000, time 454884.9, loss 0.04713794, epochs 47914, reward/epoch 7.81482, cum reward/epoch 0.17312\n",
      "step 18150000, time 455143.6, loss 0.04712665, epochs 47936, reward/epoch 8.72727, cum reward/epoch 0.17705\n",
      "step 18160000, time 455402.6, loss 0.04609980, epochs 47962, reward/epoch 9.61539, cum reward/epoch 0.18217\n",
      "step 18170000, time 455661.5, loss 0.04669996, epochs 47992, reward/epoch 7.56667, cum reward/epoch 0.18678\n",
      "step 18180000, time 455919.9, loss 0.04786979, epochs 48015, reward/epoch 11.34783, cum reward/epoch 0.19213\n",
      "step 18190000, time 456178.4, loss 0.04632936, epochs 48041, reward/epoch 9.19231, cum reward/epoch 0.19700\n",
      "step 18200000, time 456436.2, loss 0.04620675, epochs 48065, reward/epoch 10.00000, cum reward/epoch 0.20189\n",
      "step 18210000, time 456694.6, loss 0.04624526, epochs 48091, reward/epoch 7.84615, cum reward/epoch 0.20603\n",
      "step 18220000, time 456953.1, loss 0.04794224, epochs 48116, reward/epoch 9.84000, cum reward/epoch 0.21103\n",
      "step 18230000, time 457211.4, loss 0.04650179, epochs 48141, reward/epoch 9.56000, cum reward/epoch 0.21589\n",
      "step 18240000, time 457469.9, loss 0.04670957, epochs 48167, reward/epoch 8.61539, cum reward/epoch 0.22042\n",
      "step 18250000, time 457728.8, loss 0.04779505, epochs 48189, reward/epoch 7.36364, cum reward/epoch 0.22368\n",
      "step 18260000, time 457987.2, loss 0.04685042, epochs 48214, reward/epoch 9.04000, cum reward/epoch 0.22825\n",
      "step 18270000, time 458245.3, loss 0.04657311, epochs 48241, reward/epoch 9.51852, cum reward/epoch 0.23345\n",
      "step 18280000, time 458504.0, loss 0.04697013, epochs 48267, reward/epoch 11.34615, cum reward/epoch 0.23944\n",
      "step 18290000, time 458763.8, loss 0.04638183, epochs 48295, reward/epoch 9.28571, cum reward/epoch 0.24468\n",
      "step 18300000, time 459022.7, loss 0.04755241, epochs 48317, reward/epoch 10.00000, cum reward/epoch 0.24913\n",
      "step 18310000, time 459282.3, loss 0.04619794, epochs 48341, reward/epoch 7.83333, cum reward/epoch 0.25289\n",
      "step 18320000, time 459540.9, loss 0.04629714, epochs 48370, reward/epoch 8.13793, cum reward/epoch 0.25762\n",
      "step 18330000, time 459800.5, loss 0.04692450, epochs 48391, reward/epoch 7.61905, cum reward/epoch 0.26081\n",
      "step 18340000, time 460058.8, loss 0.04697746, epochs 48415, reward/epoch 8.87500, cum reward/epoch 0.26508\n",
      "step 18350000, time 460316.8, loss 0.04615883, epochs 48437, reward/epoch 8.63636, cum reward/epoch 0.26889\n",
      "step 18360000, time 460575.4, loss 0.04691538, epochs 48465, reward/epoch 9.00000, cum reward/epoch 0.27393\n",
      "step 18370000, time 460834.9, loss 0.04588613, epochs 48493, reward/epoch 9.32143, cum reward/epoch 0.27915\n",
      "step 18380000, time 461093.3, loss 0.04626301, epochs 48517, reward/epoch 9.66667, cum reward/epoch 0.28380\n",
      "step 18390000, time 461352.3, loss 0.04633194, epochs 48543, reward/epoch 7.88462, cum reward/epoch 0.28787\n",
      "step 18400000, time 461611.3, loss 0.04724995, epochs 48568, reward/epoch 8.64000, cum reward/epoch 0.29217\n",
      "step 18410000, time 461870.3, loss 0.04801314, epochs 48591, reward/epoch 7.30435, cum reward/epoch 0.29549\n",
      "step 18420000, time 462128.9, loss 0.04678564, epochs 48618, reward/epoch 7.96296, cum reward/epoch 0.29974\n",
      "step 18430000, time 462387.7, loss 0.04749577, epochs 48643, reward/epoch 10.60000, cum reward/epoch 0.30504\n",
      "step 18440000, time 462646.2, loss 0.04636937, epochs 48672, reward/epoch 7.68966, cum reward/epoch 0.30944\n",
      "step 18450000, time 462904.9, loss 0.04603415, epochs 48695, reward/epoch 11.08696, cum reward/epoch 0.31453\n",
      "step 18460000, time 463163.0, loss 0.04729512, epochs 48722, reward/epoch 8.37037, cum reward/epoch 0.31899\n",
      "step 18470000, time 463421.4, loss 0.04771581, epochs 48747, reward/epoch 10.60000, cum reward/epoch 0.32427\n",
      "step 18480000, time 463679.5, loss 0.04627452, epochs 48774, reward/epoch 10.14815, cum reward/epoch 0.32970\n",
      "step 18490000, time 463938.0, loss 0.04645288, epochs 48800, reward/epoch 7.30769, cum reward/epoch 0.33342\n",
      "step 18500000, time 464196.4, loss 0.04741035, epochs 48821, reward/epoch 8.14286, cum reward/epoch 0.33678\n",
      "step 18510000, time 464455.1, loss 0.04639541, epochs 48844, reward/epoch 9.91304, cum reward/epoch 0.34129\n",
      "step 18520000, time 464714.0, loss 0.04639841, epochs 48872, reward/epoch 8.03571, cum reward/epoch 0.34570\n",
      "step 18530000, time 464973.0, loss 0.04678327, epochs 48894, reward/epoch 9.81818, cum reward/epoch 0.34996\n",
      "step 18540000, time 465231.9, loss 0.04696452, epochs 48921, reward/epoch 7.22222, cum reward/epoch 0.35375\n",
      "step 18550000, time 465491.9, loss 0.04733348, epochs 48942, reward/epoch 5.61905, cum reward/epoch 0.35601\n",
      "step 18560000, time 465751.4, loss 0.04658812, epochs 48969, reward/epoch 7.55556, cum reward/epoch 0.35998\n",
      "step 18570000, time 466011.3, loss 0.04691355, epochs 48997, reward/epoch 6.10714, cum reward/epoch 0.36327\n",
      "step 18580000, time 466270.0, loss 0.04690652, epochs 49017, reward/epoch 8.60000, cum reward/epoch 0.36663\n",
      "step 18590000, time 466529.0, loss 0.04689055, epochs 49045, reward/epoch 8.67857, cum reward/epoch 0.37137\n",
      "step 18600000, time 466788.0, loss 0.04695628, epochs 49065, reward/epoch 7.10000, cum reward/epoch 0.37412\n",
      "step 18610000, time 467047.4, loss 0.04691850, epochs 49090, reward/epoch 6.96000, cum reward/epoch 0.37747\n",
      "step 18620000, time 467341.1, loss 0.04671641, epochs 49114, reward/epoch 8.37500, cum reward/epoch 0.38138\n",
      "step 18630000, time 467647.7, loss 0.04722635, epochs 49139, reward/epoch 8.24000, cum reward/epoch 0.38538\n",
      "step 18640000, time 467905.3, loss 0.04639575, epochs 49163, reward/epoch 8.58333, cum reward/epoch 0.38938\n",
      "step 18650000, time 468163.0, loss 0.04642522, epochs 49186, reward/epoch 6.73913, cum reward/epoch 0.39235\n",
      "step 18660000, time 468420.7, loss 0.04641825, epochs 49215, reward/epoch 7.41379, cum reward/epoch 0.39648\n",
      "step 18670000, time 468678.4, loss 0.04624637, epochs 49236, reward/epoch 11.23810, cum reward/epoch 0.40111\n",
      "step 18680000, time 468936.1, loss 0.04661832, epochs 49262, reward/epoch 5.96154, cum reward/epoch 0.40404\n",
      "step 18690000, time 469194.2, loss 0.04684209, epochs 49284, reward/epoch 7.86364, cum reward/epoch 0.40737\n",
      "step 18700000, time 469452.7, loss 0.04626991, epochs 49309, reward/epoch 7.24000, cum reward/epoch 0.41084\n",
      "step 18710000, time 469711.4, loss 0.04620531, epochs 49333, reward/epoch 7.33333, cum reward/epoch 0.41421\n",
      "step 18720000, time 469970.1, loss 0.04657815, epochs 49355, reward/epoch 7.72727, cum reward/epoch 0.41747\n",
      "step 18730000, time 470228.7, loss 0.04662903, epochs 49383, reward/epoch 8.82143, cum reward/epoch 0.42223\n",
      "step 18740000, time 470487.6, loss 0.04661648, epochs 49408, reward/epoch 10.88000, cum reward/epoch 0.42752\n",
      "step 18750000, time 470745.7, loss 0.04668783, epochs 49430, reward/epoch 5.45455, cum reward/epoch 0.42976\n",
      "step 18760000, time 471004.0, loss 0.04616930, epochs 49457, reward/epoch 9.18519, cum reward/epoch 0.43454\n",
      "step 18770000, time 471261.5, loss 0.04805313, epochs 49481, reward/epoch 6.83333, cum reward/epoch 0.43764\n",
      "step 18780000, time 471519.0, loss 0.04684466, epochs 49503, reward/epoch 9.86364, cum reward/epoch 0.44183\n",
      "step 18790000, time 471776.9, loss 0.04624039, epochs 49532, reward/epoch 8.68966, cum reward/epoch 0.44666\n",
      "step 18800000, time 472034.3, loss 0.04576493, epochs 49556, reward/epoch 8.75000, cum reward/epoch 0.45068\n",
      "step 18810000, time 472291.5, loss 0.04616796, epochs 49582, reward/epoch 7.23077, cum reward/epoch 0.45424\n",
      "step 18820000, time 472549.4, loss 0.04702461, epochs 49605, reward/epoch 9.34783, cum reward/epoch 0.45836\n",
      "step 18830000, time 472807.8, loss 0.04603091, epochs 49633, reward/epoch 9.89286, cum reward/epoch 0.46368\n",
      "step 18840000, time 473066.0, loss 0.04678879, epochs 49656, reward/epoch 6.47826, cum reward/epoch 0.46647\n",
      "step 18850000, time 473322.9, loss 0.04629094, epochs 49680, reward/epoch 7.54167, cum reward/epoch 0.46989\n",
      "step 18860000, time 473580.3, loss 0.04611640, epochs 49707, reward/epoch 9.14815, cum reward/epoch 0.47460\n",
      "step 18870000, time 473838.2, loss 0.04721304, epochs 49728, reward/epoch 8.14286, cum reward/epoch 0.47784\n",
      "step 18880000, time 474096.3, loss 0.04701914, epochs 49755, reward/epoch 7.85185, cum reward/epoch 0.48184\n",
      "step 18890000, time 474354.4, loss 0.04712984, epochs 49779, reward/epoch 6.00000, cum reward/epoch 0.48450\n",
      "step 18900000, time 474611.8, loss 0.04638306, epochs 49801, reward/epoch 9.18182, cum reward/epoch 0.48834\n",
      "step 18910000, time 474870.0, loss 0.04686758, epochs 49830, reward/epoch 8.03448, cum reward/epoch 0.49274\n",
      "step 18920000, time 475127.4, loss 0.04702562, epochs 49854, reward/epoch 10.54167, cum reward/epoch 0.49757\n",
      "step 18930000, time 475384.7, loss 0.04710762, epochs 49881, reward/epoch 8.92593, cum reward/epoch 0.50214\n",
      "step 18940000, time 475642.4, loss 0.04648640, epochs 49904, reward/epoch 7.78261, cum reward/epoch 0.50549\n",
      "step 18950000, time 475900.3, loss 0.04703365, epochs 49930, reward/epoch 7.46154, cum reward/epoch 0.50911\n",
      "step 18960000, time 476157.9, loss 0.04710488, epochs 49955, reward/epoch 7.84000, cum reward/epoch 0.51278\n",
      "step 18970000, time 476415.9, loss 0.04704833, epochs 49977, reward/epoch 8.68182, cum reward/epoch 0.51638\n",
      "step 18980000, time 476673.2, loss 0.04699945, epochs 50003, reward/epoch 8.57692, cum reward/epoch 0.52057\n",
      "step 18990000, time 476930.7, loss 0.04752624, epochs 50027, reward/epoch 7.25000, cum reward/epoch 0.52380\n",
      "step 19000000, time 477188.5, loss 0.04682736, epochs 50051, reward/epoch 7.12500, cum reward/epoch 0.52696\n",
      "step 19010000, time 477446.3, loss 0.04737361, epochs 50075, reward/epoch 9.79167, cum reward/epoch 0.53140\n",
      "step 19020000, time 477704.3, loss 0.04635312, epochs 50099, reward/epoch 6.83333, cum reward/epoch 0.53442\n",
      "step 19030000, time 477962.0, loss 0.04611613, epochs 50120, reward/epoch 7.90476, cum reward/epoch 0.53751\n",
      "step 19040000, time 478219.9, loss 0.04683089, epochs 50144, reward/epoch 6.41667, cum reward/epoch 0.54032\n",
      "step 19050000, time 478477.6, loss 0.04736171, epochs 50167, reward/epoch 6.78261, cum reward/epoch 0.54319\n",
      "step 19060000, time 478735.4, loss 0.04690963, epochs 50195, reward/epoch 6.92857, cum reward/epoch 0.54675\n",
      "step 19070000, time 478993.0, loss 0.04575311, epochs 50216, reward/epoch 9.85714, cum reward/epoch 0.55064\n",
      "step 19080000, time 479251.0, loss 0.04800389, epochs 50243, reward/epoch 8.29630, cum reward/epoch 0.55480\n",
      "step 19090000, time 479508.9, loss 0.04683999, epochs 50270, reward/epoch 8.81481, cum reward/epoch 0.55924\n",
      "step 19100000, time 479766.9, loss 0.04665543, epochs 50293, reward/epoch 8.47826, cum reward/epoch 0.56286\n",
      "step 19110000, time 480024.5, loss 0.04683671, epochs 50318, reward/epoch 8.80000, cum reward/epoch 0.56695\n",
      "step 19120000, time 480282.1, loss 0.04632084, epochs 50342, reward/epoch 8.83333, cum reward/epoch 0.57090\n",
      "step 19130000, time 480540.8, loss 0.04705595, epochs 50366, reward/epoch 6.50000, cum reward/epoch 0.57372\n",
      "step 19140000, time 480799.0, loss 0.04717635, epochs 50390, reward/epoch 8.41667, cum reward/epoch 0.57746\n",
      "step 19150000, time 481056.7, loss 0.04822599, epochs 50412, reward/epoch 3.04545, cum reward/epoch 0.57853\n",
      "step 19160000, time 481314.4, loss 0.04702868, epochs 50439, reward/epoch 6.55556, cum reward/epoch 0.58173\n",
      "step 19170000, time 481571.8, loss 0.04768506, epochs 50459, reward/epoch 4.60000, cum reward/epoch 0.58333\n",
      "step 19180000, time 481829.1, loss 0.04782307, epochs 50480, reward/epoch 7.28571, cum reward/epoch 0.58611\n",
      "step 19190000, time 482086.4, loss 0.04622163, epochs 50507, reward/epoch 8.07407, cum reward/epoch 0.59012\n",
      "step 19200000, time 482344.4, loss 0.04624237, epochs 50530, reward/epoch 8.04348, cum reward/epoch 0.59351\n",
      "step 19210000, time 482602.4, loss 0.04703801, epochs 50552, reward/epoch 7.13636, cum reward/epoch 0.59636\n",
      "step 19220000, time 482860.3, loss 0.04589681, epochs 50579, reward/epoch 9.51852, cum reward/epoch 0.60112\n",
      "step 19230000, time 483118.6, loss 0.04647009, epochs 50600, reward/epoch 5.47619, cum reward/epoch 0.60314\n",
      "step 19240000, time 483376.3, loss 0.04683522, epochs 50628, reward/epoch 7.64286, cum reward/epoch 0.60704\n",
      "step 19250000, time 483634.0, loss 0.04634696, epochs 50652, reward/epoch 6.79167, cum reward/epoch 0.60997\n",
      "step 19260000, time 483891.9, loss 0.04619693, epochs 50674, reward/epoch 6.54545, cum reward/epoch 0.61254\n",
      "step 19270000, time 484149.9, loss 0.04658187, epochs 50698, reward/epoch 8.12500, cum reward/epoch 0.61610\n",
      "step 19280000, time 484407.6, loss 0.04778048, epochs 50720, reward/epoch 7.50000, cum reward/epoch 0.61909\n",
      "step 19290000, time 484665.4, loss 0.04641235, epochs 50743, reward/epoch 7.86957, cum reward/epoch 0.62237\n",
      "step 19300000, time 484923.1, loss 0.04652012, epochs 50769, reward/epoch 7.80769, cum reward/epoch 0.62605\n",
      "step 19310000, time 485180.5, loss 0.04740891, epochs 50791, reward/epoch 7.00000, cum reward/epoch 0.62881\n",
      "step 19320000, time 485438.3, loss 0.04706229, epochs 50815, reward/epoch 9.66667, cum reward/epoch 0.63308\n",
      "step 19330000, time 485695.8, loss 0.04639513, epochs 50835, reward/epoch 7.50000, cum reward/epoch 0.63578\n",
      "step 19340000, time 485953.6, loss 0.04888524, epochs 50860, reward/epoch -1.52000, cum reward/epoch 0.63472\n",
      "step 19350000, time 486211.3, loss 0.04770222, epochs 50886, reward/epoch 5.00000, cum reward/epoch 0.63695\n",
      "step 19360000, time 486468.7, loss 0.04760392, epochs 50907, reward/epoch 6.47619, cum reward/epoch 0.63936\n",
      "step 19370000, time 486726.1, loss 0.04804410, epochs 50934, reward/epoch 4.40741, cum reward/epoch 0.64136\n",
      "step 19380000, time 486984.1, loss 0.04814108, epochs 50957, reward/epoch 7.34783, cum reward/epoch 0.64439\n",
      "step 19390000, time 487241.2, loss 0.04803215, epochs 50981, reward/epoch 8.66667, cum reward/epoch 0.64816\n",
      "step 19400000, time 487499.5, loss 0.04670229, epochs 51008, reward/epoch 8.92593, cum reward/epoch 0.65254\n",
      "step 19410000, time 487757.5, loss 0.04626490, epochs 51032, reward/epoch 7.91667, cum reward/epoch 0.65596\n",
      "step 19420000, time 488014.3, loss 0.04741420, epochs 51058, reward/epoch 8.03846, cum reward/epoch 0.65972\n",
      "step 19430000, time 488271.8, loss 0.04730168, epochs 51080, reward/epoch 9.90909, cum reward/epoch 0.66370\n",
      "step 19440000, time 488529.3, loss 0.04710074, epochs 51104, reward/epoch 5.33333, cum reward/epoch 0.66590\n",
      "step 19450000, time 488786.5, loss 0.04731689, epochs 51130, reward/epoch 9.69231, cum reward/epoch 0.67049\n",
      "step 19460000, time 489044.6, loss 0.04602203, epochs 51154, reward/epoch 8.00000, cum reward/epoch 0.67393\n",
      "step 19470000, time 489302.4, loss 0.04914837, epochs 51178, reward/epoch 2.25000, cum reward/epoch 0.67466\n",
      "step 19480000, time 489559.8, loss 0.04845563, epochs 51201, reward/epoch 4.34783, cum reward/epoch 0.67631\n",
      "step 19490000, time 489817.8, loss 0.04785007, epochs 51229, reward/epoch 4.50000, cum reward/epoch 0.67840\n",
      "step 19500000, time 490075.2, loss 0.04713095, epochs 51251, reward/epoch 8.54545, cum reward/epoch 0.68178\n",
      "step 19510000, time 490332.2, loss 0.04708003, epochs 51273, reward/epoch 3.77273, cum reward/epoch 0.68311\n",
      "step 19520000, time 490589.9, loss 0.04678864, epochs 51298, reward/epoch 7.88000, cum reward/epoch 0.68662\n",
      "step 19530000, time 490847.3, loss 0.04755287, epochs 51320, reward/epoch 8.22727, cum reward/epoch 0.68985\n",
      "step 19540000, time 491104.2, loss 0.04762738, epochs 51347, reward/epoch 7.85185, cum reward/epoch 0.69361\n",
      "step 19550000, time 491361.0, loss 0.04797627, epochs 51371, reward/epoch 7.25000, cum reward/epoch 0.69668\n",
      "step 19560000, time 491618.1, loss 0.04727045, epochs 51398, reward/epoch 10.29630, cum reward/epoch 0.70172\n",
      "step 19570000, time 491875.4, loss 0.04743060, epochs 51422, reward/epoch 4.79167, cum reward/epoch 0.70363\n",
      "step 19580000, time 492131.9, loss 0.04715048, epochs 51445, reward/epoch 7.26087, cum reward/epoch 0.70656\n",
      "step 19590000, time 492389.0, loss 0.04661129, epochs 51467, reward/epoch 5.86364, cum reward/epoch 0.70876\n",
      "step 19600000, time 492646.0, loss 0.04783017, epochs 51492, reward/epoch 7.16000, cum reward/epoch 0.71190\n",
      "step 19610000, time 492903.8, loss 0.04677441, epochs 51515, reward/epoch 7.13043, cum reward/epoch 0.71476\n",
      "step 19620000, time 493161.0, loss 0.04710092, epochs 51539, reward/epoch 6.91667, cum reward/epoch 0.71765\n",
      "step 19630000, time 493418.1, loss 0.04607854, epochs 51567, reward/epoch 8.82143, cum reward/epoch 0.72205\n",
      "step 19640000, time 493675.5, loss 0.04689920, epochs 51590, reward/epoch 9.17391, cum reward/epoch 0.72582\n",
      "step 19650000, time 493933.3, loss 0.04737429, epochs 51616, reward/epoch 7.19231, cum reward/epoch 0.72908\n",
      "step 19660000, time 494190.2, loss 0.04682710, epochs 51637, reward/epoch 7.90476, cum reward/epoch 0.73199\n",
      "step 19670000, time 494447.8, loss 0.04827096, epochs 51661, reward/epoch 7.87500, cum reward/epoch 0.73531\n",
      "step 19680000, time 494705.1, loss 0.04624598, epochs 51687, reward/epoch 8.19231, cum reward/epoch 0.73906\n",
      "step 19690000, time 494963.4, loss 0.04617647, epochs 51710, reward/epoch 10.21739, cum reward/epoch 0.74328\n",
      "step 19700000, time 495221.1, loss 0.04615303, epochs 51731, reward/epoch 7.80952, cum reward/epoch 0.74615\n",
      "step 19710000, time 495479.0, loss 0.04595567, epochs 51758, reward/epoch 9.48148, cum reward/epoch 0.75071\n",
      "step 19720000, time 495736.8, loss 0.04618573, epochs 51782, reward/epoch 7.83333, cum reward/epoch 0.75399\n",
      "step 19730000, time 495994.4, loss 0.04715536, epochs 51808, reward/epoch 7.03846, cum reward/epoch 0.75714\n",
      "step 19740000, time 496252.5, loss 0.04642387, epochs 51830, reward/epoch 8.31818, cum reward/epoch 0.76035\n",
      "step 19750000, time 496510.0, loss 0.04676338, epochs 51854, reward/epoch 6.58333, cum reward/epoch 0.76305\n",
      "step 19760000, time 496767.9, loss 0.04672442, epochs 51876, reward/epoch 8.45455, cum reward/epoch 0.76631\n",
      "step 19770000, time 497025.1, loss 0.04590560, epochs 51899, reward/epoch 7.69565, cum reward/epoch 0.76938\n",
      "step 19780000, time 497282.8, loss 0.04591965, epochs 51925, reward/epoch 7.03846, cum reward/epoch 0.77252\n",
      "step 19790000, time 497541.0, loss 0.04636674, epochs 51945, reward/epoch 9.70000, cum reward/epoch 0.77596\n",
      "step 19800000, time 497798.8, loss 0.04676122, epochs 51972, reward/epoch 6.07407, cum reward/epoch 0.77871\n",
      "step 19810000, time 498056.7, loss 0.04616362, epochs 51994, reward/epoch 9.04545, cum reward/epoch 0.78221\n",
      "step 19820000, time 498314.0, loss 0.04662041, epochs 52018, reward/epoch 8.12500, cum reward/epoch 0.78559\n",
      "step 19830000, time 498572.0, loss 0.04641635, epochs 52043, reward/epoch 6.56000, cum reward/epoch 0.78837\n",
      "step 19840000, time 498829.8, loss 0.04704555, epochs 52066, reward/epoch 8.21739, cum reward/epoch 0.79165\n",
      "step 19850000, time 499098.4, loss 0.04738712, epochs 52090, reward/epoch 7.20833, cum reward/epoch 0.79461\n",
      "step 19860000, time 499355.9, loss 0.04645836, epochs 52114, reward/epoch 6.91667, cum reward/epoch 0.79742\n",
      "step 19870000, time 499613.7, loss 0.04632095, epochs 52138, reward/epoch 6.66667, cum reward/epoch 0.80013\n",
      "step 19880000, time 499871.3, loss 0.04646105, epochs 52164, reward/epoch 6.53846, cum reward/epoch 0.80299\n",
      "step 19890000, time 500131.3, loss 0.04684817, epochs 52185, reward/epoch 9.47619, cum reward/epoch 0.80648\n",
      "step 19900000, time 500389.4, loss 0.04624173, epochs 52216, reward/epoch 9.25806, cum reward/epoch 0.81149\n",
      "step 19910000, time 500646.1, loss 0.04666853, epochs 52239, reward/epoch 7.17391, cum reward/epoch 0.81430\n",
      "step 19920000, time 500902.7, loss 0.04649135, epochs 52261, reward/epoch 10.04545, cum reward/epoch 0.81818\n",
      "step 19930000, time 501159.9, loss 0.04745717, epochs 52286, reward/epoch 7.12000, cum reward/epoch 0.82119\n",
      "step 19940000, time 501416.8, loss 0.04604652, epochs 52308, reward/epoch 9.45455, cum reward/epoch 0.82483\n",
      "step 19950000, time 501674.4, loss 0.04571429, epochs 52334, reward/epoch 7.00000, cum reward/epoch 0.82789\n",
      "step 19960000, time 501931.8, loss 0.04627965, epochs 52358, reward/epoch 8.25000, cum reward/epoch 0.83130\n",
      "step 19970000, time 502189.1, loss 0.04752542, epochs 52379, reward/epoch 10.04762, cum reward/epoch 0.83499\n",
      "step 19980000, time 502446.8, loss 0.04716315, epochs 52406, reward/epoch 6.59259, cum reward/epoch 0.83796\n",
      "step 19990000, time 502704.3, loss 0.04649823, epochs 52429, reward/epoch 9.17391, cum reward/epoch 0.84161\n",
      "step 20000000, time 502960.8, loss 0.04662126, epochs 52454, reward/epoch 7.56000, cum reward/epoch 0.84482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "430.87,33327,1.3612e+05,25878,34203,1.3485e+05,1.3425e+05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic\n",
    "var block_loss = 0f\n",
    "var block_reward = 0f\n",
    "var total_reward = 0f\n",
    "total_epochs = 0\n",
    "var last_epochs = 0\n",
    "val new_state = state.copy\n",
    "\n",
    "val times = zeros(1,8)\n",
    "val dtimes = zeros(1,7)\n",
    "for (istep <- 0 until nsteps) {\n",
    "//    if (render): envs[0].render()\n",
    "    times(0) = toc\n",
    "    val epsilon = epsilons(math.min(istep, neps-1));                                // get an epsilon for the eps-greedy policy\n",
    "    val lr = learning_rates(math.min(istep, nlr-1));                                // update the decayed learning rate\n",
    "    \n",
    "    update_estimator(target_estimator, q_estimator, target_window, istep);          // update the target estimator if needed    \n",
    "    times(1) = toc\n",
    "    \n",
    "    val action_probs = policy(q_estimator, state, epsilon);                         // get the next action probabilities from the policy\n",
    "    times(2) = toc\n",
    "                                                          \n",
    "    val actions = random_choices(action_probs);                                     // Choose actions using the policy\n",
    "    val (obs, rewards, dones) = ALE.stepAll2(envs, VALID_ACTIONS(actions))           // step through parallel envs\n",
    "    times(3) = toc\n",
    "    \n",
    "    for (i <- 0 until npar) {                                                     \n",
    "        val img = preprocess(obs(i));                                               // process the observation\n",
    "        new_state(?,i) = state(nfeats->state.nrows,i) on img;                       // add it to buffer of last nwindow imgs        \n",
    "    }    \n",
    "    total_epochs += sum(dones).v.toInt\n",
    "    block_reward += sum(rewards).v  \n",
    "    times(4) = toc\n",
    "    \n",
    "    val q_values_next = target_estimator.predict(new_state);                        // predict the Q values\n",
    "    times(5) = toc\n",
    "    \n",
    "    dones <-- (dones + (rewards != 0f) > 0f);\n",
    "    val targets = rewards+discount_factor*(1f-dones) *@ maxi(q_values_next);        // compute target values   \n",
    "    block_loss += q_estimator.gradient(state, actions, targets);                    // compute q-estimator gradient and return the loss\n",
    "    times(6) = toc\n",
    "    \n",
    "    if (istep % rmsevery == 0) {\n",
    "        q_estimator.rmsprop(lr, gsq_decay);                       // apply the gradient update\n",
    "//        print(\"ds1=%f, ss1=%f, ds2=%f, ss2=%f\\n\" format(res(0,0), res(1,0), res(0,1), res(1,1)));\n",
    "    }\n",
    "    times(7) = toc\n",
    "    \n",
    "    dtimes ~ dtimes + (times(0,1->8) - times(0,0->7))\n",
    "    val t = toc;\n",
    "    if (istep % printsteps == 0) {\n",
    "        total_reward += block_reward;\n",
    "        println(\"step %d, time %2.1f, loss %9.8f, epochs %d, reward/epoch %6.5f, cum reward/epoch %6.5f\" format(\n",
    "                istep, t, block_loss/printsteps, total_epochs, block_reward/math.max(1,total_epochs-last_epochs), total_reward/math.max(1,total_epochs)))\n",
    "        last_epochs = total_epochs;\n",
    "        block_reward = 0f;\n",
    "        block_loss = 0f;\n",
    "    }\n",
    "    state <-- new_state;\n",
    "}\n",
    "dtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And animate the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAGQCAYAAABYs5LGAAAUzElEQVR42u3df4ibdx3A8YGI+If4n/iXiCDiHyIiiH+IhJIjoUdxVFqucLphsZSVxJSuWPwxR+uOjVY6lI1JjDA6JCiFjRHZUNywTKgtS0onMkaLxaMMVxpS6ORozVc+D1zo3SW5dNdektvrBV988s2TuxqUd5/n+T5PH0gAwNR7wFcAAIIOAAg6ACDoAICgwwf6P80DD4w01vvch9nbb7+djh49mr785S/7XkDQQdC34ncICDqMJUb3+3NbURyZ//znP8+O1H0vIOgwVUHH9wmCDh+CI/SFhYX02c9+Nn30ox9Nn//859Px48fX/dy9eu+///1v+sEPfpA++clPpo997GMr9n3nnXey9774xS+mj3/849mf79Of/nSan59Pf//73wUdBB0EfdmuXbv6Xk8+cODApgR9bm6ut/2Rj3ykt1+9Xs8CP+yadyxuE3QQdJj6oG90Udzp06dXzH/1q19N//nPf7Lxta99bVOC/oUvfCH94x//WLFPs9lcsU8+n0/vvvtuunXrVtq3b9+K91566SVBB0GHD3fQZ2dnV8z/6U9/6r0X26OGefWp8rsJ+quvvrrmz3vnUXuMS5cu9d5bWlpa8V4ulxN0EHSY7qBv9HOf+MQnVsz/73//GxjO+xX0O3/nsriePupfXuLauqCDoMOHOuixyOyD3r9+r4Lez+o/192ekRB0EHRwhP4BjtDvXMwWP2OjQV/954o/yyR9n4Cgw0QF/Vvf+taK+b/85S+999a7hr76KHo5unE72UaDvnrl/QsvvCDoIOgg6IM+9/LLL6+Y/8Y3vtFb5f71r3996O/7yle+suK93/zmN9k95YVCYcNBX/2Xgrj3/PXXX++dAbh48WJ65plnsj+joIOgw4c+6OG73/3uB7oP/be//W3fz8WDYDYa9OWfH6fy7/X18/t9XR4EHRhL0EM8Ge5zn/tcdho9/vMXv/hFds/3eqvJf/WrX/U+95nPfCb73Hq/727+O8T96XHfedyrHr8jAh/X1+MswOOPP54uXLgg6CDowDC///3vVwQuIgog6DChvvnNb6bf/e536dq1a9nrWNwWrz/1qU+t+wAYAEGHSfk/4jqnnuMe81//+te+KEDQYZKdP38+W8j2pS99KbtOHgGP69Tbtm1LP/nJT9K//vUvXxIg6AAg6ACAoAMAgg4ACDoACDoAIOgAgKADAIIOAIIOAAj6pGo2myteP/roo+lnP/uZYRiGYUzcqFQqgj7I66+/vuJ1fGEAMInutlGCDgCCLugAIOiCDgCCLugACLqgCzoAgi7oACDogg4Agi7oAAj6RAY9l8v1xqhqtVoqFovZqFargg6AoE9S2EfRaDRSuVxOnU4nG/GIvJgTdAAEfYqCHjFvtVq917FdKpUEHQBBn6agFwqF1O12e69jO+YEHQBBn6Kg99svn88LOgCCvlWP0OOfTY2Y1+t1QQdA0Ccp6P2uocecI3QABH2Cg756fnmVe7vdtsodAEGfpJCvHuuFPu49dx86AILuSXH+FwOAoAs6AAi6oAOAoAs6AIIu6IIOgKALOgAIuqADgKALOgCCLuiCDoCgCzoACLqgA4CgCzoAgi7ogg6AoAs6AAi6oAOAoAs6AIIu6IIOgKALOgAIuqADgKALOgCCLuiCDoCgb65arZaKxWI2qtXq0H1v3LiRjh07lmZmZtKOHTvS888/L+gACPq4NRqNVC6XU6fTyUalUsnmBllYWEjHjx9Pt27dSktLS+nEiRPpj3/8o6ADIOjjFDFvtVq917FdKpUG7h9H5hHyZbF98OBBQQdA0MepUCikbrfbex3bMTdq0ONIfdj+gg6AoG+CXC63Zi6fzw/c/4knnshOs0fUl0+5D9tf0AEQ9Ak8Qo9FcUePHs2O1Hfu3JlefPHFNDs723ffZrOZxbxerws6AIJ+P/W7hh5zo3rllVeyhXKO0AEQ9DFaXuXebrf7rnJffUr+6aefzvaNI/mzZ8+m+fn5tLi4KOgACPq4xb3ng+5DXx30OCKPU+1xyv3QoUPp8uXL6/58QQdA0LcAQQdA0AUdAARd0AFA0AUdAEEXdEEHQNAFHQAEXdABQNAFHQBBF3RBB0DQBR0ABF3QAUDQBR0AQRd0QQdA0AUdAARd0AFA0AUdAEEXdEEHQNAFHQAEXdABQNAFHQAEXdABEHRBBwBB37harZaKxWI2qtXq0H3ffffddOTIkVQoFLIR21evXhV0AAR9nBqNRiqXy6nT6WSjUqlkc4Ps3bs3vfDCC+n27dvZOHXqVPr+978v6AAI+jhFzFutVu91bJdKpYH7b9u2bc3czMyMoAMg6OMUp8273W7vdWzH3CCPPfZYdlQe+8V4/vnnszlBB0DQxyiXy62Zy+fzA/d/77330tzcXPa5GLF9/fr1vvs2m80s5vV6XdABEPRJOkI/dOhQdoR+5zX0gwcPOkIHQNDHqd819JgbpN/R+7AjekEHQNA3wfIq93a73XeV++pT8rGiPa6b33kN3Sp3AAR9AsS954PuQ18d9MXFxewUe6xsjxHbMSfoAAj6FifoAAi6oAOAoAs6AAi6oAMg6IIu6AAIuqADgKALOgAIuqADIOiCLugACLqgA4CgCzoACLqgAyDogi7oAAi6oAOAoAs6AAi6oAMg6IIu6AAIuqADgKALOgAIuqADgKALOgCCPna1Wi0Vi8VsVKvVofvmcrk1Y3Z2VtABEPRxajQaqVwup06nk41KpZLNjeqNN95Y9y8Bgg6AoN9nEfNWq9V7HdulUmnkz+/bty9dv35d0AEQ9HEqFAqp2+32Xsd2zI3i7Nmz6eTJk+vuJ+gACPp9FtfAV8vn8yN99pFHHklXrlwZ+H6z2cxiXq/XBR0AQZ/EI/Q4Nf/YY4+N9DscoQMg6PdZv2voMbeeuM7+z3/+U9ABEPRJsLzKvd1u913l3u+U/MWLF+9q4ZygAyDomyBuOxt0H3q/oEf0z507J+gACPqH6csRdAAEXdABQNAFHQAEXdABEHRBF3QABF3QAUDQBR0ABF3QARB0QRd0AARd0AFA0AUdAARd0AEQdEEXdAAEXdABQNAFHQAEXdABEHRBF3QABF3QAUDQBR0ABF3QAUDQBR0AQR+7Wq2WisViNqrV6rr7X758OR06dCgVCoW0a9eu9Morrwg6AII+To1GI5XL5dTpdLJRqVSyuUGuXLmS9uzZk86ePZu63W5qt9vpl7/8paADIOjjFDFvtVq917FdKpUG7v/kk0+ue0Qu6AAI+iaL0+ZxpL0stmNukNnZ2fTSSy+lnTt3ppmZmfT444+nGzduCDoAgj5OuVxuzVw+nx+6//Hjx9OtW7fS0tJSOnHiRDp27FjffZvNZhbzer0u6AAI+iDbtm37QO9t5Ag93ouQL4uwx5G6I3QABP0eBz1OgY8a9H7X0GNukFg0tzrow/4CIOgACPoAcdp7vbFeZJctr3KP1er9VrmvPiUfC+LiNHtEPUacfl9YWBB0AAT9gxyZx4jYLm/fOeJ+8tOnT4/88+Le80H3ofe7xn7q1Km0Y8eO7FT70aNHLYoDQNA3YtjitUki6AAI+hYg6AAI+hCxIC3uB+93DX3URXGCDgBjDvrc3NyKgN85Jul0vKADIOhDRLhfe+21if9yBB0AQR/CojgA2AJBj3+6NO4dF3QAmOKgnzt3Lj300EPZQ2EEHQCmNOjDnhRnlTsATEnQ+z0lzip3AJiyoE8LQQdA0AUdALZ20F1DB4AtEPTV183vDLpr6AAwJUHvJ+5Lf/jhh1Or1RJ0AJjWoIebN2+m3bt3CzoATHPQg1PuADDFQb99+3Z69dVXBR0ApiXoq1e137kwbu/evYIOANMQ9EFPifv2t7+dut2uoAPANAR9Wgg6AIK+CWq1WioWi9moVqtD9+33EBtBB0DQN+jixYvZLWqxCC5GbMfcqBqNRiqXy9n96zEqlUo2NyzojtABEPR7GPTz588PfPTrqFGPmN/5EJrYLpVKgg6AoG9W0ONo/PDhw+n69eu9udg+ePBg2rVr10g/o1AorFhAF9sxNyzos7Oz2dmA73znO+nUqVOCDoCgb0RE9datW2vm4170mZmZkX5GvyPuUe9h//e//51++MMfpueee07QARD0jQR9aWlpzXxEftSg3+0R+mrxmNlYTNdPs9nMYl6v1wUdAEEfZG5uLrvefe3atSzEMWJ7//79Iz/Lvd819Ji7F0F3hA6AoI8gFr4NWhT39ttvj/Qzlle5t9vtvqvcV5+Sf/LJJ9Pi4mK2/d5776Wf/vSn6eTJk4IOgKBvRIQ7jsbjFHuM2B415svi3vNB96GvDvqZM2eyx8rGfDyRLq6f9zvtL+gACPoWI+gACLqgA8DWDHrc//3QQw8NfH/Pnj1pfn5e0AFgkoO+ffv27B7wQS5fvpw9/EXQAWCCgz7ogTLLYpHaqA+HEXQAGFPQ4988HyX6gg4AExz0uL3sxo0bA9+P9+K0vKADwAQHPRbEDXuYSzz8Je4VF3QAmOCgX7lyJXuwy49//OPsX1eLf4wlRmzHk9vivatXrwo6AExy0MOJEycGPvb16aefnqgvR9ABEPQh/va3v6157GvMTRpBB0DQtwBBB0DQBR0ABF3QAUDQBR0AQRd0QQdA0AUdAARd0AFA0AUdAEEXdEEHQNAFHQAE/W7VarXsn2SNUa1WR/5cpVLJnh0v6AAI+pg1Go1ULpdTp9PJRkQ65tbz5z//OZVKJUEHQNAnQcS81Wr1Xsd2hHqY999/P83Pz2f/RKugAyDoE6BQKKRut9t7HdsxN8yzzz6bTp8+nW0LOgCCPgH6BTmfzw/c/9KlS+nAgQNDPy/oAAj6hB+hR8wXFxdHCnqz2cxiXq/XBR0AQb+f+l1Dj7lhR/T9hiN0AAR9jJZXubfb7b6r3NeLtVPuAAj6hIh7zwfdhy7oAAj6lAT9fhN0AARd0AFA0AUdAARd0AEQdEEXdAAEXdABQNAFHQAEXdABEHRBF3QABF3QAUDQBR0ABF3QARB0QRd0AARd0AFA0AUdAARd0AEQdEEXdAAEXdABQNAFHQAEXdABQNAFHQBBF3QAEPSNq9VqqVgsZqNarQ7d980330yVSiXNzMyk7du3p4WFhXTt2jVBB0DQx6nRaKRyuZw6nU42ItYxN8jhw4fTuXPn0u3bt1O3201/+MMf0v79+wUdAEEfp4h5q9XqvY7tUql0Vz8jjtYFHQBBH6NCoZAdaS+L7ZgbRex7+vTpdOTIEUEHQNDHKZfLrZnL5/MjfS7Ggw8+mBYXF/vu02w2s5jX63VBB0DQJ/kIPWJ94MABR+gACPo49buGHnN3Y70jekEHQNDvs+VV7u12u+8q99Wn5E+ePJmuXr2abd+8eTO7zW29vwAIOgCCvgkiyoPuQ18d9DNnzqS9e/dm8zt27EhPPfVU9pcBQQdA0Lc4QQdA0AUdAARd0AFA0AUdAEEXdEEHQNAFHQAEXdABQNAFHQBBF3RBB0DQBR0ABF3QAUDQBR0AQRd0QQdA0AUdAARd0AFA0AUdAEEXdEEHQNAFHQAEXdABQNAFHQAEXdABEPSxq9VqqVgsZqNarQ7d980330wHDx5MMzMzafv27empp55K7XZb0AEQ9HFqNBqpXC6nTqeTjUqlks0NcuTIkXT+/PnU7XbT0tJSeuaZZ7LACzoAgj5GEfNWq9V7HdulUmnkz0fY8/m8oAMg6ONUKBSyKN8Z6Jgb1dmzZ9OBAwcEHQBBH6dcLrdmbr0j7mWXL19Oe/bsSZcuXer7frPZzGJer9cFHQBBn8Qj9AsXLqS5ubn01ltvrbuvI3QABP0+63cNPeaGOXPmTNq9e3d65513Rvodgg6AoN9ny6vc49azfqvcV5+Sf/HFF9OuXbvSlStXRv4dgg6AoG+CuPd80H3oq4Mer/sNQQdA0Lc4QQdA0AUdAARd0AFA0AUdAEEXdEEHQNAFHQAEXdABQNAFHQBBF3RBB0DQBR0ABF3QAUDQBR0AQRd0QQdA0AUdAARd0AFA0AUdAEEXdEEHQNAFHQAEXdABQNAFHQAEXdABEPSxq9VqqVgsZqNarQ7dN5fL9YagAyDoE6LRaKRyuZw6nU42KpVKNrceQQdA0Cco6BHzVqvVex3bpVJJ0AEQ9GkKeqFQSN1ut/c6tmNO0AEQ9CkKer8w5/P5exL0ZrOZxbxerws6AILuCB0ABH2oftfQY07QARD0KQr68ir3drvdd5X7oHALOgCCPmH3oce954PuQ18d7jvvQx/1fnRBB0DQtwBBB0DQBR0ABF3QAUDQBR0AQRd0QQdA0AUdAARd0AFA0AUdAEEXdEEHQNAFHQAEXdABQNAFHQBBF3RBB0DQBR0ABF3QAUDQBR0AQRd0QQdA0AUdAARd0AFA0AUdAARd0AEQ9LGr1WqpWCxmo1qt3vP9BR0AQb/PGo1GKpfLqdPpZKNSqWRz92p/QQdA0DdBxLnVavVex3apVLpn+ws6AIK+CQqFQup2u73XsR1z92p/QQdA0DdBLpdbM5fP5+/Z/oIOgKBP+RF6s9nMYv7yyy+vmH/00UezL8wwDMMwJm3E2rCpDHq/a+Ixd6/2B4CtbOJWubfb7b6r1lefYl9vfwAQ9DGJe8kH3Vfe75r5sP0BQNA/JJavrRuGYRjGpI07LysLOgA4QgcABB0AEHQAQNABQNABAEEHAAQdABB0ABB0AEDQAQBBBwAEHQAEHQAQdABA0AEAQQcAQQcABB0AEHQAQNABAEEHAEEHAAQdmGYLCwspl8ulI0eOrHnvRz/6UfZe7AMIOjDB3n///bR79+4s3BcuXOjNv/XWW9lcvHfz5k1fFAg6MOki5BHvffv29eb279+/JvKAoAMT7rnnnssC/tprr2Ujtp999llfDAg6ME1u376dvve976X5+fm0Z8+e9PDDD2dzgKADU+TGjRtp586d6ZFHHsnGgw8+mDqdji8GBB2YJk888UTvmvnygrhjx475YkDQgWnxxhtvZAE/fPhwby62Y+6vf/2rLwgEHZh0y6faI96XLl3qzcd2zDn1DoIOTIHlU+39Tq/HnFPvIOgAgKADgKADAIIOAAg6ACDoACDoAICgAwCCDgAIOgAIOgAw5f4PbU9HqmbPxD4AAAAASUVORK5CYII=",
      "text/plain": [
       "BufferedImage@508910d4: type = 2 DirectColorModel: rmask=ff0000 gmask=ff00 bmask=ff amask=ff000000 IntegerInterleavedRaster: width = 500 height = 400 #Bands = 4 xOff = 0 yOff = 0 dataOffset[0] 0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*state0 = state[:,0]\n",
    "for i in np.arange(200):\n",
    "    envs[0].render()\n",
    "    preds = test_estimator.predict(state0)\n",
    "    iaction = np.argmax(preds)\n",
    "    obs, _, done0, _ = envs[0].step(VALID_ACTIONS[iaction])\n",
    "    state0 = np.concatenate((state0[nfeats:], preprocess(obs)))\n",
    "    if (done0): envs[0].reset() */\n",
    "//hist(ln(abs(q_estimator.gradsq(\"W1\")(?))),100)\n",
    "//    hist(ln(abs(q_estimator.gradsq(\"W1\")(?))),100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there we have it. Simple 1-step Q-Learning can solve easy problems very fast. Note that environments that produce images will be much slower to train on than environments (like CartPole) which return an observation of the state of the system. But this model can still train on those image-based games - like Atari games. It will take hours-days however. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "<console>:46: error: not found: value actions",
      "              q_estimator.gradient(state,actions,targets)",
      "                                         ^",
      "<console>:46: error: not found: value targets",
      "              q_estimator.gradient(state,actions,targets)",
      "                                                 ^"
     ]
    }
   ],
   "source": [
    "//q_estimator.gradient(state,actions,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "//saveFMat(\"BestW1.fmat.lz4\",q_estimator.model(\"W1\"))\n",
    "//saveFMat(\"BestW2.fmat.lz4\",q_estimator.model(\"W2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, time 0.0, epochs 0, reward/epoch 0.00000, cum reward/epoch 0.00000\n",
      "step 10000, time 93.0, epochs 22, reward/epoch 8.81818, cum reward/epoch 8.81818\n",
      "step 20000, time 186.3, epochs 47, reward/epoch 7.56000, cum reward/epoch 8.14894\n",
      "step 30000, time 279.1, epochs 72, reward/epoch 10.20000, cum reward/epoch 8.86111\n",
      "step 40000, time 372.2, epochs 101, reward/epoch 7.65517, cum reward/epoch 8.51485\n",
      "step 50000, time 465.1, epochs 124, reward/epoch 9.91304, cum reward/epoch 8.77419\n",
      "step 60000, time 557.9, epochs 149, reward/epoch 8.76000, cum reward/epoch 8.77181\n",
      "step 70000, time 650.7, epochs 173, reward/epoch 9.54167, cum reward/epoch 8.87861\n",
      "step 80000, time 743.6, epochs 198, reward/epoch 8.48000, cum reward/epoch 8.82828\n",
      "step 90000, time 836.5, epochs 223, reward/epoch 9.52000, cum reward/epoch 8.90583\n",
      "step 100000, time 929.4, epochs 247, reward/epoch 8.20833, cum reward/epoch 8.83806\n"
     ]
    }
   ],
   "source": [
    "val test_steps = 100001;\n",
    "val testprintsteps = 10000;\n",
    "\n",
    "val test_estimator = new Estimator(nfeats*nwindow, nhidden, nactions);\n",
    "test_estimator.model(\"W1\") = loadFMat(\"BestW1.fmat.lz4\");\n",
    "test_estimator.model(\"W2\") = loadFMat(\"BestW2.fmat.lz4\");\n",
    "\n",
    "block_reward = 0f;\n",
    "total_reward = 0f;\n",
    "total_epochs = 0;\n",
    "last_epochs = 0;\n",
    "\n",
    "tic;\n",
    "for (istep <- 0 until test_steps) {\n",
    "    \n",
    "    val action_probs = policy(test_estimator, state, 0);                    // get the next action probabilities from the policy                                                         \n",
    "    val actions = random_choices(action_probs);                             // Choose actions using the policy\n",
    "    val (obs, rewards, dones) = ALE.stepAll2(envs, VALID_ACTIONS(actions))  // step through parallel envs   \n",
    "    for (i <- 0 until npar) {                                                     \n",
    "        val img = preprocess(obs(i));                                       // process the observation\n",
    "        state(?,i) = state(nfeats->state.nrows,i) on img;                   // add it to buffer of last nwindow imgs        \n",
    "    }    \n",
    "    total_epochs += sum(dones).v.toInt\n",
    "    block_reward += sum(rewards).v  \n",
    "    \n",
    "    val t = toc;\n",
    "    if (istep % testprintsteps == 0) {\n",
    "        total_reward += block_reward;\n",
    "        println(\"step %d, time %2.1f, epochs %d, reward/epoch %6.5f, cum reward/epoch %6.5f\" format(\n",
    "                istep, t, total_epochs, block_reward/math.max(1,total_epochs-last_epochs), total_reward/math.max(1,total_epochs)))\n",
    "        last_epochs = total_epochs;\n",
    "        block_reward = 0f;\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
